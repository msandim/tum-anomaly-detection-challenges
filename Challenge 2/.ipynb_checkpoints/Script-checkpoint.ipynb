{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Anomaly Detection Challenge 1\n",
    "## Miguel Sandim and Paula Fortuna"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 - Data Reading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 - Solve format problems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a text editor (e. g. sublime) use regex.\n",
    "\n",
    "1) Replace \" by \"\"\n",
    "\n",
    "2) Surround text field with \"\n",
    "To match the first one use this (dont forget to remove the one that appears also in the begining of the sentence, and the one in the header):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "^[^;]*;[^;]*;[^;]*;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use this to find the last:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ";[^;]*;[^;]*;[^;]*;[^;]*;[^;]*;[^;]*$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) check if all the lines match the refered structure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "^[^;]*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4) Remove random newlines that appear in the rows and make new instance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Load data (finally!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# pandas\n",
    "import pandas as pd\n",
    "from pandas import Series,DataFrame\n",
    "\n",
    "# numpy, matplotlib, seaborn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "# Random libraries and seeds:\n",
    "import random\n",
    "random.seed(2)\n",
    "np.random.seed(2)\n",
    "\n",
    "# read from csv\n",
    "\n",
    "\n",
    "train_df = pd.read_csv(\"data/yelp_data_train.dat\", sep = ';', encoding = 'utf-8')\n",
    "test_df = pd.read_csv(\"data/yelp_data_test.dat\", sep = ';', encoding = 'utf-8')\n",
    "reviewers_df = pd.read_csv(\"data/yelp_data_reviewer.dat\", sep = ';', encoding = 'utf-8')\n",
    "#hotels_df = pd.read_csv(\"data/yelp_data_hotel.dat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>reviewID</th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>reviewContent</th>\n",
       "      <th>rating</th>\n",
       "      <th>usefulCount</th>\n",
       "      <th>coolCount</th>\n",
       "      <th>funnyCount</th>\n",
       "      <th>fake</th>\n",
       "      <th>hotelID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9/16/2010</td>\n",
       "      <td>Ol</td>\n",
       "      <td>nf3q2h-kSQoZK2jBY92FOg</td>\n",
       "      <td>If you are considering staying here, watch thi...</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>N</td>\n",
       "      <td>tQfLGoolUMu2J0igcWcoZg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2/5/2010</td>\n",
       "      <td>i4HIAcNTjabdpG1K4F5Q2g</td>\n",
       "      <td>Sb3DJGdZ4Rq__CqxPbae-g</td>\n",
       "      <td>This place is disgusting, absolutely horrible,...</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>N</td>\n",
       "      <td>tQfLGoolUMu2J0igcWcoZg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8/9/2010</td>\n",
       "      <td>veKKNAaSKWj8os</td>\n",
       "      <td>nR7zLyFOlzAYqmzgJ3DtXg</td>\n",
       "      <td>Disgusting!!!  There is literally duct tape ho...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>N</td>\n",
       "      <td>tQfLGoolUMu2J0igcWcoZg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8/11/2012</td>\n",
       "      <td>6c-ZiQkHXtp1n6VfiKDQ3g</td>\n",
       "      <td>747lP4p8dUD6RTkcsIaSGg</td>\n",
       "      <td>This hotel came up on Hotwire for $108 a night...</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>33Xc1Bk_gkSY5xb2doQ7Ng</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7/9/2012</td>\n",
       "      <td>POWQ6FuUf3oe2ZkhmHvciA</td>\n",
       "      <td>Ij5t6VdwtasSkrpp9uAbKg</td>\n",
       "      <td>Good location, really run down. I am surprised...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>33Xc1Bk_gkSY5xb2doQ7Ng</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6/19/2012</td>\n",
       "      <td>QBynYcLgIgtAd-YfnrrAtA</td>\n",
       "      <td>hSERzClUe57bCw3nCp4plA</td>\n",
       "      <td>Beautiful lobby. The rest is a dump. The eleva...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>33Xc1Bk_gkSY5xb2doQ7Ng</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>9/14/2012</td>\n",
       "      <td>ELY3TK</td>\n",
       "      <td>OMm2VcGks3QL0p0n3_kPFw</td>\n",
       "      <td>Stayed here when I went to Chicago for a weddi...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>33Xc1Bk_gkSY5xb2doQ7Ng</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3/20/2012</td>\n",
       "      <td>uWKWYb5vDpeDGEAZUc192g</td>\n",
       "      <td>yevHGEUQQmnVlBXIrJ885A</td>\n",
       "      <td>I bleed SPG loyalty blood to the point where I...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>33Xc1Bk_gkSY5xb2doQ7Ng</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3/3/2012</td>\n",
       "      <td>hkt7Dnr7kRnLLd9pm-fxDw</td>\n",
       "      <td>Lql1_3zeGlny_Tgq4MI6Fg</td>\n",
       "      <td>I stayed here a couple of times in 2011, as th...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>33Xc1Bk_gkSY5xb2doQ7Ng</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>6/18/2012</td>\n",
       "      <td>ZlexD7XvkqH8yve4zCAR7g</td>\n",
       "      <td>RtyDimVdIBwjGdQr0dti1w</td>\n",
       "      <td>This is an older property, so the decor is dat...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>33Xc1Bk_gkSY5xb2doQ7Ng</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>3/13/2012</td>\n",
       "      <td>Rw1JmyRyyjoACCUFvmS9kQ</td>\n",
       "      <td>hCIJT7tIhPX_YZBCPhYhMg</td>\n",
       "      <td>Small Rooms....one elevator that takes forever...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>33Xc1Bk_gkSY5xb2doQ7Ng</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>5/24/2010</td>\n",
       "      <td>O9chyjQi5</td>\n",
       "      <td>nKgjmPhPPiJ8BL97dO76XA</td>\n",
       "      <td>Great location, terribly outdated. Feels like ...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>33Xc1Bk_gkSY5xb2doQ7Ng</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>10/25/2010</td>\n",
       "      <td>x4FHvju16JpVa3ihzIwQvw</td>\n",
       "      <td>IhKctrZ3BtJkfpf0qO-8mQ</td>\n",
       "      <td>My husband and I came to Chicago for a week an...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>33Xc1Bk_gkSY5xb2doQ7Ng</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2/13/2011</td>\n",
       "      <td>NaN</td>\n",
       "      <td>yoB_PYQHjnPjh78ATA0Jgw</td>\n",
       "      <td>Stayed here over the Jan 15th weekend.  The lo...</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>33Xc1Bk_gkSY5xb2doQ7Ng</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>8/9/2011</td>\n",
       "      <td>9CPWfP7Ibj-2TthBN</td>\n",
       "      <td>b8B2b2q_Lcactxp8xr-jvg</td>\n",
       "      <td>Breakfast no longer free, but the wifi is. The...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>33Xc1Bk_gkSY5xb2doQ7Ng</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>9/21/2010</td>\n",
       "      <td>4sIRV-M-nrhyU5wHJSznrA</td>\n",
       "      <td>y5ptsWmvGEAftOQaiFhBcg</td>\n",
       "      <td>I can't imagine paying full price to stay here...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>33Xc1Bk_gkSY5xb2doQ7Ng</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>6/17/2009</td>\n",
       "      <td>s3V-CRnWtlHc2goC7xIAEA</td>\n",
       "      <td>QTJCwSaCfBz3T944SOiHBQ</td>\n",
       "      <td>For the money.. it was a great hotel. Clean, g...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>33Xc1Bk_gkSY5xb2doQ7Ng</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>4/4/2012</td>\n",
       "      <td>A5WJkZECjZVwSoV8Uxciww</td>\n",
       "      <td>_h5MGqTBM8J0tuAfbEvVDg</td>\n",
       "      <td>Great location for walking to any part of down...</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>33Xc1Bk_gkSY5xb2doQ7Ng</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>7/8/2011</td>\n",
       "      <td>xnZtuSIepywIkSC1uGYzGg</td>\n",
       "      <td>s6tSJ1NQMSU59lsCPYzzwQ</td>\n",
       "      <td>Excellent location right down the street from ...</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>33Xc1Bk_gkSY5xb2doQ7Ng</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>4/4/2011</td>\n",
       "      <td>FRM7-hER5S9wMf0IzciDcg</td>\n",
       "      <td>0oA4l1ob50aIZ9x9Kxobqg</td>\n",
       "      <td>Great location for a good price. Book it direc...</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>33Xc1Bk_gkSY5xb2doQ7Ng</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>8/23/2010</td>\n",
       "      <td>0fLzbPuBnOMKzVnmxqz-1w</td>\n",
       "      <td>3KM5g9hyaR-uE92WfMU6Cw</td>\n",
       "      <td>Another Travelzoo deal at an awesome price of ...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>33Xc1Bk_gkSY5xb2doQ7Ng</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>8/9/2008</td>\n",
       "      <td>MGcMncJSQQ7zzE</td>\n",
       "      <td>Nybw4RhZvdexOR-XgXD4DQ</td>\n",
       "      <td>For the love of God, whatever you do, DO NOT t...</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>33Xc1Bk_gkSY5xb2doQ7Ng</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>4/24/2011</td>\n",
       "      <td>8a8MaeJ99mi3WTUZYDYL2Q</td>\n",
       "      <td>SKgjcQz0TNg8LKqlJwxjfg</td>\n",
       "      <td>Decent price for downtown Chicago over a weeke...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>33Xc1Bk_gkSY5xb2doQ7Ng</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>10/3/2009</td>\n",
       "      <td>K8HSCX-GCOcF8VUsAtMSGQ</td>\n",
       "      <td>tdE3__i2otI_nL3M3sy0MQ</td>\n",
       "      <td>Some rooms may reveal the building's age, but ...</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>33Xc1Bk_gkSY5xb2doQ7Ng</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>4/17/2011</td>\n",
       "      <td>2rAeHez1ZzyHvL1u2DIJsw</td>\n",
       "      <td>fOTzYtBF4lJTwDIMfCAeyQ</td>\n",
       "      <td>If you want a reasonably priced, clean, non-ch...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>33Xc1Bk_gkSY5xb2doQ7Ng</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>7/17/2010</td>\n",
       "      <td>07mEVsw7wUKuUOH</td>\n",
       "      <td>Uu-qEGsSb72ngIQUF85rDQ</td>\n",
       "      <td>I arrived at the Tremont this past weekend for...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>33Xc1Bk_gkSY5xb2doQ7Ng</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>10/26/2009</td>\n",
       "      <td>Og0iVk</td>\n",
       "      <td>ptgFdw9WzPQx16w37XxsPQ</td>\n",
       "      <td>I have a fondness for older hotels that are a ...</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>33Xc1Bk_gkSY5xb2doQ7Ng</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>11/23/2011</td>\n",
       "      <td>JKcDTRG0dYs23kj1NeOB5A</td>\n",
       "      <td>zyk-YPhtFZK6kkbpzEKrWw</td>\n",
       "      <td>Well this was an interesting place.  I went to...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>2nnXespKBBNtDQTtrumNFg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>4/5/2012</td>\n",
       "      <td>6h8rBu1K3AxUiQE8biaTIg</td>\n",
       "      <td>T4LT4dPTTTVZocPhwrJboQ</td>\n",
       "      <td>The card key never worked.  I even got an extr...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>2nnXespKBBNtDQTtrumNFg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>3/24/2012</td>\n",
       "      <td>4uniW9GJpi56lRUyJFU-OQ</td>\n",
       "      <td>HfypTYNqexsCBuRBQFhKTA</td>\n",
       "      <td>I won't go into details but basically employee...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>2nnXespKBBNtDQTtrumNFg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2878</th>\n",
       "      <td>5/1/2007</td>\n",
       "      <td>ELidp04R7jwXfXV5mFW1XQ</td>\n",
       "      <td>_f9NyNygDasxm4x_8K0FMg</td>\n",
       "      <td>Boo Marriott. You may have comfy beds but hosp...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>Gh4Tb2qCBUCOd5r7jqKnGA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2879</th>\n",
       "      <td>7/14/2012</td>\n",
       "      <td>nJh1lZINVD5SAW2ecQir7A</td>\n",
       "      <td>aAnY0oKxg4WEcYsC9hw3cQ</td>\n",
       "      <td>I attended a week-long training in their confe...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>BISUDalmPulSzHvsO3PhDA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2880</th>\n",
       "      <td>3/5/2012</td>\n",
       "      <td>QkDj-K2</td>\n",
       "      <td>YfsNifnBJYJ1aq05eC-u3g</td>\n",
       "      <td>I am torn with how I want to rate this hotel. ...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>BISUDalmPulSzHvsO3PhDA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2881</th>\n",
       "      <td>9/14/2010</td>\n",
       "      <td>TFKtb8DG7yTAxkntYCRMTQ</td>\n",
       "      <td>uqC3ll6vCfqFalbWnPi-Qg</td>\n",
       "      <td>Rooms are kinda old. Service is pretty mediocr...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>BISUDalmPulSzHvsO3PhDA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2882</th>\n",
       "      <td>1/26/2010</td>\n",
       "      <td>QYD-28qlQRmlAe7G2FbNUA</td>\n",
       "      <td>mzO44cSLjgjo-TUYUqPyHA</td>\n",
       "      <td>I agree with the first reviewer Celeste. I had...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>BISUDalmPulSzHvsO3PhDA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2883</th>\n",
       "      <td>8/3/2011</td>\n",
       "      <td>ZjhC8PHPq5RGocFrXTYcWw</td>\n",
       "      <td>oa027MtAk0PV7Tom9K8xHQ</td>\n",
       "      <td>For the price I got this room for it was Great...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>BISUDalmPulSzHvsO3PhDA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2884</th>\n",
       "      <td>5/27/2010</td>\n",
       "      <td>u5gKtqSW4os8H1OImGEkEw</td>\n",
       "      <td>b_54V-mRPPHIwj0wFWby-g</td>\n",
       "      <td>I once found a key on the sidewalk near here, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>N</td>\n",
       "      <td>bem-1CTpTNpArpCtThTmFw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2885</th>\n",
       "      <td>2/3/2009</td>\n",
       "      <td>VlJdOpIVNevAbBeESTofeQ</td>\n",
       "      <td>WauJzu-aZSJZuCLkLWFkag</td>\n",
       "      <td>I was once told by the talent buyer at the Log...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>N</td>\n",
       "      <td>bem-1CTpTNpArpCtThTmFw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2886</th>\n",
       "      <td>10/4/2009</td>\n",
       "      <td>1bY3wvqJD3zOUx6b-HOb8g</td>\n",
       "      <td>OBz87AmKkY-RKP7dFQFugQ</td>\n",
       "      <td>Where do I begin?? There are so many horrible ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Y</td>\n",
       "      <td>bem-1CTpTNpArpCtThTmFw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2887</th>\n",
       "      <td>9/4/2009</td>\n",
       "      <td>BMQbKdF_m2gGeY6hr9Fv1Q</td>\n",
       "      <td>Dv3r6dxp6N7B2S4stwS4dg</td>\n",
       "      <td>This is obviously a place for junkies and hook...</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Y</td>\n",
       "      <td>bem-1CTpTNpArpCtThTmFw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2888</th>\n",
       "      <td>12/25/2011</td>\n",
       "      <td>M9jtbdwJYyxwWWufBaw3EA</td>\n",
       "      <td>-2aZoH_YaC-1s1BFzo7GcA</td>\n",
       "      <td>Over priced,  nickle and dime you for everythi...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Y</td>\n",
       "      <td>g51qDl6fQhgat-kFTrcbug</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2889</th>\n",
       "      <td>6/24/2011</td>\n",
       "      <td>LuMU5Me4cAMaxmoKWUrNZg</td>\n",
       "      <td>N0pY2Nd7xTZupPd3SYUWEA</td>\n",
       "      <td>Housekeeping staff here needs lessons--dusty f...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Y</td>\n",
       "      <td>g51qDl6fQhgat-kFTrcbug</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2890</th>\n",
       "      <td>11/30/2010</td>\n",
       "      <td>vE1oKqdlBCOfRDf7ObE_WQ</td>\n",
       "      <td>HWIJ4kkTMnuCTBkLmaupMA</td>\n",
       "      <td>There are too many old men trying to pick up w...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Y</td>\n",
       "      <td>BISUDalmPulSzHvsO3PhDA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2891</th>\n",
       "      <td>6/28/2011</td>\n",
       "      <td>ux6ZfjP5yWHXU4zQA3P7yA</td>\n",
       "      <td>zJ2Op8FsslxF5TSem1f-zw</td>\n",
       "      <td>I used priceline to get a room at this hotel. ...</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Y</td>\n",
       "      <td>Gh4Tb2qCBUCOd5r7jqKnGA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2892</th>\n",
       "      <td>4/16/2010</td>\n",
       "      <td>HzOVUdfy4vAXsIm_eH-Pww</td>\n",
       "      <td>2ck_k8Swtj6-48kLR6IVWA</td>\n",
       "      <td>When we got to the place where check in was ha...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Y</td>\n",
       "      <td>Gh4Tb2qCBUCOd5r7jqKnGA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2893</th>\n",
       "      <td>6/14/2011</td>\n",
       "      <td>D9urHoAJiktxTfpDy84vUw</td>\n",
       "      <td>MtR3yxthVe-LoHEAXUKSGw</td>\n",
       "      <td>My boss booked two rooms here because the pric...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Y</td>\n",
       "      <td>h-U_YfWBK2u_Vqo8AVA4KQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2894</th>\n",
       "      <td>6/4/2010</td>\n",
       "      <td>TYcOMlIhPaobaHFLywRLvw</td>\n",
       "      <td>2ynZkFzXxSYli0acUGEjxA</td>\n",
       "      <td>We stayed in the motel because of it's conveni...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Y</td>\n",
       "      <td>h-U_YfWBK2u_Vqo8AVA4KQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2895</th>\n",
       "      <td>9/25/2011</td>\n",
       "      <td>ECKiMfnDzi11HdfeK0LIBw</td>\n",
       "      <td>pB_MluKOj16YTAH4ZozyNA</td>\n",
       "      <td>Would recommend this hotel to anyone.  My wife...</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Y</td>\n",
       "      <td>wLjR0DkA4zxu8iqbUQc0Og</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2896</th>\n",
       "      <td>7/27/2012</td>\n",
       "      <td>W0KFuAk6Y62JTMdJw_7hWw</td>\n",
       "      <td>cHegKQwdtrdd3Hpo1b6NsA</td>\n",
       "      <td>Fantastic location, friendly staff and nice ac...</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Y</td>\n",
       "      <td>t5JK4OZzCuetIrJXdHLntg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2897</th>\n",
       "      <td>5/18/2012</td>\n",
       "      <td>t9G4R6uGohktZeHZmf3kKA</td>\n",
       "      <td>nFSimJkp5uq8FPTyY-4NNQ</td>\n",
       "      <td>This boutique hotel is in an excellent locatio...</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Y</td>\n",
       "      <td>t5JK4OZzCuetIrJXdHLntg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2898</th>\n",
       "      <td>8/1/2011</td>\n",
       "      <td>f_MP8IYIvV_Sp3AgAFG0Iw</td>\n",
       "      <td>YMsf5cb9kbEj7DuPdyQ4eA</td>\n",
       "      <td>My wife and I stayed here July 30th. We arrive...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Y</td>\n",
       "      <td>t5JK4OZzCuetIrJXdHLntg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2899</th>\n",
       "      <td>7/19/2011</td>\n",
       "      <td>6mqU5bF4Iq1ZHBfknBUsYQ</td>\n",
       "      <td>JwKrfYb2BNFRZdHCFlwO1w</td>\n",
       "      <td>Very clean and super helpful staff.  The rooms...</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Y</td>\n",
       "      <td>t5JK4OZzCuetIrJXdHLntg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2900</th>\n",
       "      <td>6/16/2010</td>\n",
       "      <td>pXxaEx57oNIMqsLBqVczyg</td>\n",
       "      <td>hI8LGBnG-VupdJhsj_U3Og</td>\n",
       "      <td>My company held an event here and the staff ov...</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Y</td>\n",
       "      <td>S_qmb0Uzm_cNoRjSvZ6y1w</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2901</th>\n",
       "      <td>4/6/2010</td>\n",
       "      <td>OTJHRZXJn8UfAJ4ljWN9sw</td>\n",
       "      <td>hU9lnr5ZAwWr0SHzg7RdHg</td>\n",
       "      <td>This boutique hotel has a very personal approa...</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Y</td>\n",
       "      <td>S_qmb0Uzm_cNoRjSvZ6y1w</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2902</th>\n",
       "      <td>10/10/2008</td>\n",
       "      <td>IDSx8yGQKNUImss-4YUlGg</td>\n",
       "      <td>BaRtixU-lZsMr2PF4hrvqg</td>\n",
       "      <td>Wife and I stay here when we visit. Went up on...</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Y</td>\n",
       "      <td>S_qmb0Uzm_cNoRjSvZ6y1w</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2903</th>\n",
       "      <td>8/2/2012</td>\n",
       "      <td>lFkroXzrRhmMTrnn6__tnw</td>\n",
       "      <td>ZpFB_pqaUaDmIuCXbN87Ww</td>\n",
       "      <td>All Westins are definitely nice and so was thi...</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Y</td>\n",
       "      <td>LUmAQaRrAleKdXZd8On16Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2904</th>\n",
       "      <td>12/14/2011</td>\n",
       "      <td>mV2x61nyxzsKRgGbM3yuqg</td>\n",
       "      <td>twaozx1wvDOL0Z_fG9gclA</td>\n",
       "      <td>This place was awesome! Well except for the we...</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Y</td>\n",
       "      <td>PyG0aSX3pBx0hzoSH20FnA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2905</th>\n",
       "      <td>11/21/2009</td>\n",
       "      <td>CNwz6w426kCF5H6j-neQSg</td>\n",
       "      <td>S5L1xguLhXJWadpFXnRKqQ</td>\n",
       "      <td>My friend and I, along with our mothers, staye...</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Y</td>\n",
       "      <td>PyG0aSX3pBx0hzoSH20FnA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2906</th>\n",
       "      <td>11/20/2011</td>\n",
       "      <td>1eJPupHCsl-r3WUuz6QvTA</td>\n",
       "      <td>PJK4GsUItBU8JJuoAujWOA</td>\n",
       "      <td>So Surprising when we arrived, The staff was g...</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Y</td>\n",
       "      <td>gCdjyQeE0uRKCh7mVmnZzQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2907</th>\n",
       "      <td>8/5/2010</td>\n",
       "      <td>xwPMoEzuvpn3J32IvTcsiQ</td>\n",
       "      <td>MdYbNl_9Hm1CybsuC6UnkQ</td>\n",
       "      <td>Noise, noise, noise!  Unbelievable!  Between t...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Y</td>\n",
       "      <td>rpP9iZsT3NC-Z4pUtQGoiA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2908 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            date                reviewID              reviewerID  \\\n",
       "0      9/16/2010                      Ol  nf3q2h-kSQoZK2jBY92FOg   \n",
       "1       2/5/2010  i4HIAcNTjabdpG1K4F5Q2g  Sb3DJGdZ4Rq__CqxPbae-g   \n",
       "2       8/9/2010          veKKNAaSKWj8os  nR7zLyFOlzAYqmzgJ3DtXg   \n",
       "3      8/11/2012  6c-ZiQkHXtp1n6VfiKDQ3g  747lP4p8dUD6RTkcsIaSGg   \n",
       "4       7/9/2012  POWQ6FuUf3oe2ZkhmHvciA  Ij5t6VdwtasSkrpp9uAbKg   \n",
       "5      6/19/2012  QBynYcLgIgtAd-YfnrrAtA  hSERzClUe57bCw3nCp4plA   \n",
       "6      9/14/2012                  ELY3TK  OMm2VcGks3QL0p0n3_kPFw   \n",
       "7      3/20/2012  uWKWYb5vDpeDGEAZUc192g  yevHGEUQQmnVlBXIrJ885A   \n",
       "8       3/3/2012  hkt7Dnr7kRnLLd9pm-fxDw  Lql1_3zeGlny_Tgq4MI6Fg   \n",
       "9      6/18/2012  ZlexD7XvkqH8yve4zCAR7g  RtyDimVdIBwjGdQr0dti1w   \n",
       "10     3/13/2012  Rw1JmyRyyjoACCUFvmS9kQ  hCIJT7tIhPX_YZBCPhYhMg   \n",
       "11     5/24/2010               O9chyjQi5  nKgjmPhPPiJ8BL97dO76XA   \n",
       "12    10/25/2010  x4FHvju16JpVa3ihzIwQvw  IhKctrZ3BtJkfpf0qO-8mQ   \n",
       "13     2/13/2011                     NaN  yoB_PYQHjnPjh78ATA0Jgw   \n",
       "14      8/9/2011       9CPWfP7Ibj-2TthBN  b8B2b2q_Lcactxp8xr-jvg   \n",
       "15     9/21/2010  4sIRV-M-nrhyU5wHJSznrA  y5ptsWmvGEAftOQaiFhBcg   \n",
       "16     6/17/2009  s3V-CRnWtlHc2goC7xIAEA  QTJCwSaCfBz3T944SOiHBQ   \n",
       "17      4/4/2012  A5WJkZECjZVwSoV8Uxciww  _h5MGqTBM8J0tuAfbEvVDg   \n",
       "18      7/8/2011  xnZtuSIepywIkSC1uGYzGg  s6tSJ1NQMSU59lsCPYzzwQ   \n",
       "19      4/4/2011  FRM7-hER5S9wMf0IzciDcg  0oA4l1ob50aIZ9x9Kxobqg   \n",
       "20     8/23/2010  0fLzbPuBnOMKzVnmxqz-1w  3KM5g9hyaR-uE92WfMU6Cw   \n",
       "21      8/9/2008          MGcMncJSQQ7zzE  Nybw4RhZvdexOR-XgXD4DQ   \n",
       "22     4/24/2011  8a8MaeJ99mi3WTUZYDYL2Q  SKgjcQz0TNg8LKqlJwxjfg   \n",
       "23     10/3/2009  K8HSCX-GCOcF8VUsAtMSGQ  tdE3__i2otI_nL3M3sy0MQ   \n",
       "24     4/17/2011  2rAeHez1ZzyHvL1u2DIJsw  fOTzYtBF4lJTwDIMfCAeyQ   \n",
       "25     7/17/2010         07mEVsw7wUKuUOH  Uu-qEGsSb72ngIQUF85rDQ   \n",
       "26    10/26/2009                  Og0iVk  ptgFdw9WzPQx16w37XxsPQ   \n",
       "27    11/23/2011  JKcDTRG0dYs23kj1NeOB5A  zyk-YPhtFZK6kkbpzEKrWw   \n",
       "28      4/5/2012  6h8rBu1K3AxUiQE8biaTIg  T4LT4dPTTTVZocPhwrJboQ   \n",
       "29     3/24/2012  4uniW9GJpi56lRUyJFU-OQ  HfypTYNqexsCBuRBQFhKTA   \n",
       "...          ...                     ...                     ...   \n",
       "2878    5/1/2007  ELidp04R7jwXfXV5mFW1XQ  _f9NyNygDasxm4x_8K0FMg   \n",
       "2879   7/14/2012  nJh1lZINVD5SAW2ecQir7A  aAnY0oKxg4WEcYsC9hw3cQ   \n",
       "2880    3/5/2012                 QkDj-K2  YfsNifnBJYJ1aq05eC-u3g   \n",
       "2881   9/14/2010  TFKtb8DG7yTAxkntYCRMTQ  uqC3ll6vCfqFalbWnPi-Qg   \n",
       "2882   1/26/2010  QYD-28qlQRmlAe7G2FbNUA  mzO44cSLjgjo-TUYUqPyHA   \n",
       "2883    8/3/2011  ZjhC8PHPq5RGocFrXTYcWw  oa027MtAk0PV7Tom9K8xHQ   \n",
       "2884   5/27/2010  u5gKtqSW4os8H1OImGEkEw  b_54V-mRPPHIwj0wFWby-g   \n",
       "2885    2/3/2009  VlJdOpIVNevAbBeESTofeQ  WauJzu-aZSJZuCLkLWFkag   \n",
       "2886   10/4/2009  1bY3wvqJD3zOUx6b-HOb8g  OBz87AmKkY-RKP7dFQFugQ   \n",
       "2887    9/4/2009  BMQbKdF_m2gGeY6hr9Fv1Q  Dv3r6dxp6N7B2S4stwS4dg   \n",
       "2888  12/25/2011  M9jtbdwJYyxwWWufBaw3EA  -2aZoH_YaC-1s1BFzo7GcA   \n",
       "2889   6/24/2011  LuMU5Me4cAMaxmoKWUrNZg  N0pY2Nd7xTZupPd3SYUWEA   \n",
       "2890  11/30/2010  vE1oKqdlBCOfRDf7ObE_WQ  HWIJ4kkTMnuCTBkLmaupMA   \n",
       "2891   6/28/2011  ux6ZfjP5yWHXU4zQA3P7yA  zJ2Op8FsslxF5TSem1f-zw   \n",
       "2892   4/16/2010  HzOVUdfy4vAXsIm_eH-Pww  2ck_k8Swtj6-48kLR6IVWA   \n",
       "2893   6/14/2011  D9urHoAJiktxTfpDy84vUw  MtR3yxthVe-LoHEAXUKSGw   \n",
       "2894    6/4/2010  TYcOMlIhPaobaHFLywRLvw  2ynZkFzXxSYli0acUGEjxA   \n",
       "2895   9/25/2011  ECKiMfnDzi11HdfeK0LIBw  pB_MluKOj16YTAH4ZozyNA   \n",
       "2896   7/27/2012  W0KFuAk6Y62JTMdJw_7hWw  cHegKQwdtrdd3Hpo1b6NsA   \n",
       "2897   5/18/2012  t9G4R6uGohktZeHZmf3kKA  nFSimJkp5uq8FPTyY-4NNQ   \n",
       "2898    8/1/2011  f_MP8IYIvV_Sp3AgAFG0Iw  YMsf5cb9kbEj7DuPdyQ4eA   \n",
       "2899   7/19/2011  6mqU5bF4Iq1ZHBfknBUsYQ  JwKrfYb2BNFRZdHCFlwO1w   \n",
       "2900   6/16/2010  pXxaEx57oNIMqsLBqVczyg  hI8LGBnG-VupdJhsj_U3Og   \n",
       "2901    4/6/2010  OTJHRZXJn8UfAJ4ljWN9sw  hU9lnr5ZAwWr0SHzg7RdHg   \n",
       "2902  10/10/2008  IDSx8yGQKNUImss-4YUlGg  BaRtixU-lZsMr2PF4hrvqg   \n",
       "2903    8/2/2012  lFkroXzrRhmMTrnn6__tnw  ZpFB_pqaUaDmIuCXbN87Ww   \n",
       "2904  12/14/2011  mV2x61nyxzsKRgGbM3yuqg  twaozx1wvDOL0Z_fG9gclA   \n",
       "2905  11/21/2009  CNwz6w426kCF5H6j-neQSg  S5L1xguLhXJWadpFXnRKqQ   \n",
       "2906  11/20/2011  1eJPupHCsl-r3WUuz6QvTA  PJK4GsUItBU8JJuoAujWOA   \n",
       "2907    8/5/2010  xwPMoEzuvpn3J32IvTcsiQ  MdYbNl_9Hm1CybsuC6UnkQ   \n",
       "\n",
       "                                          reviewContent  rating  usefulCount  \\\n",
       "0     If you are considering staying here, watch thi...       1            8   \n",
       "1     This place is disgusting, absolutely horrible,...       3           11   \n",
       "2     Disgusting!!!  There is literally duct tape ho...       1            1   \n",
       "3     This hotel came up on Hotwire for $108 a night...       4            2   \n",
       "4     Good location, really run down. I am surprised...       2            0   \n",
       "5     Beautiful lobby. The rest is a dump. The eleva...       1            0   \n",
       "6     Stayed here when I went to Chicago for a weddi...       3            2   \n",
       "7     I bleed SPG loyalty blood to the point where I...       1            1   \n",
       "8     I stayed here a couple of times in 2011, as th...       3            0   \n",
       "9     This is an older property, so the decor is dat...       1            0   \n",
       "10    Small Rooms....one elevator that takes forever...       2            0   \n",
       "11    Great location, terribly outdated. Feels like ...       2            2   \n",
       "12    My husband and I came to Chicago for a week an...       4            1   \n",
       "13    Stayed here over the Jan 15th weekend.  The lo...       4            0   \n",
       "14    Breakfast no longer free, but the wifi is. The...       4            1   \n",
       "15    I can't imagine paying full price to stay here...       2            0   \n",
       "16    For the money.. it was a great hotel. Clean, g...       3            0   \n",
       "17    Great location for walking to any part of down...       4            0   \n",
       "18    Excellent location right down the street from ...       4            0   \n",
       "19    Great location for a good price. Book it direc...       4            0   \n",
       "20    Another Travelzoo deal at an awesome price of ...       2            0   \n",
       "21    For the love of God, whatever you do, DO NOT t...       4            0   \n",
       "22    Decent price for downtown Chicago over a weeke...       2            0   \n",
       "23    Some rooms may reveal the building's age, but ...       4            0   \n",
       "24    If you want a reasonably priced, clean, non-ch...       3            0   \n",
       "25    I arrived at the Tremont this past weekend for...       2            2   \n",
       "26    I have a fondness for older hotels that are a ...       4            0   \n",
       "27    Well this was an interesting place.  I went to...       3            1   \n",
       "28    The card key never worked.  I even got an extr...       1            1   \n",
       "29    I won't go into details but basically employee...       1            1   \n",
       "...                                                 ...     ...          ...   \n",
       "2878  Boo Marriott. You may have comfy beds but hosp...       1            2   \n",
       "2879  I attended a week-long training in their confe...       4            1   \n",
       "2880  I am torn with how I want to rate this hotel. ...       4            3   \n",
       "2881  Rooms are kinda old. Service is pretty mediocr...       3            0   \n",
       "2882  I agree with the first reviewer Celeste. I had...       2            2   \n",
       "2883  For the price I got this room for it was Great...       3            1   \n",
       "2884  I once found a key on the sidewalk near here, ...       1            4   \n",
       "2885  I was once told by the talent buyer at the Log...       1            3   \n",
       "2886  Where do I begin?? There are so many horrible ...       1            0   \n",
       "2887  This is obviously a place for junkies and hook...       5            0   \n",
       "2888  Over priced,  nickle and dime you for everythi...       1            0   \n",
       "2889  Housekeeping staff here needs lessons--dusty f...       2            0   \n",
       "2890  There are too many old men trying to pick up w...       2            0   \n",
       "2891  I used priceline to get a room at this hotel. ...       4            0   \n",
       "2892  When we got to the place where check in was ha...       1            0   \n",
       "2893  My boss booked two rooms here because the pric...       1            0   \n",
       "2894  We stayed in the motel because of it's conveni...       1            0   \n",
       "2895  Would recommend this hotel to anyone.  My wife...       5            0   \n",
       "2896  Fantastic location, friendly staff and nice ac...       4            0   \n",
       "2897  This boutique hotel is in an excellent locatio...       4            0   \n",
       "2898  My wife and I stayed here July 30th. We arrive...       2            0   \n",
       "2899  Very clean and super helpful staff.  The rooms...       4            0   \n",
       "2900  My company held an event here and the staff ov...       4            0   \n",
       "2901  This boutique hotel has a very personal approa...       5            0   \n",
       "2902  Wife and I stay here when we visit. Went up on...       5            0   \n",
       "2903  All Westins are definitely nice and so was thi...       4            0   \n",
       "2904  This place was awesome! Well except for the we...       4            0   \n",
       "2905  My friend and I, along with our mothers, staye...       5            0   \n",
       "2906  So Surprising when we arrived, The staff was g...       5            0   \n",
       "2907  Noise, noise, noise!  Unbelievable!  Between t...       1            0   \n",
       "\n",
       "      coolCount  funnyCount fake                 hotelID  \n",
       "0             2           6    N  tQfLGoolUMu2J0igcWcoZg  \n",
       "1             4           9    N  tQfLGoolUMu2J0igcWcoZg  \n",
       "2             0           3    N  tQfLGoolUMu2J0igcWcoZg  \n",
       "3             0           1    N  33Xc1Bk_gkSY5xb2doQ7Ng  \n",
       "4             0           0    N  33Xc1Bk_gkSY5xb2doQ7Ng  \n",
       "5             1           1    N  33Xc1Bk_gkSY5xb2doQ7Ng  \n",
       "6             0           0    N  33Xc1Bk_gkSY5xb2doQ7Ng  \n",
       "7             1           0    N  33Xc1Bk_gkSY5xb2doQ7Ng  \n",
       "8             0           0    N  33Xc1Bk_gkSY5xb2doQ7Ng  \n",
       "9             0           0    N  33Xc1Bk_gkSY5xb2doQ7Ng  \n",
       "10            0           0    N  33Xc1Bk_gkSY5xb2doQ7Ng  \n",
       "11            1           1    N  33Xc1Bk_gkSY5xb2doQ7Ng  \n",
       "12            0           0    N  33Xc1Bk_gkSY5xb2doQ7Ng  \n",
       "13            0           0    N  33Xc1Bk_gkSY5xb2doQ7Ng  \n",
       "14            0           0    N  33Xc1Bk_gkSY5xb2doQ7Ng  \n",
       "15            0           1    N  33Xc1Bk_gkSY5xb2doQ7Ng  \n",
       "16            0           0    N  33Xc1Bk_gkSY5xb2doQ7Ng  \n",
       "17            0           0    N  33Xc1Bk_gkSY5xb2doQ7Ng  \n",
       "18            0           0    N  33Xc1Bk_gkSY5xb2doQ7Ng  \n",
       "19            0           0    N  33Xc1Bk_gkSY5xb2doQ7Ng  \n",
       "20            1           1    N  33Xc1Bk_gkSY5xb2doQ7Ng  \n",
       "21            0           1    N  33Xc1Bk_gkSY5xb2doQ7Ng  \n",
       "22            0           0    N  33Xc1Bk_gkSY5xb2doQ7Ng  \n",
       "23            0           0    N  33Xc1Bk_gkSY5xb2doQ7Ng  \n",
       "24            0           1    N  33Xc1Bk_gkSY5xb2doQ7Ng  \n",
       "25            0           0    N  33Xc1Bk_gkSY5xb2doQ7Ng  \n",
       "26            0           0    N  33Xc1Bk_gkSY5xb2doQ7Ng  \n",
       "27            0           0    N  2nnXespKBBNtDQTtrumNFg  \n",
       "28            0           0    N  2nnXespKBBNtDQTtrumNFg  \n",
       "29            0           0    N  2nnXespKBBNtDQTtrumNFg  \n",
       "...         ...         ...  ...                     ...  \n",
       "2878          0           0    N  Gh4Tb2qCBUCOd5r7jqKnGA  \n",
       "2879          0           0    N  BISUDalmPulSzHvsO3PhDA  \n",
       "2880          1           1    N  BISUDalmPulSzHvsO3PhDA  \n",
       "2881          0           0    N  BISUDalmPulSzHvsO3PhDA  \n",
       "2882          0           0    N  BISUDalmPulSzHvsO3PhDA  \n",
       "2883          0           0    N  BISUDalmPulSzHvsO3PhDA  \n",
       "2884          2          11    N  bem-1CTpTNpArpCtThTmFw  \n",
       "2885          2           3    N  bem-1CTpTNpArpCtThTmFw  \n",
       "2886          0           0    Y  bem-1CTpTNpArpCtThTmFw  \n",
       "2887          0           0    Y  bem-1CTpTNpArpCtThTmFw  \n",
       "2888          0           0    Y  g51qDl6fQhgat-kFTrcbug  \n",
       "2889          0           0    Y  g51qDl6fQhgat-kFTrcbug  \n",
       "2890          0           0    Y  BISUDalmPulSzHvsO3PhDA  \n",
       "2891          0           0    Y  Gh4Tb2qCBUCOd5r7jqKnGA  \n",
       "2892          0           0    Y  Gh4Tb2qCBUCOd5r7jqKnGA  \n",
       "2893          0           0    Y  h-U_YfWBK2u_Vqo8AVA4KQ  \n",
       "2894          0           0    Y  h-U_YfWBK2u_Vqo8AVA4KQ  \n",
       "2895          0           0    Y  wLjR0DkA4zxu8iqbUQc0Og  \n",
       "2896          0           0    Y  t5JK4OZzCuetIrJXdHLntg  \n",
       "2897          0           0    Y  t5JK4OZzCuetIrJXdHLntg  \n",
       "2898          0           0    Y  t5JK4OZzCuetIrJXdHLntg  \n",
       "2899          0           0    Y  t5JK4OZzCuetIrJXdHLntg  \n",
       "2900          0           0    Y  S_qmb0Uzm_cNoRjSvZ6y1w  \n",
       "2901          0           0    Y  S_qmb0Uzm_cNoRjSvZ6y1w  \n",
       "2902          0           0    Y  S_qmb0Uzm_cNoRjSvZ6y1w  \n",
       "2903          0           0    Y  LUmAQaRrAleKdXZd8On16Q  \n",
       "2904          0           0    Y  PyG0aSX3pBx0hzoSH20FnA  \n",
       "2905          0           0    Y  PyG0aSX3pBx0hzoSH20FnA  \n",
       "2906          0           0    Y  gCdjyQeE0uRKCh7mVmnZzQ  \n",
       "2907          0           0    Y  rpP9iZsT3NC-Z4pUtQGoiA  \n",
       "\n",
       "[2908 rows x 10 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_df.iloc[:,36].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "479/(3956 + 479)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## About 10% of our dataset are anomalous cases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Global Variables "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Y_train = train_df[len(train_df.columns)-1]\n",
    "X_train = train_df.drop(len(train_df.columns)-1,axis=1)\n",
    "num_rows_X_train = X_train[0].count()\n",
    "num_columns_X_train = len(X_train.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utils Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# From: http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\n",
    "import itertools\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "######################################\n",
    "# Function Save Data To CSV\n",
    "######################################\n",
    "\n",
    "def saveDataToCSV(Y_pred):\n",
    "    id_list = range(1, len(Y_pred)+1)\n",
    "    submission = pd.DataFrame({\n",
    "        \"Id\": id_list,\n",
    "        \"Expected\": Y_pred\n",
    "    })\n",
    "    submission = submission[['Id', 'Expected']]\n",
    "    submission.to_csv('submission.csv', index=False)\n",
    "    return\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 - Data Pre-Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 - Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n",
    "import numpy.ma as ma\n",
    "import math\n",
    "\n",
    "######################################\n",
    "# Strategies based on constants\n",
    "######################################\n",
    "\n",
    "#replace by zero - black colour in RGB\n",
    "def replaceByZero(df):\n",
    "    return np.nan_to_num(df)\n",
    "\n",
    "#replace by 255 - white colour in RGB\n",
    "def replaceBy255(df):\n",
    "    return df.fillna(255)\n",
    "\n",
    "#####################################\n",
    "# Strategies based on columns values\n",
    "#####################################\n",
    "\n",
    "#column minimum\n",
    "def replaceByColumnMinimum(df):\n",
    "    return df.fillna(df.min())\n",
    "\n",
    "#column maximum\n",
    "def replaceByColumnMaximum(df):\n",
    "    return df.fillna(df.max())\n",
    "\n",
    "#column mean\n",
    "def replaceByColumnMean(df):\n",
    "    return df.fillna(df.mean())\n",
    "\n",
    "#column median\n",
    "def replaceByColumnMedian(df):\n",
    "    return df.fillna(df.median())\n",
    "\n",
    "#####################################\n",
    "# Strategies based on rows values\n",
    "#####################################\n",
    "\n",
    "# in the analysis of the rows we have to take into account that each four consecutive rows describe a pixel.\n",
    "# Each of these four rows stands for: Red, Green, IR, IR. |R|G|IR1|IR2|\n",
    "# These values refer to different things, and therefore are analysed independently.\n",
    "# this will allow to consider more the specificities of the problem\n",
    "\n",
    "# divide the data into four datasets, corresponding to each type of values \n",
    "\n",
    "#general function to gather columns for each type |R|G|IR1|IR2| using the mod operator\n",
    "def separatePixelColumns(position, df):\n",
    "    indexes = range(0, num_columns_X_train-1)\n",
    "    indexes = [x for x in indexes if x % 4 == position]\n",
    "    df_p_attribute = df.iloc[:,indexes]\n",
    "    return df_p_attribute\n",
    "\n",
    "#general function to fill missing values based on the rows\n",
    "#Note that does not make sense to consider the four values |R|G|IR1|IR2|, because they refer to different properties\n",
    "def fillMissingValuesByRow(df, function):\n",
    "    for index, row in df.iterrows():\n",
    "        value_without_nan = function(row)\n",
    "        nan_positions = row.isnull()\n",
    "        row[nan_positions] = value_without_nan\n",
    "    return df\n",
    "\n",
    "#row spectral mean\n",
    "def replaceByRowMean(df):\n",
    "    return fillMissingValuesByRow(df, np.nanmean)\n",
    "\n",
    "#row spectral median\n",
    "def replaceByRowMedian(df):\n",
    "    return fillMissingValuesByRow(df, np.nanmedian)\n",
    "\n",
    "#row spectral minimum\n",
    "def replaceByRowMinimum(df):\n",
    "    return fillMissingValuesByRow(df, np.nanmin)\n",
    "\n",
    "#row spectral maximum\n",
    "def replaceByRowMaximum(df):\n",
    "    return fillMissingValuesByRow(df, np.nanmax)\n",
    "\n",
    "########################################\n",
    "# Strategies based on data distribution\n",
    "########################################\n",
    "\n",
    "#consider the distribution of the spectral values of each type. \n",
    "#Get random value from the spectral values of same type\n",
    "\n",
    "    \n",
    "def getRandomNumberFromDataframe(df):\n",
    "    while True:\n",
    "        row = df.sample(1, random_state = 2)\n",
    "        values = row.values[0]\n",
    "        value = random.choice(values)\n",
    "        if not math.isnan(value):\n",
    "            break\n",
    "    return value\n",
    "        \n",
    "def fillMissingValuesWithDistribution(df):\n",
    "    for index, row in df.iterrows():\n",
    "        nan_positions = row.isnull()\n",
    "        for i in range(len(nan_positions)): \n",
    "            if nan_positions.iloc[i] == True:\n",
    "                value = getRandomNumberFromDataframe(df)\n",
    "                row.iloc[i] = value\n",
    "    return df\n",
    "\n",
    "#########################################%%%\n",
    "# fill Missing Values Considering Spectral\n",
    "#########################################%%%\n",
    "\n",
    "def fillMissingValuesBySpectral(df, function):\n",
    "\n",
    "    #generate four new datasets with the columns of each type\n",
    "    df_p_attribute_R = separatePixelColumns(0, df)\n",
    "    df_p_attribute_G = separatePixelColumns(1, df)\n",
    "    df_p_attribute_IR1 = separatePixelColumns(2, df)\n",
    "    df_p_attribute_IR2 = separatePixelColumns(3, df)\n",
    "\n",
    "    #apply function to each of the 4 datasets\n",
    "    df_p_attribute_R = function(df_p_attribute_R)\n",
    "    df_p_attribute_G = function(df_p_attribute_G)\n",
    "    df_p_attribute_IR1 = function(df_p_attribute_IR1)\n",
    "    df_p_attribute_IR2 = function(df_p_attribute_IR2)\n",
    "\n",
    "    df = pd.concat(\n",
    "                        [df_p_attribute_R, \n",
    "                         df_p_attribute_G,\n",
    "                         df_p_attribute_IR1,\n",
    "                         df_p_attribute_IR2], \n",
    "                        axis=1\n",
    "                        )\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#######################\n",
    "#   CHAMADAS\n",
    "#######################\n",
    "\n",
    "#X_train = replaceByZero(X_train)\n",
    "#test_df = replaceByZero(test_df)\n",
    "\n",
    "#X_train = replaceBy255(X_train)\n",
    "#test_df = replaceBy255(test_df)\n",
    "\n",
    "#X_train = replaceByColumnMinimum(X_train)\n",
    "#test_df = replaceByColumnMinimum(test_df)\n",
    "\n",
    "#X_train = replaceByColumnMaximum(X_train)\n",
    "#test_df = replaceByColumnMaximum(test_df)\n",
    "\n",
    "#X_train = replaceByColumnMean(X_train)\n",
    "#test_df = replaceByColumnMean(test_df)\n",
    "\n",
    "#X_train = replaceByColumnMedian(X_train)\n",
    "#test_df = replaceByColumnMedian(test_df)\n",
    "\n",
    "#X_train = fillMissingValuesBySpectral(X_train, replaceByRowMean)\n",
    "#test_df = fillMissingValuesBySpectral(test_df, replaceByRowMean)\n",
    "\n",
    "#X_train = fillMissingValuesBySpectral(X_train, replaceByRowMedian)\n",
    "#test_df = fillMissingValuesBySpectral(test_df, replaceByRowMedian)\n",
    "\n",
    "#X_train = fillMissingValuesBySpectral(X_train, replaceByRowMinimum)\n",
    "#test_df = fillMissingValuesBySpectral(test_df, replaceByRowMinimum)\n",
    "\n",
    "#X_train = fillMissingValuesBySpectral(X_train, replaceByRowMaximum)\n",
    "#test_df = fillMissingValuesBySpectral(test_df, replaceByRowMaximum)\n",
    "\n",
    "#X_train = fillMissingValuesBySpectral(X_train, fillMissingValuesWithDistribution)\n",
    "#test_df = fillMissingValuesBySpectral(test_df, fillMissingValuesWithDistribution)\n",
    "\n",
    "datasets = {f_name: {\"train\": f(X_train.copy()), \"test\": f(test_df.copy())} for f_name, f in [\n",
    "        (\"01-zero\", replaceByZero),\n",
    "        (\"02-255\", replaceBy255),\n",
    "        (\"03-col-min\", replaceByColumnMinimum),\n",
    "        (\"04-col-max\", replaceByColumnMaximum),\n",
    "        (\"05-col-mean\", replaceByColumnMean),\n",
    "        (\"06-col-median\", replaceByColumnMedian),\n",
    "        (\"07-spec-mean\", lambda data: fillMissingValuesBySpectral(data, replaceByRowMean)),\n",
    "        (\"08-spec-median\", lambda data: fillMissingValuesBySpectral(data, replaceByRowMedian)),\n",
    "        (\"09-spec-min\", lambda data: fillMissingValuesBySpectral(data, replaceByRowMinimum)),\n",
    "        (\"10-spec-max\", lambda data: fillMissingValuesBySpectral(data, replaceByRowMaximum)),\n",
    "        (\"11-spec-dis\", lambda data: fillMissingValuesBySpectral(data, fillMissingValuesWithDistribution))\n",
    "    ]}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Normalization\n",
    "\n",
    "There is no need for normalization in this dataset, since all features are between 0 and 255."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 - Model Selection\n",
    "\n",
    "- First goal: discover which type of analyses works better\n",
    "- Second Goal: tune the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 - Model selection based on which models do best in CV using default settings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#inspired in http://machinelearningmastery.com/compare-machine-learning-algorithms-python-scikit-learn/\n",
    "\n",
    "import sklearn.model_selection as mds\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "import xgboost as xgb\n",
    "\n",
    "# prepare data\n",
    "\n",
    "#Y_train = train_df[:,-1]\n",
    "#X_train = train_df[:,:-1]\n",
    "\n",
    "#Y_train = train_df[len(train_df.columns)-1]\n",
    "#X_train = train_df.drop(len(train_df.columns)-1,axis=1)\n",
    "\n",
    "# prepare configuration for cross validation test harness\n",
    "num_folds = 10\n",
    "num_instances = len(X_train)\n",
    "\n",
    "# prepare models\n",
    "models = []\n",
    "models.append(('LR', LogisticRegression()))\n",
    "models.append(('LDA', LinearDiscriminantAnalysis()))\n",
    "models.append(('KNN', KNeighborsClassifier()))\n",
    "models.append(('CART', DecisionTreeClassifier()))\n",
    "models.append(('NB', GaussianNB()))\n",
    "#models.append(('SVM-Linear', SVC(kernel=\"linear\")))\n",
    "models.append(('SVM-Poly', SVC(kernel=\"poly\")))\n",
    "models.append(('SVM-RBF', SVC(kernel=\"rbf\")))\n",
    "models.append(('NN', MLPClassifier(alpha=1))) \n",
    "models.append(('RF', RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1)))\n",
    "models.append(('AB', AdaBoostClassifier()))\n",
    "models.append(('XGB', xgb.XGBClassifier()))\n",
    "\n",
    "# evaluate each model in turn\n",
    "results = {}\n",
    "scoring = 'roc_auc' # try with 'roc_auc', f1'\n",
    "\n",
    "kfold = mds.StratifiedKFold(n_splits=num_folds, shuffle=True, random_state=2)\n",
    "\n",
    "for NA_strategy in sorted(datasets.keys()):\n",
    "    \n",
    "    results_by_strategy = []\n",
    "    \n",
    "    for model_name, model in models:\n",
    "        cv_results = mds.cross_val_score(model, datasets[NA_strategy][\"train\"], Y_train, cv=kfold, scoring=scoring)\n",
    "        results_by_strategy.append({\"name\": model_name, \"cv_results\": cv_results, \"mean\": cv_results.mean(), \"std\": cv_results.std()})\n",
    "        #print(\"%s: %f (%f)\" % (model_name, cv_results.mean(), cv_results.std()))\n",
    "        \n",
    "    # boxplot algorithm comparison\n",
    "    fig = plt.figure(figsize=(13, 5), dpi=500)\n",
    "    fig.suptitle('Algorithm Comparison using \\\"%s\\\"' % NA_strategy)\n",
    "    ax = fig.add_subplot(111)\n",
    "    plt.boxplot([x[\"cv_results\"] for x in results_by_strategy])\n",
    "    ax.set_xticklabels([x[\"name\"] for x in results_by_strategy])\n",
    "    plt.show()\n",
    "    \n",
    "    # order the models by the mean auc\n",
    "    results_by_strategy.sort(key=lambda x: x[\"mean\"], reverse=True)\n",
    "    print([(x[\"name\"], x[\"mean\"]) for x in results_by_strategy])\n",
    "    \n",
    "    results[NA_strategy] = results_by_strategy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results sorted by AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "results_sorted = [(na_method, algorithm[\"name\"], algorithm[\"mean\"]) for na_method in results for algorithm in results[na_method]]\n",
    "results_sorted.sort(key=lambda x: x[2], reverse=True)\n",
    "results_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plotSupervisedAlgorithmsDefault(inf, sup):\n",
    "    plt.figure(figsize=(13, 7), dpi=500)\n",
    "    \n",
    "    # x axis\n",
    "    labels = [na_method for na_method in results]\n",
    "    labels.sort()\n",
    "    plt.xticks(np.arange(len(labels)), labels, rotation='vertical')\n",
    "    plt.ylim(inf, sup)\n",
    "    \n",
    "    # legend:\n",
    "    algorithm_names = [x[\"name\"] for x in results[\"01-zero\"]] \n",
    "    \n",
    "    [plt.plot([[x[\"mean\"] for x in results[na_method] if x[\"name\"] == alg_name] for na_method in sorted(results)],\n",
    "              label = alg_name) for alg_name in algorithm_names]\n",
    "    \n",
    "    plt.ylabel('AUC')\n",
    "    plt.xlabel('NA-filling method')\n",
    "    \n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "    plt.show()\n",
    "    \n",
    "plotSupervisedAlgorithmsDefault(0.69, 1)\n",
    "plotSupervisedAlgorithmsDefault(0.9, 1)\n",
    "plotSupervisedAlgorithmsDefault(0.99, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Based on this plot, we decided to tune XGB and LDA and use 07-spec-mean and 09-spec-min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plotConfusionMatrixBestXGB():\n",
    "    kfold = mds.StratifiedKFold(n_splits=2, shuffle=True, random_state=2)\n",
    "    train, test = kfold.split(datasets[\"07-spec-mean\"][\"train\"], Y_train)\n",
    "\n",
    "    lol = xgb.XGBClassifier().fit(datasets[\"07-spec-mean\"][\"train\"].iloc[train[0]], Y_train[train[0]])\n",
    "\n",
    "    train1_pred = lol.predict(datasets[\"07-spec-mean\"][\"train\"].iloc[train[1]])\n",
    "\n",
    "    plot_confusion_matrix(confusion_matrix(Y_train[train[1]], train1_pred, labels = [0, 1]), classes = [0, 1])\n",
    "    \n",
    "plotConfusionMatrixBestXGB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plotConfusionMatrixBestLDA():\n",
    "    kfold = mds.StratifiedKFold(n_splits=2, shuffle=True, random_state=2)\n",
    "    train, test = kfold.split(datasets[\"09-spec-min\"][\"train\"], Y_train)\n",
    "\n",
    "    lol = xgb.XGBClassifier().fit(datasets[\"09-spec-min\"][\"train\"].iloc[train[0]], Y_train[train[0]])\n",
    "\n",
    "    train1_pred = lol.predict(datasets[\"09-spec-min\"][\"train\"].iloc[train[1]])\n",
    "\n",
    "    plot_confusion_matrix(confusion_matrix(Y_train[train[1]], train1_pred, labels = [0, 1]), classes = [0, 1])\n",
    "    \n",
    "plotConfusionMatrixBestLDA()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.1 - Tuning of the best models\n",
    "#### Based on this plot, we decided to tune LDA and XGB\n",
    "### Tuning XGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Adapted from https://www.analyticsvidhya.com/blog/2016/03/complete-guide-parameter-tuning-xgboost-with-codes-python/\n",
    "def modelfit(alg, train_predictors, train_target, useTrainCV=True, cv_folds=10, early_stopping_rounds=50):\n",
    "    \n",
    "    if useTrainCV:\n",
    "        xgb_param = alg.get_xgb_params()\n",
    "        xgtrain = xgb.DMatrix(train_predictors.values, label=train_target.values)\n",
    "        cvresult = xgb.cv(xgb_param, xgtrain, num_boost_round=alg.get_params()['n_estimators'], nfold=cv_folds,\n",
    "            metrics='auc', early_stopping_rounds=early_stopping_rounds, verbose_eval=True)\n",
    "        alg.set_params(n_estimators=cvresult.shape[0])\n",
    "    \n",
    "    #Fit the algorithm on the data\n",
    "    alg.fit(train_predictors, train_target, eval_metric='auc')\n",
    "        \n",
    "    #Predict training set:\n",
    "    dtrain_predictions = alg.predict(train_predictors)\n",
    "    dtrain_predprob = alg.predict_proba(train_predictors)[:,1]\n",
    "        \n",
    "    #Print model report:\n",
    "    print(\"\\nModel Report\")\n",
    "    print(\"Accuracy : %.4g\" % metrics.accuracy_score(train_target.values, dtrain_predictions))\n",
    "    print(\"AUC Score (Train): %f\" % metrics.roc_auc_score(train_target, dtrain_predprob))\n",
    "                    \n",
    "    #feat_imp = pd.Series(alg.booster().get_fscore()).sort_values(ascending=False)\n",
    "    #feat_imp.plot(kind='bar', title='Feature Importances')\n",
    "    #plt.ylabel('Feature Importance Score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics   #Additional scklearn functions\n",
    "from sklearn.model_selection import GridSearchCV   #Perforing grid search\n",
    "\n",
    "def tuneXGB1():\n",
    "    xgb1 = xgb.XGBClassifier(\n",
    "        learning_rate=0.1,\n",
    "        n_estimators=1000,\n",
    "        max_depth=5, # This should be between 3-10\n",
    "        min_child_weight=1, # A smaller value is chosen because it is a highly imbalanced class problem\n",
    "        gamma=0,\n",
    "        subsample=0.8, # Typical values range between 0.5-0.9.\n",
    "        colsample_bytree=0.8, # Typical values range between 0.5-0.9.\n",
    "        objective= 'binary:logistic',\n",
    "        #nthread=4,\n",
    "        scale_pos_weight=1, # Because of high class imbalance\n",
    "        seed=2)\n",
    "    \n",
    "    modelfit(xgb1, datasets[\"07-spec-mean\"][\"train\"], Y_train)\n",
    "    \n",
    "tuneXGB1()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This last result seems too good to be truth?!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def tuneXGB2():\n",
    "    param_test1 = {\n",
    "        'max_depth': np.arange(3,10,2),\n",
    "        'min_child_weight': np.arange(1,6,2)\n",
    "    }\n",
    "    \n",
    "    gsearch1 = GridSearchCV(estimator = xgb.XGBClassifier( learning_rate=0.1, n_estimators=156, max_depth=5,\n",
    "                                                      min_child_weight=1, gamma=0, subsample=0.8, colsample_bytree=0.8,\n",
    "                                                      objective= 'binary:logistic', scale_pos_weight=1, seed=2), \n",
    "                            param_grid = param_test1, scoring='roc_auc',iid=False, cv=10)\n",
    "    \n",
    "    gsearch1.fit(datasets[\"07-spec-mean\"][\"train\"], Y_train)\n",
    "    print(gsearch1.grid_scores_, gsearch1.best_params_, gsearch1.best_score_)\n",
    "    \n",
    "tuneXGB2()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### {'max_depth': 7, 'min_child_weight': 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def tuneXGB3():\n",
    "    param_test1 = {\n",
    "        'max_depth': [6,7,8],\n",
    "        'min_child_weight': [1,2,3]\n",
    "    }\n",
    "    \n",
    "    gsearch1 = GridSearchCV(estimator = xgb.XGBClassifier( learning_rate=0.1, n_estimators=156, max_depth=5,\n",
    "                                                      min_child_weight=1, gamma=0, subsample=0.8, colsample_bytree=0.8,\n",
    "                                                      objective= 'binary:logistic', scale_pos_weight=1, seed=2), \n",
    "                            param_grid = param_test1, scoring='roc_auc',iid=False, cv=10)\n",
    "    \n",
    "    gsearch1.fit(datasets[\"07-spec-mean\"][\"train\"], Y_train)\n",
    "    print(gsearch1.grid_scores_, gsearch1.best_params_, gsearch1.best_score_)\n",
    "    \n",
    "tuneXGB3()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def tuneXGB4():\n",
    "    param_test1 = {\n",
    "        'gamma':[i/10.0 for i in np.arange(0,5)]\n",
    "    }\n",
    "    \n",
    "    gsearch1 = GridSearchCV(estimator = xgb.XGBClassifier( learning_rate=0.1, n_estimators=156, max_depth=7,\n",
    "                                                      min_child_weight=1, gamma=0, subsample=0.8, colsample_bytree=0.8,\n",
    "                                                      objective= 'binary:logistic', scale_pos_weight=1, seed=2), \n",
    "                            param_grid = param_test1, scoring='roc_auc',iid=False, cv=10)\n",
    "    \n",
    "    gsearch1.fit(datasets[\"07-spec-mean\"][\"train\"], Y_train)\n",
    "    print(gsearch1.grid_scores_, gsearch1.best_params_, gsearch1.best_score_)\n",
    "    \n",
    "tuneXGB4()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### gamma = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def tuneXGB5():\n",
    "    xgb1 = xgb.XGBClassifier(\n",
    "        learning_rate=0.1,\n",
    "        n_estimators=1000,\n",
    "        max_depth=7, # This should be between 3-10\n",
    "        min_child_weight=1, # A smaller value is chosen because it is a highly imbalanced class problem\n",
    "        gamma=0,\n",
    "        subsample=0.8, # Typical values range between 0.5-0.9.\n",
    "        colsample_bytree=0.8, # Typical values range between 0.5-0.9.\n",
    "        objective= 'binary:logistic',\n",
    "        #nthread=4,\n",
    "        scale_pos_weight=1, # Because of high class imbalance\n",
    "        seed=2)\n",
    "    \n",
    "    modelfit(xgb1, datasets[\"07-spec-mean\"][\"train\"], Y_train)\n",
    "    \n",
    "tuneXGB5()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def tuneXGB6():\n",
    "    param_test1 = {\n",
    "     'subsample': np.arange(0.6, 1.0, 0.1),\n",
    "     'colsample_bytree': np.arange(0.6, 1.0, 0.1)\n",
    "    }\n",
    "    \n",
    "    gsearch1 = GridSearchCV(estimator = xgb.XGBClassifier( learning_rate=0.1, n_estimators=156, max_depth=7,\n",
    "                                                      min_child_weight=1, gamma=0, subsample=0.8, colsample_bytree=0.8,\n",
    "                                                      objective= 'binary:logistic', scale_pos_weight=1, seed=2), \n",
    "                            param_grid = param_test1, scoring='roc_auc',iid=False, cv=10)\n",
    "    \n",
    "    gsearch1.fit(datasets[\"07-spec-mean\"][\"train\"], Y_train)\n",
    "    print(gsearch1.grid_scores_, gsearch1.best_params_, gsearch1.best_score_)\n",
    "    \n",
    "tuneXGB6()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### subsample = 0.6 and colsample_bytree = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def tuneXGB7():\n",
    "    param_test1 = {\n",
    "     'subsample': np.arange(0.55, 0.7, 0.05),\n",
    "     'colsample_bytree': np.arange(0.85, 1.0, 0.05)\n",
    "    }\n",
    "    \n",
    "    gsearch1 = GridSearchCV(estimator = xgb.XGBClassifier( learning_rate=0.1, n_estimators=156, max_depth=7,\n",
    "                                                      min_child_weight=1, gamma=0, subsample=0.8, colsample_bytree=0.8,\n",
    "                                                      objective= 'binary:logistic', scale_pos_weight=1, seed=2), \n",
    "                            param_grid = param_test1, scoring='roc_auc',iid=False, cv=10)\n",
    "    \n",
    "    gsearch1.fit(datasets[\"07-spec-mean\"][\"train\"], Y_train)\n",
    "    print(gsearch1.grid_scores_, gsearch1.best_params_, gsearch1.best_score_)\n",
    "    \n",
    "tuneXGB7()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### better tuned: subsample=0.55 and colsample_bytree=0.85"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def tuneXGB8():\n",
    "    param_test1 = {\n",
    "     'reg_alpha':[1e-5, 1e-2, 0.1, 1, 100]\n",
    "    }\n",
    "    \n",
    "    gsearch1 = GridSearchCV(estimator = xgb.XGBClassifier( learning_rate=0.1, n_estimators=156, max_depth=7,\n",
    "                                                      min_child_weight=1, gamma=0, subsample=0.55, colsample_bytree=0.85,\n",
    "                                                      objective= 'binary:logistic', scale_pos_weight=1, seed=2), \n",
    "                            param_grid = param_test1, scoring='roc_auc',iid=False, cv=10)\n",
    "    \n",
    "    gsearch1.fit(datasets[\"07-spec-mean\"][\"train\"], Y_train)\n",
    "    print(gsearch1.grid_scores_, gsearch1.best_params_, gsearch1.best_score_)\n",
    "    \n",
    "tuneXGB8()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reg alpha = 1e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def tuneXGB9():    \n",
    "    xgb1 = xgb.XGBClassifier( learning_rate=0.01, n_estimators=5000, max_depth=7,\n",
    "                      min_child_weight=1, gamma=0, subsample=0.55, colsample_bytree=0.85,\n",
    "                      reg_alpha=1e-5, objective= 'binary:logistic', scale_pos_weight=1, seed=2)\n",
    "    \n",
    "    modelfit(xgb1, datasets[\"07-spec-mean\"][\"train\"], Y_train)\n",
    "    \n",
    "tuneXGB9()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def tuneLDA():\n",
    "    param_test1 = [{\"solver\": [\"svd\"], \"n_components\": np.arange(1,len(X_train.columns) - 1)},\n",
    "                   {\"solver\": [\"lsqr\", \"eigen\"], \"n_components\": np.arange(1,len(X_train.columns) - 1), \"shrinkage\": [\"auto\"]}]\n",
    "        \n",
    "    gsearch1 = GridSearchCV(estimator=LinearDiscriminantAnalysis(), \n",
    "                            param_grid = param_test1, scoring='roc_auc', cv=10)\n",
    "    \n",
    "    fit = gsearch1.fit(datasets[\"09-spec-min\"][\"train\"], Y_train)\n",
    "    return(fit)\n",
    "    \n",
    "bestLDAfit = tuneLDA()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bestLDAfit.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bestLDAfit.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def evaluatingBestLDA():\n",
    "    kfold = mds.StratifiedKFold(n_splits=num_folds, shuffle=True, random_state=2)\n",
    "    model = LinearDiscriminantAnalysis(n_components = 1, shrinkage = \"auto\", solver=\"lsqr\")\n",
    "    \n",
    "    cv_results = mds.cross_val_score(model, datasets[\"09-spec-min\"][\"train\"], Y_train, cv=kfold, scoring=\"roc_auc\")\n",
    "    print(cv_results.mean())\n",
    "    \n",
    "evaluatingBestLDA()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 - Unsupervised Anomaly Detection Methods\n",
    "We decided to try LOF and see how it goes. We used our implementation from HW1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import lof_pal as lof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def makePredictonsLOF():\n",
    "    outliers = []\n",
    "    \n",
    "    kfold = mds.StratifiedKFold(n_splits=2, shuffle=True, random_state=2)\n",
    "    sets,_ = kfold.split(datasets[\"07-spec-mean\"][\"train\"], Y_train)                                      \n",
    "    \n",
    "    # Train with only positive examples:\n",
    "    l = lof.LOF(datasets[\"07-spec-mean\"][\"train\"].iloc[sets[0]][Y_train[sets[0]] != 1], 3)\n",
    "    \n",
    "    Y_pred = [1 if x > 1.2 else 0 for x in l.predict(datasets[\"07-spec-mean\"][\"train\"].iloc[sets[1]])]\n",
    "        \n",
    "    plot_confusion_matrix(confusion_matrix(Y_train[sets[1]], Y_pred, labels = [0, 1]), classes = [0, 1])\n",
    "    #return Y_pred\n",
    "        \n",
    "    \n",
    "makePredictonsLOF()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 - Submission to Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# choose algorithm\n",
    "def makeSubmissionKaggle(NA_strategy, algorithm):\n",
    "    print(\"Submiting using \\\"%s\\\"\" % (NA_strategy))\n",
    "\n",
    "    algorithm.fit(datasets[NA_strategy][\"train\"], Y_train)\n",
    "    Y_pred = algorithm.predict(datasets[NA_strategy][\"test\"])\n",
    "    Y_pred = Y_pred.astype(int)\n",
    "\n",
    "    # save data to CSV\n",
    "    saveDataToCSV(Y_pred)\n",
    "    \n",
    "#makeSubmissionKaggle(\"07-spec-mean\", xgb.XGBClassifier( learning_rate=0.01, n_estimators=5000, max_depth=7,\n",
    "#                      min_child_weight=1, gamma=0, subsample=0.55, colsample_bytree=0.85,\n",
    "#                      reg_alpha=1e-5, objective= 'binary:logistic', scale_pos_weight=1, seed=2))\n",
    "\n",
    "#makeSubmissionKaggle(\"09-spec-min\", LinearDiscriminantAnalysis(n_components = 1, shrinkage = \"auto\", solver=\"lsqr\"))\n",
    "makeSubmissionKaggle(\"10-spec-max\", AdaBoostClassifier())"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
