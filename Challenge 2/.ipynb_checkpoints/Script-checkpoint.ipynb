{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Anomaly Detection Challenge 1\n",
    "## Miguel Sandim and Paula Fortuna"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 - Data Reading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "b'Skipping line 19: expected 10 fields, saw 11\\nSkipping line 28: expected 10 fields, saw 11\\nSkipping line 41: expected 10 fields, saw 11\\nSkipping line 47: expected 10 fields, saw 11\\nSkipping line 69: expected 10 fields, saw 11\\nSkipping line 70: expected 10 fields, saw 11\\nSkipping line 71: expected 10 fields, saw 12\\nSkipping line 128: expected 10 fields, saw 11\\nSkipping line 140: expected 10 fields, saw 11\\nSkipping line 143: expected 10 fields, saw 11\\nSkipping line 150: expected 10 fields, saw 11\\nSkipping line 158: expected 10 fields, saw 11\\nSkipping line 164: expected 10 fields, saw 11\\nSkipping line 200: expected 10 fields, saw 11\\nSkipping line 206: expected 10 fields, saw 11\\nSkipping line 218: expected 10 fields, saw 11\\nSkipping line 223: expected 10 fields, saw 11\\nSkipping line 234: expected 10 fields, saw 11\\nSkipping line 235: expected 10 fields, saw 11\\nSkipping line 236: expected 10 fields, saw 11\\nSkipping line 273: expected 10 fields, saw 11\\nSkipping line 276: expected 10 fields, saw 11\\nSkipping line 282: expected 10 fields, saw 11\\nSkipping line 292: expected 10 fields, saw 11\\nSkipping line 300: expected 10 fields, saw 11\\nSkipping line 327: expected 10 fields, saw 11\\nSkipping line 345: expected 10 fields, saw 11\\nSkipping line 349: expected 10 fields, saw 18\\nSkipping line 352: expected 10 fields, saw 11\\nSkipping line 355: expected 10 fields, saw 11\\nSkipping line 375: expected 10 fields, saw 11\\nSkipping line 387: expected 10 fields, saw 11\\nSkipping line 416: expected 10 fields, saw 11\\nSkipping line 423: expected 10 fields, saw 14\\nSkipping line 429: expected 10 fields, saw 11\\nSkipping line 434: expected 10 fields, saw 12\\nSkipping line 439: expected 10 fields, saw 11\\nSkipping line 447: expected 10 fields, saw 11\\nSkipping line 458: expected 10 fields, saw 11\\nSkipping line 459: expected 10 fields, saw 11\\nSkipping line 465: expected 10 fields, saw 11\\nSkipping line 487: expected 10 fields, saw 11\\nSkipping line 492: expected 10 fields, saw 11\\nSkipping line 495: expected 10 fields, saw 11\\nSkipping line 498: expected 10 fields, saw 11\\nSkipping line 500: expected 10 fields, saw 11\\nSkipping line 509: expected 10 fields, saw 12\\nSkipping line 537: expected 10 fields, saw 12\\nSkipping line 547: expected 10 fields, saw 11\\nSkipping line 557: expected 10 fields, saw 11\\nSkipping line 574: expected 10 fields, saw 13\\nSkipping line 589: expected 10 fields, saw 11\\nSkipping line 592: expected 10 fields, saw 11\\nSkipping line 597: expected 10 fields, saw 11\\nSkipping line 606: expected 10 fields, saw 11\\nSkipping line 607: expected 10 fields, saw 11\\nSkipping line 653: expected 10 fields, saw 11\\nSkipping line 654: expected 10 fields, saw 12\\nSkipping line 670: expected 10 fields, saw 11\\nSkipping line 678: expected 10 fields, saw 11\\nSkipping line 750: expected 10 fields, saw 11\\nSkipping line 784: expected 10 fields, saw 11\\nSkipping line 809: expected 10 fields, saw 11\\nSkipping line 819: expected 10 fields, saw 11\\nSkipping line 825: expected 10 fields, saw 11\\nSkipping line 835: expected 10 fields, saw 13\\nSkipping line 839: expected 10 fields, saw 11\\nSkipping line 873: expected 10 fields, saw 11\\nSkipping line 876: expected 10 fields, saw 11\\nSkipping line 901: expected 10 fields, saw 11\\nSkipping line 902: expected 10 fields, saw 11\\nSkipping line 904: expected 10 fields, saw 11\\nSkipping line 933: expected 10 fields, saw 11\\nSkipping line 974: expected 10 fields, saw 11\\nSkipping line 1006: expected 10 fields, saw 11\\nSkipping line 1010: expected 10 fields, saw 11\\nSkipping line 1014: expected 10 fields, saw 11\\nSkipping line 1022: expected 10 fields, saw 11\\nSkipping line 1023: expected 10 fields, saw 12\\nSkipping line 1030: expected 10 fields, saw 11\\nSkipping line 1038: expected 10 fields, saw 18\\nSkipping line 1062: expected 10 fields, saw 11\\nSkipping line 1088: expected 10 fields, saw 12\\nSkipping line 1100: expected 10 fields, saw 11\\nSkipping line 1105: expected 10 fields, saw 11\\nSkipping line 1178: expected 10 fields, saw 12\\nSkipping line 1217: expected 10 fields, saw 11\\nSkipping line 1235: expected 10 fields, saw 11\\nSkipping line 1238: expected 10 fields, saw 11\\nSkipping line 1240: expected 10 fields, saw 11\\nSkipping line 1244: expected 10 fields, saw 11\\nSkipping line 1253: expected 10 fields, saw 12\\nSkipping line 1271: expected 10 fields, saw 11\\nSkipping line 1291: expected 10 fields, saw 11\\nSkipping line 1292: expected 10 fields, saw 11\\nSkipping line 1304: expected 10 fields, saw 11\\nSkipping line 1328: expected 10 fields, saw 11\\nSkipping line 1333: expected 10 fields, saw 11\\nSkipping line 1340: expected 10 fields, saw 11\\nSkipping line 1378: expected 10 fields, saw 11\\nSkipping line 1388: expected 10 fields, saw 11\\nSkipping line 1399: expected 10 fields, saw 11\\nSkipping line 1407: expected 10 fields, saw 11\\nSkipping line 1416: expected 10 fields, saw 11\\nSkipping line 1449: expected 10 fields, saw 11\\nSkipping line 1461: expected 10 fields, saw 11\\nSkipping line 1468: expected 10 fields, saw 12\\nSkipping line 1477: expected 10 fields, saw 13\\nSkipping line 1479: expected 10 fields, saw 11\\nSkipping line 1497: expected 10 fields, saw 11\\nSkipping line 1521: expected 10 fields, saw 12\\nSkipping line 1525: expected 10 fields, saw 11\\nSkipping line 1532: expected 10 fields, saw 11\\nSkipping line 1548: expected 10 fields, saw 11\\nSkipping line 1572: expected 10 fields, saw 11\\nSkipping line 1573: expected 10 fields, saw 12\\nSkipping line 1587: expected 10 fields, saw 11\\nSkipping line 1588: expected 10 fields, saw 11\\nSkipping line 1591: expected 10 fields, saw 11\\nSkipping line 1595: expected 10 fields, saw 11\\nSkipping line 1596: expected 10 fields, saw 11\\nSkipping line 1608: expected 10 fields, saw 11\\nSkipping line 1609: expected 10 fields, saw 13\\nSkipping line 1611: expected 10 fields, saw 11\\nSkipping line 1616: expected 10 fields, saw 11\\nSkipping line 1647: expected 10 fields, saw 13\\nSkipping line 1648: expected 10 fields, saw 11\\nSkipping line 1657: expected 10 fields, saw 11\\nSkipping line 1682: expected 10 fields, saw 11\\nSkipping line 1687: expected 10 fields, saw 11\\nSkipping line 1691: expected 10 fields, saw 11\\nSkipping line 1697: expected 10 fields, saw 11\\nSkipping line 1709: expected 10 fields, saw 11\\nSkipping line 1715: expected 10 fields, saw 12\\nSkipping line 1727: expected 10 fields, saw 11\\nSkipping line 1729: expected 10 fields, saw 11\\nSkipping line 1746: expected 10 fields, saw 11\\nSkipping line 1755: expected 10 fields, saw 11\\nSkipping line 1787: expected 10 fields, saw 11\\nSkipping line 1883: expected 10 fields, saw 11\\nSkipping line 1888: expected 10 fields, saw 11\\nSkipping line 1904: expected 10 fields, saw 11\\nSkipping line 1909: expected 10 fields, saw 11\\nSkipping line 1914: expected 10 fields, saw 12\\nSkipping line 1916: expected 10 fields, saw 11\\nSkipping line 1929: expected 10 fields, saw 16\\nSkipping line 1968: expected 10 fields, saw 11\\nSkipping line 1976: expected 10 fields, saw 11\\nSkipping line 1990: expected 10 fields, saw 17\\nSkipping line 1995: expected 10 fields, saw 11\\nSkipping line 1999: expected 10 fields, saw 11\\nSkipping line 2015: expected 10 fields, saw 11\\nSkipping line 2019: expected 10 fields, saw 11\\nSkipping line 2023: expected 10 fields, saw 11\\nSkipping line 2025: expected 10 fields, saw 11\\nSkipping line 2032: expected 10 fields, saw 11\\nSkipping line 2037: expected 10 fields, saw 16\\nSkipping line 2049: expected 10 fields, saw 13\\nSkipping line 2055: expected 10 fields, saw 11\\nSkipping line 2058: expected 10 fields, saw 11\\nSkipping line 2059: expected 10 fields, saw 11\\nSkipping line 2062: expected 10 fields, saw 11\\nSkipping line 2067: expected 10 fields, saw 12\\nSkipping line 2077: expected 10 fields, saw 11\\nSkipping line 2104: expected 10 fields, saw 13\\nSkipping line 2105: expected 10 fields, saw 11\\nSkipping line 2116: expected 10 fields, saw 11\\nSkipping line 2126: expected 10 fields, saw 11\\nSkipping line 2138: expected 10 fields, saw 11\\nSkipping line 2160: expected 10 fields, saw 13\\nSkipping line 2166: expected 10 fields, saw 13\\nSkipping line 2196: expected 10 fields, saw 11\\nSkipping line 2202: expected 10 fields, saw 12\\nSkipping line 2214: expected 10 fields, saw 11\\nSkipping line 2218: expected 10 fields, saw 11\\nSkipping line 2235: expected 10 fields, saw 11\\nSkipping line 2237: expected 10 fields, saw 12\\nSkipping line 2275: expected 10 fields, saw 11\\nSkipping line 2287: expected 10 fields, saw 11\\nSkipping line 2297: expected 10 fields, saw 11\\nSkipping line 2299: expected 10 fields, saw 12\\nSkipping line 2301: expected 10 fields, saw 11\\nSkipping line 2332: expected 10 fields, saw 11\\nSkipping line 2335: expected 10 fields, saw 12\\nSkipping line 2342: expected 10 fields, saw 11\\nSkipping line 2370: expected 10 fields, saw 11\\nSkipping line 2378: expected 10 fields, saw 11\\nSkipping line 2398: expected 10 fields, saw 11\\nSkipping line 2423: expected 10 fields, saw 12\\nSkipping line 2425: expected 10 fields, saw 11\\nSkipping line 2443: expected 10 fields, saw 11\\nSkipping line 2484: expected 10 fields, saw 11\\nSkipping line 2494: expected 10 fields, saw 11\\nSkipping line 2512: expected 10 fields, saw 11\\nSkipping line 2546: expected 10 fields, saw 11\\nSkipping line 2553: expected 10 fields, saw 11\\nSkipping line 2575: expected 10 fields, saw 11\\nSkipping line 2606: expected 10 fields, saw 11\\nSkipping line 2629: expected 10 fields, saw 11\\nSkipping line 2704: expected 10 fields, saw 11\\nSkipping line 2717: expected 10 fields, saw 11\\nSkipping line 2754: expected 10 fields, saw 11\\nSkipping line 2780: expected 10 fields, saw 11\\nSkipping line 2806: expected 10 fields, saw 11\\nSkipping line 2839: expected 10 fields, saw 11\\nSkipping line 2842: expected 10 fields, saw 12\\nSkipping line 2846: expected 10 fields, saw 11\\nSkipping line 2862: expected 10 fields, saw 11\\nSkipping line 2863: expected 10 fields, saw 11\\nSkipping line 2874: expected 10 fields, saw 11\\nSkipping line 2875: expected 10 fields, saw 11\\nSkipping line 2889: expected 10 fields, saw 11\\n'\n"
     ]
    }
   ],
   "source": [
    "# pandas\n",
    "import pandas as pd\n",
    "from pandas import Series,DataFrame\n",
    "\n",
    "# numpy, matplotlib, seaborn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "# Random libraries and seeds:\n",
    "import random\n",
    "random.seed(2)\n",
    "np.random.seed(2)\n",
    "\n",
    "# read from csv\n",
    "\n",
    "train_df = pd.read_csv(\"data/yelp_data_train.dat\", sep = ';', encoding = 'utf-8')\n",
    "#test_df = pd.read_csv(\"data/yelp_data_test.dat\")\n",
    "#reviewers_df = pd.read_csv(\"data/yelp_data_reviewer.dat\")\n",
    "#hotels_df = pd.read_csv(\"data/yelp_data_hotel.dat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_df.iloc[:,36].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "479/(3956 + 479)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## About 10% of our dataset are anomalous cases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Global Variables "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Y_train = train_df[len(train_df.columns)-1]\n",
    "X_train = train_df.drop(len(train_df.columns)-1,axis=1)\n",
    "num_rows_X_train = X_train[0].count()\n",
    "num_columns_X_train = len(X_train.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utils Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# From: http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\n",
    "import itertools\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "######################################\n",
    "# Function Save Data To CSV\n",
    "######################################\n",
    "\n",
    "def saveDataToCSV(Y_pred):\n",
    "    id_list = range(1, len(Y_pred)+1)\n",
    "    submission = pd.DataFrame({\n",
    "        \"Id\": id_list,\n",
    "        \"Expected\": Y_pred\n",
    "    })\n",
    "    submission = submission[['Id', 'Expected']]\n",
    "    submission.to_csv('submission.csv', index=False)\n",
    "    return\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 - Data Pre-Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 - Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n",
    "import numpy.ma as ma\n",
    "import math\n",
    "\n",
    "######################################\n",
    "# Strategies based on constants\n",
    "######################################\n",
    "\n",
    "#replace by zero - black colour in RGB\n",
    "def replaceByZero(df):\n",
    "    return np.nan_to_num(df)\n",
    "\n",
    "#replace by 255 - white colour in RGB\n",
    "def replaceBy255(df):\n",
    "    return df.fillna(255)\n",
    "\n",
    "#####################################\n",
    "# Strategies based on columns values\n",
    "#####################################\n",
    "\n",
    "#column minimum\n",
    "def replaceByColumnMinimum(df):\n",
    "    return df.fillna(df.min())\n",
    "\n",
    "#column maximum\n",
    "def replaceByColumnMaximum(df):\n",
    "    return df.fillna(df.max())\n",
    "\n",
    "#column mean\n",
    "def replaceByColumnMean(df):\n",
    "    return df.fillna(df.mean())\n",
    "\n",
    "#column median\n",
    "def replaceByColumnMedian(df):\n",
    "    return df.fillna(df.median())\n",
    "\n",
    "#####################################\n",
    "# Strategies based on rows values\n",
    "#####################################\n",
    "\n",
    "# in the analysis of the rows we have to take into account that each four consecutive rows describe a pixel.\n",
    "# Each of these four rows stands for: Red, Green, IR, IR. |R|G|IR1|IR2|\n",
    "# These values refer to different things, and therefore are analysed independently.\n",
    "# this will allow to consider more the specificities of the problem\n",
    "\n",
    "# divide the data into four datasets, corresponding to each type of values \n",
    "\n",
    "#general function to gather columns for each type |R|G|IR1|IR2| using the mod operator\n",
    "def separatePixelColumns(position, df):\n",
    "    indexes = range(0, num_columns_X_train-1)\n",
    "    indexes = [x for x in indexes if x % 4 == position]\n",
    "    df_p_attribute = df.iloc[:,indexes]\n",
    "    return df_p_attribute\n",
    "\n",
    "#general function to fill missing values based on the rows\n",
    "#Note that does not make sense to consider the four values |R|G|IR1|IR2|, because they refer to different properties\n",
    "def fillMissingValuesByRow(df, function):\n",
    "    for index, row in df.iterrows():\n",
    "        value_without_nan = function(row)\n",
    "        nan_positions = row.isnull()\n",
    "        row[nan_positions] = value_without_nan\n",
    "    return df\n",
    "\n",
    "#row spectral mean\n",
    "def replaceByRowMean(df):\n",
    "    return fillMissingValuesByRow(df, np.nanmean)\n",
    "\n",
    "#row spectral median\n",
    "def replaceByRowMedian(df):\n",
    "    return fillMissingValuesByRow(df, np.nanmedian)\n",
    "\n",
    "#row spectral minimum\n",
    "def replaceByRowMinimum(df):\n",
    "    return fillMissingValuesByRow(df, np.nanmin)\n",
    "\n",
    "#row spectral maximum\n",
    "def replaceByRowMaximum(df):\n",
    "    return fillMissingValuesByRow(df, np.nanmax)\n",
    "\n",
    "########################################\n",
    "# Strategies based on data distribution\n",
    "########################################\n",
    "\n",
    "#consider the distribution of the spectral values of each type. \n",
    "#Get random value from the spectral values of same type\n",
    "\n",
    "    \n",
    "def getRandomNumberFromDataframe(df):\n",
    "    while True:\n",
    "        row = df.sample(1, random_state = 2)\n",
    "        values = row.values[0]\n",
    "        value = random.choice(values)\n",
    "        if not math.isnan(value):\n",
    "            break\n",
    "    return value\n",
    "        \n",
    "def fillMissingValuesWithDistribution(df):\n",
    "    for index, row in df.iterrows():\n",
    "        nan_positions = row.isnull()\n",
    "        for i in range(len(nan_positions)): \n",
    "            if nan_positions.iloc[i] == True:\n",
    "                value = getRandomNumberFromDataframe(df)\n",
    "                row.iloc[i] = value\n",
    "    return df\n",
    "\n",
    "#########################################%%%\n",
    "# fill Missing Values Considering Spectral\n",
    "#########################################%%%\n",
    "\n",
    "def fillMissingValuesBySpectral(df, function):\n",
    "\n",
    "    #generate four new datasets with the columns of each type\n",
    "    df_p_attribute_R = separatePixelColumns(0, df)\n",
    "    df_p_attribute_G = separatePixelColumns(1, df)\n",
    "    df_p_attribute_IR1 = separatePixelColumns(2, df)\n",
    "    df_p_attribute_IR2 = separatePixelColumns(3, df)\n",
    "\n",
    "    #apply function to each of the 4 datasets\n",
    "    df_p_attribute_R = function(df_p_attribute_R)\n",
    "    df_p_attribute_G = function(df_p_attribute_G)\n",
    "    df_p_attribute_IR1 = function(df_p_attribute_IR1)\n",
    "    df_p_attribute_IR2 = function(df_p_attribute_IR2)\n",
    "\n",
    "    df = pd.concat(\n",
    "                        [df_p_attribute_R, \n",
    "                         df_p_attribute_G,\n",
    "                         df_p_attribute_IR1,\n",
    "                         df_p_attribute_IR2], \n",
    "                        axis=1\n",
    "                        )\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#######################\n",
    "#   CHAMADAS\n",
    "#######################\n",
    "\n",
    "#X_train = replaceByZero(X_train)\n",
    "#test_df = replaceByZero(test_df)\n",
    "\n",
    "#X_train = replaceBy255(X_train)\n",
    "#test_df = replaceBy255(test_df)\n",
    "\n",
    "#X_train = replaceByColumnMinimum(X_train)\n",
    "#test_df = replaceByColumnMinimum(test_df)\n",
    "\n",
    "#X_train = replaceByColumnMaximum(X_train)\n",
    "#test_df = replaceByColumnMaximum(test_df)\n",
    "\n",
    "#X_train = replaceByColumnMean(X_train)\n",
    "#test_df = replaceByColumnMean(test_df)\n",
    "\n",
    "#X_train = replaceByColumnMedian(X_train)\n",
    "#test_df = replaceByColumnMedian(test_df)\n",
    "\n",
    "#X_train = fillMissingValuesBySpectral(X_train, replaceByRowMean)\n",
    "#test_df = fillMissingValuesBySpectral(test_df, replaceByRowMean)\n",
    "\n",
    "#X_train = fillMissingValuesBySpectral(X_train, replaceByRowMedian)\n",
    "#test_df = fillMissingValuesBySpectral(test_df, replaceByRowMedian)\n",
    "\n",
    "#X_train = fillMissingValuesBySpectral(X_train, replaceByRowMinimum)\n",
    "#test_df = fillMissingValuesBySpectral(test_df, replaceByRowMinimum)\n",
    "\n",
    "#X_train = fillMissingValuesBySpectral(X_train, replaceByRowMaximum)\n",
    "#test_df = fillMissingValuesBySpectral(test_df, replaceByRowMaximum)\n",
    "\n",
    "#X_train = fillMissingValuesBySpectral(X_train, fillMissingValuesWithDistribution)\n",
    "#test_df = fillMissingValuesBySpectral(test_df, fillMissingValuesWithDistribution)\n",
    "\n",
    "datasets = {f_name: {\"train\": f(X_train.copy()), \"test\": f(test_df.copy())} for f_name, f in [\n",
    "        (\"01-zero\", replaceByZero),\n",
    "        (\"02-255\", replaceBy255),\n",
    "        (\"03-col-min\", replaceByColumnMinimum),\n",
    "        (\"04-col-max\", replaceByColumnMaximum),\n",
    "        (\"05-col-mean\", replaceByColumnMean),\n",
    "        (\"06-col-median\", replaceByColumnMedian),\n",
    "        (\"07-spec-mean\", lambda data: fillMissingValuesBySpectral(data, replaceByRowMean)),\n",
    "        (\"08-spec-median\", lambda data: fillMissingValuesBySpectral(data, replaceByRowMedian)),\n",
    "        (\"09-spec-min\", lambda data: fillMissingValuesBySpectral(data, replaceByRowMinimum)),\n",
    "        (\"10-spec-max\", lambda data: fillMissingValuesBySpectral(data, replaceByRowMaximum)),\n",
    "        (\"11-spec-dis\", lambda data: fillMissingValuesBySpectral(data, fillMissingValuesWithDistribution))\n",
    "    ]}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Normalization\n",
    "\n",
    "There is no need for normalization in this dataset, since all features are between 0 and 255."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 - Model Selection\n",
    "\n",
    "- First goal: discover which type of analyses works better\n",
    "- Second Goal: tune the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 - Model selection based on which models do best in CV using default settings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#inspired in http://machinelearningmastery.com/compare-machine-learning-algorithms-python-scikit-learn/\n",
    "\n",
    "import sklearn.model_selection as mds\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "import xgboost as xgb\n",
    "\n",
    "# prepare data\n",
    "\n",
    "#Y_train = train_df[:,-1]\n",
    "#X_train = train_df[:,:-1]\n",
    "\n",
    "#Y_train = train_df[len(train_df.columns)-1]\n",
    "#X_train = train_df.drop(len(train_df.columns)-1,axis=1)\n",
    "\n",
    "# prepare configuration for cross validation test harness\n",
    "num_folds = 10\n",
    "num_instances = len(X_train)\n",
    "\n",
    "# prepare models\n",
    "models = []\n",
    "models.append(('LR', LogisticRegression()))\n",
    "models.append(('LDA', LinearDiscriminantAnalysis()))\n",
    "models.append(('KNN', KNeighborsClassifier()))\n",
    "models.append(('CART', DecisionTreeClassifier()))\n",
    "models.append(('NB', GaussianNB()))\n",
    "#models.append(('SVM-Linear', SVC(kernel=\"linear\")))\n",
    "models.append(('SVM-Poly', SVC(kernel=\"poly\")))\n",
    "models.append(('SVM-RBF', SVC(kernel=\"rbf\")))\n",
    "models.append(('NN', MLPClassifier(alpha=1))) \n",
    "models.append(('RF', RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1)))\n",
    "models.append(('AB', AdaBoostClassifier()))\n",
    "models.append(('XGB', xgb.XGBClassifier()))\n",
    "\n",
    "# evaluate each model in turn\n",
    "results = {}\n",
    "scoring = 'roc_auc' # try with 'roc_auc', f1'\n",
    "\n",
    "kfold = mds.StratifiedKFold(n_splits=num_folds, shuffle=True, random_state=2)\n",
    "\n",
    "for NA_strategy in sorted(datasets.keys()):\n",
    "    \n",
    "    results_by_strategy = []\n",
    "    \n",
    "    for model_name, model in models:\n",
    "        cv_results = mds.cross_val_score(model, datasets[NA_strategy][\"train\"], Y_train, cv=kfold, scoring=scoring)\n",
    "        results_by_strategy.append({\"name\": model_name, \"cv_results\": cv_results, \"mean\": cv_results.mean(), \"std\": cv_results.std()})\n",
    "        #print(\"%s: %f (%f)\" % (model_name, cv_results.mean(), cv_results.std()))\n",
    "        \n",
    "    # boxplot algorithm comparison\n",
    "    fig = plt.figure(figsize=(13, 5), dpi=500)\n",
    "    fig.suptitle('Algorithm Comparison using \\\"%s\\\"' % NA_strategy)\n",
    "    ax = fig.add_subplot(111)\n",
    "    plt.boxplot([x[\"cv_results\"] for x in results_by_strategy])\n",
    "    ax.set_xticklabels([x[\"name\"] for x in results_by_strategy])\n",
    "    plt.show()\n",
    "    \n",
    "    # order the models by the mean auc\n",
    "    results_by_strategy.sort(key=lambda x: x[\"mean\"], reverse=True)\n",
    "    print([(x[\"name\"], x[\"mean\"]) for x in results_by_strategy])\n",
    "    \n",
    "    results[NA_strategy] = results_by_strategy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results sorted by AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "results_sorted = [(na_method, algorithm[\"name\"], algorithm[\"mean\"]) for na_method in results for algorithm in results[na_method]]\n",
    "results_sorted.sort(key=lambda x: x[2], reverse=True)\n",
    "results_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plotSupervisedAlgorithmsDefault(inf, sup):\n",
    "    plt.figure(figsize=(13, 7), dpi=500)\n",
    "    \n",
    "    # x axis\n",
    "    labels = [na_method for na_method in results]\n",
    "    labels.sort()\n",
    "    plt.xticks(np.arange(len(labels)), labels, rotation='vertical')\n",
    "    plt.ylim(inf, sup)\n",
    "    \n",
    "    # legend:\n",
    "    algorithm_names = [x[\"name\"] for x in results[\"01-zero\"]] \n",
    "    \n",
    "    [plt.plot([[x[\"mean\"] for x in results[na_method] if x[\"name\"] == alg_name] for na_method in sorted(results)],\n",
    "              label = alg_name) for alg_name in algorithm_names]\n",
    "    \n",
    "    plt.ylabel('AUC')\n",
    "    plt.xlabel('NA-filling method')\n",
    "    \n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "    plt.show()\n",
    "    \n",
    "plotSupervisedAlgorithmsDefault(0.69, 1)\n",
    "plotSupervisedAlgorithmsDefault(0.9, 1)\n",
    "plotSupervisedAlgorithmsDefault(0.99, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Based on this plot, we decided to tune XGB and LDA and use 07-spec-mean and 09-spec-min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plotConfusionMatrixBestXGB():\n",
    "    kfold = mds.StratifiedKFold(n_splits=2, shuffle=True, random_state=2)\n",
    "    train, test = kfold.split(datasets[\"07-spec-mean\"][\"train\"], Y_train)\n",
    "\n",
    "    lol = xgb.XGBClassifier().fit(datasets[\"07-spec-mean\"][\"train\"].iloc[train[0]], Y_train[train[0]])\n",
    "\n",
    "    train1_pred = lol.predict(datasets[\"07-spec-mean\"][\"train\"].iloc[train[1]])\n",
    "\n",
    "    plot_confusion_matrix(confusion_matrix(Y_train[train[1]], train1_pred, labels = [0, 1]), classes = [0, 1])\n",
    "    \n",
    "plotConfusionMatrixBestXGB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plotConfusionMatrixBestLDA():\n",
    "    kfold = mds.StratifiedKFold(n_splits=2, shuffle=True, random_state=2)\n",
    "    train, test = kfold.split(datasets[\"09-spec-min\"][\"train\"], Y_train)\n",
    "\n",
    "    lol = xgb.XGBClassifier().fit(datasets[\"09-spec-min\"][\"train\"].iloc[train[0]], Y_train[train[0]])\n",
    "\n",
    "    train1_pred = lol.predict(datasets[\"09-spec-min\"][\"train\"].iloc[train[1]])\n",
    "\n",
    "    plot_confusion_matrix(confusion_matrix(Y_train[train[1]], train1_pred, labels = [0, 1]), classes = [0, 1])\n",
    "    \n",
    "plotConfusionMatrixBestLDA()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.1 - Tuning of the best models\n",
    "#### Based on this plot, we decided to tune LDA and XGB\n",
    "### Tuning XGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Adapted from https://www.analyticsvidhya.com/blog/2016/03/complete-guide-parameter-tuning-xgboost-with-codes-python/\n",
    "def modelfit(alg, train_predictors, train_target, useTrainCV=True, cv_folds=10, early_stopping_rounds=50):\n",
    "    \n",
    "    if useTrainCV:\n",
    "        xgb_param = alg.get_xgb_params()\n",
    "        xgtrain = xgb.DMatrix(train_predictors.values, label=train_target.values)\n",
    "        cvresult = xgb.cv(xgb_param, xgtrain, num_boost_round=alg.get_params()['n_estimators'], nfold=cv_folds,\n",
    "            metrics='auc', early_stopping_rounds=early_stopping_rounds, verbose_eval=True)\n",
    "        alg.set_params(n_estimators=cvresult.shape[0])\n",
    "    \n",
    "    #Fit the algorithm on the data\n",
    "    alg.fit(train_predictors, train_target, eval_metric='auc')\n",
    "        \n",
    "    #Predict training set:\n",
    "    dtrain_predictions = alg.predict(train_predictors)\n",
    "    dtrain_predprob = alg.predict_proba(train_predictors)[:,1]\n",
    "        \n",
    "    #Print model report:\n",
    "    print(\"\\nModel Report\")\n",
    "    print(\"Accuracy : %.4g\" % metrics.accuracy_score(train_target.values, dtrain_predictions))\n",
    "    print(\"AUC Score (Train): %f\" % metrics.roc_auc_score(train_target, dtrain_predprob))\n",
    "                    \n",
    "    #feat_imp = pd.Series(alg.booster().get_fscore()).sort_values(ascending=False)\n",
    "    #feat_imp.plot(kind='bar', title='Feature Importances')\n",
    "    #plt.ylabel('Feature Importance Score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics   #Additional scklearn functions\n",
    "from sklearn.model_selection import GridSearchCV   #Perforing grid search\n",
    "\n",
    "def tuneXGB1():\n",
    "    xgb1 = xgb.XGBClassifier(\n",
    "        learning_rate=0.1,\n",
    "        n_estimators=1000,\n",
    "        max_depth=5, # This should be between 3-10\n",
    "        min_child_weight=1, # A smaller value is chosen because it is a highly imbalanced class problem\n",
    "        gamma=0,\n",
    "        subsample=0.8, # Typical values range between 0.5-0.9.\n",
    "        colsample_bytree=0.8, # Typical values range between 0.5-0.9.\n",
    "        objective= 'binary:logistic',\n",
    "        #nthread=4,\n",
    "        scale_pos_weight=1, # Because of high class imbalance\n",
    "        seed=2)\n",
    "    \n",
    "    modelfit(xgb1, datasets[\"07-spec-mean\"][\"train\"], Y_train)\n",
    "    \n",
    "tuneXGB1()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This last result seems too good to be truth?!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def tuneXGB2():\n",
    "    param_test1 = {\n",
    "        'max_depth': np.arange(3,10,2),\n",
    "        'min_child_weight': np.arange(1,6,2)\n",
    "    }\n",
    "    \n",
    "    gsearch1 = GridSearchCV(estimator = xgb.XGBClassifier( learning_rate=0.1, n_estimators=156, max_depth=5,\n",
    "                                                      min_child_weight=1, gamma=0, subsample=0.8, colsample_bytree=0.8,\n",
    "                                                      objective= 'binary:logistic', scale_pos_weight=1, seed=2), \n",
    "                            param_grid = param_test1, scoring='roc_auc',iid=False, cv=10)\n",
    "    \n",
    "    gsearch1.fit(datasets[\"07-spec-mean\"][\"train\"], Y_train)\n",
    "    print(gsearch1.grid_scores_, gsearch1.best_params_, gsearch1.best_score_)\n",
    "    \n",
    "tuneXGB2()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### {'max_depth': 7, 'min_child_weight': 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def tuneXGB3():\n",
    "    param_test1 = {\n",
    "        'max_depth': [6,7,8],\n",
    "        'min_child_weight': [1,2,3]\n",
    "    }\n",
    "    \n",
    "    gsearch1 = GridSearchCV(estimator = xgb.XGBClassifier( learning_rate=0.1, n_estimators=156, max_depth=5,\n",
    "                                                      min_child_weight=1, gamma=0, subsample=0.8, colsample_bytree=0.8,\n",
    "                                                      objective= 'binary:logistic', scale_pos_weight=1, seed=2), \n",
    "                            param_grid = param_test1, scoring='roc_auc',iid=False, cv=10)\n",
    "    \n",
    "    gsearch1.fit(datasets[\"07-spec-mean\"][\"train\"], Y_train)\n",
    "    print(gsearch1.grid_scores_, gsearch1.best_params_, gsearch1.best_score_)\n",
    "    \n",
    "tuneXGB3()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def tuneXGB4():\n",
    "    param_test1 = {\n",
    "        'gamma':[i/10.0 for i in np.arange(0,5)]\n",
    "    }\n",
    "    \n",
    "    gsearch1 = GridSearchCV(estimator = xgb.XGBClassifier( learning_rate=0.1, n_estimators=156, max_depth=7,\n",
    "                                                      min_child_weight=1, gamma=0, subsample=0.8, colsample_bytree=0.8,\n",
    "                                                      objective= 'binary:logistic', scale_pos_weight=1, seed=2), \n",
    "                            param_grid = param_test1, scoring='roc_auc',iid=False, cv=10)\n",
    "    \n",
    "    gsearch1.fit(datasets[\"07-spec-mean\"][\"train\"], Y_train)\n",
    "    print(gsearch1.grid_scores_, gsearch1.best_params_, gsearch1.best_score_)\n",
    "    \n",
    "tuneXGB4()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### gamma = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def tuneXGB5():\n",
    "    xgb1 = xgb.XGBClassifier(\n",
    "        learning_rate=0.1,\n",
    "        n_estimators=1000,\n",
    "        max_depth=7, # This should be between 3-10\n",
    "        min_child_weight=1, # A smaller value is chosen because it is a highly imbalanced class problem\n",
    "        gamma=0,\n",
    "        subsample=0.8, # Typical values range between 0.5-0.9.\n",
    "        colsample_bytree=0.8, # Typical values range between 0.5-0.9.\n",
    "        objective= 'binary:logistic',\n",
    "        #nthread=4,\n",
    "        scale_pos_weight=1, # Because of high class imbalance\n",
    "        seed=2)\n",
    "    \n",
    "    modelfit(xgb1, datasets[\"07-spec-mean\"][\"train\"], Y_train)\n",
    "    \n",
    "tuneXGB5()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def tuneXGB6():\n",
    "    param_test1 = {\n",
    "     'subsample': np.arange(0.6, 1.0, 0.1),\n",
    "     'colsample_bytree': np.arange(0.6, 1.0, 0.1)\n",
    "    }\n",
    "    \n",
    "    gsearch1 = GridSearchCV(estimator = xgb.XGBClassifier( learning_rate=0.1, n_estimators=156, max_depth=7,\n",
    "                                                      min_child_weight=1, gamma=0, subsample=0.8, colsample_bytree=0.8,\n",
    "                                                      objective= 'binary:logistic', scale_pos_weight=1, seed=2), \n",
    "                            param_grid = param_test1, scoring='roc_auc',iid=False, cv=10)\n",
    "    \n",
    "    gsearch1.fit(datasets[\"07-spec-mean\"][\"train\"], Y_train)\n",
    "    print(gsearch1.grid_scores_, gsearch1.best_params_, gsearch1.best_score_)\n",
    "    \n",
    "tuneXGB6()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### subsample = 0.6 and colsample_bytree = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def tuneXGB7():\n",
    "    param_test1 = {\n",
    "     'subsample': np.arange(0.55, 0.7, 0.05),\n",
    "     'colsample_bytree': np.arange(0.85, 1.0, 0.05)\n",
    "    }\n",
    "    \n",
    "    gsearch1 = GridSearchCV(estimator = xgb.XGBClassifier( learning_rate=0.1, n_estimators=156, max_depth=7,\n",
    "                                                      min_child_weight=1, gamma=0, subsample=0.8, colsample_bytree=0.8,\n",
    "                                                      objective= 'binary:logistic', scale_pos_weight=1, seed=2), \n",
    "                            param_grid = param_test1, scoring='roc_auc',iid=False, cv=10)\n",
    "    \n",
    "    gsearch1.fit(datasets[\"07-spec-mean\"][\"train\"], Y_train)\n",
    "    print(gsearch1.grid_scores_, gsearch1.best_params_, gsearch1.best_score_)\n",
    "    \n",
    "tuneXGB7()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### better tuned: subsample=0.55 and colsample_bytree=0.85"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def tuneXGB8():\n",
    "    param_test1 = {\n",
    "     'reg_alpha':[1e-5, 1e-2, 0.1, 1, 100]\n",
    "    }\n",
    "    \n",
    "    gsearch1 = GridSearchCV(estimator = xgb.XGBClassifier( learning_rate=0.1, n_estimators=156, max_depth=7,\n",
    "                                                      min_child_weight=1, gamma=0, subsample=0.55, colsample_bytree=0.85,\n",
    "                                                      objective= 'binary:logistic', scale_pos_weight=1, seed=2), \n",
    "                            param_grid = param_test1, scoring='roc_auc',iid=False, cv=10)\n",
    "    \n",
    "    gsearch1.fit(datasets[\"07-spec-mean\"][\"train\"], Y_train)\n",
    "    print(gsearch1.grid_scores_, gsearch1.best_params_, gsearch1.best_score_)\n",
    "    \n",
    "tuneXGB8()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reg alpha = 1e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def tuneXGB9():    \n",
    "    xgb1 = xgb.XGBClassifier( learning_rate=0.01, n_estimators=5000, max_depth=7,\n",
    "                      min_child_weight=1, gamma=0, subsample=0.55, colsample_bytree=0.85,\n",
    "                      reg_alpha=1e-5, objective= 'binary:logistic', scale_pos_weight=1, seed=2)\n",
    "    \n",
    "    modelfit(xgb1, datasets[\"07-spec-mean\"][\"train\"], Y_train)\n",
    "    \n",
    "tuneXGB9()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def tuneLDA():\n",
    "    param_test1 = [{\"solver\": [\"svd\"], \"n_components\": np.arange(1,len(X_train.columns) - 1)},\n",
    "                   {\"solver\": [\"lsqr\", \"eigen\"], \"n_components\": np.arange(1,len(X_train.columns) - 1), \"shrinkage\": [\"auto\"]}]\n",
    "        \n",
    "    gsearch1 = GridSearchCV(estimator=LinearDiscriminantAnalysis(), \n",
    "                            param_grid = param_test1, scoring='roc_auc', cv=10)\n",
    "    \n",
    "    fit = gsearch1.fit(datasets[\"09-spec-min\"][\"train\"], Y_train)\n",
    "    return(fit)\n",
    "    \n",
    "bestLDAfit = tuneLDA()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bestLDAfit.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bestLDAfit.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def evaluatingBestLDA():\n",
    "    kfold = mds.StratifiedKFold(n_splits=num_folds, shuffle=True, random_state=2)\n",
    "    model = LinearDiscriminantAnalysis(n_components = 1, shrinkage = \"auto\", solver=\"lsqr\")\n",
    "    \n",
    "    cv_results = mds.cross_val_score(model, datasets[\"09-spec-min\"][\"train\"], Y_train, cv=kfold, scoring=\"roc_auc\")\n",
    "    print(cv_results.mean())\n",
    "    \n",
    "evaluatingBestLDA()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 - Unsupervised Anomaly Detection Methods\n",
    "We decided to try LOF and see how it goes. We used our implementation from HW1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import lof_pal as lof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def makePredictonsLOF():\n",
    "    outliers = []\n",
    "    \n",
    "    kfold = mds.StratifiedKFold(n_splits=2, shuffle=True, random_state=2)\n",
    "    sets,_ = kfold.split(datasets[\"07-spec-mean\"][\"train\"], Y_train)                                      \n",
    "    \n",
    "    # Train with only positive examples:\n",
    "    l = lof.LOF(datasets[\"07-spec-mean\"][\"train\"].iloc[sets[0]][Y_train[sets[0]] != 1], 3)\n",
    "    \n",
    "    Y_pred = [1 if x > 1.2 else 0 for x in l.predict(datasets[\"07-spec-mean\"][\"train\"].iloc[sets[1]])]\n",
    "        \n",
    "    plot_confusion_matrix(confusion_matrix(Y_train[sets[1]], Y_pred, labels = [0, 1]), classes = [0, 1])\n",
    "    #return Y_pred\n",
    "        \n",
    "    \n",
    "makePredictonsLOF()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 - Submission to Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# choose algorithm\n",
    "def makeSubmissionKaggle(NA_strategy, algorithm):\n",
    "    print(\"Submiting using \\\"%s\\\"\" % (NA_strategy))\n",
    "\n",
    "    algorithm.fit(datasets[NA_strategy][\"train\"], Y_train)\n",
    "    Y_pred = algorithm.predict(datasets[NA_strategy][\"test\"])\n",
    "    Y_pred = Y_pred.astype(int)\n",
    "\n",
    "    # save data to CSV\n",
    "    saveDataToCSV(Y_pred)\n",
    "    \n",
    "#makeSubmissionKaggle(\"07-spec-mean\", xgb.XGBClassifier( learning_rate=0.01, n_estimators=5000, max_depth=7,\n",
    "#                      min_child_weight=1, gamma=0, subsample=0.55, colsample_bytree=0.85,\n",
    "#                      reg_alpha=1e-5, objective= 'binary:logistic', scale_pos_weight=1, seed=2))\n",
    "\n",
    "#makeSubmissionKaggle(\"09-spec-min\", LinearDiscriminantAnalysis(n_components = 1, shrinkage = \"auto\", solver=\"lsqr\"))\n",
    "makeSubmissionKaggle(\"10-spec-max\", AdaBoostClassifier())"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
