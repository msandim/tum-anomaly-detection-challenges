{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 - Data Reading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# pandas\n",
    "import pandas as pd\n",
    "from pandas import Series,DataFrame\n",
    "\n",
    "# numpy, matplotlib, seaborn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "#read from csv\n",
    "test_df = pd.read_csv(\"sat-test-data.csv.dat\", header=None)\n",
    "train_df = pd.read_csv(\"sat-train.csv.dat\", header =None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 - Data Pre-Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 - Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        0      1      2      3     4      5      6      7     8      9  ...  \\\n",
      "0     92.0  115.0  120.0   94.0  84.0  102.0  106.0   79.0  84.0  102.0 ...   \n",
      "1     84.0  102.0  106.0   79.0  84.0  102.0  102.0   83.0  80.0  102.0 ...   \n",
      "2     84.0  102.0    NaN   83.0   NaN    NaN  102.0   79.0  84.0   94.0 ...   \n",
      "3     80.0  102.0  102.0   79.0  84.0    NaN  102.0   79.0  80.0    NaN ...   \n",
      "4     84.0   94.0  102.0   79.0  80.0   94.0   98.0   76.0  80.0  102.0 ...   \n",
      "5     80.0   94.0   98.0   76.0  80.0  102.0  102.0   79.0  76.0  102.0 ...   \n",
      "6     76.0  102.0  106.0    NaN  76.0  102.0    NaN   87.0   NaN   98.0 ...   \n",
      "7     76.0  102.0  106.0   87.0   NaN   98.0  106.0    NaN  76.0   94.0 ...   \n",
      "8      NaN    NaN   98.0   76.0   NaN    NaN   98.0    NaN  76.0   98.0 ...   \n",
      "9      NaN   94.0    NaN   76.0  76.0   98.0    NaN    NaN   NaN    NaN ...   \n",
      "10    76.0    NaN  102.0   72.0  76.0    NaN   90.0    NaN   NaN   89.0 ...   \n",
      "11    72.0   94.0   90.0   72.0  72.0   89.0   94.0   76.0  72.0   89.0 ...   \n",
      "12    72.0   89.0    NaN   76.0  72.0   89.0   98.0    NaN  76.0    NaN ...   \n",
      "13    76.0   94.0   98.0    NaN  72.0   85.0   90.0   72.0   NaN    NaN ...   \n",
      "14    68.0   85.0   86.0   68.0  68.0   89.0   86.0   72.0  68.0   85.0 ...   \n",
      "15    68.0    NaN    NaN   72.0   NaN   85.0   90.0   76.0   NaN   94.0 ...   \n",
      "16    68.0   85.0   90.0   76.0  68.0   94.0   94.0   79.0  76.0   94.0 ...   \n",
      "17    68.0   94.0   94.0   79.0  76.0   94.0    NaN   79.0  80.0   98.0 ...   \n",
      "18    80.0   94.0    NaN   83.0  80.0  102.0    NaN   87.0  84.0  106.0 ...   \n",
      "19    88.0  106.0  115.0   87.0  88.0  111.0  111.0   91.0  88.0  106.0 ...   \n",
      "20    84.0   98.0  111.0   83.0   NaN    NaN  115.0    NaN  88.0  102.0 ...   \n",
      "21     NaN   89.0  115.0   87.0  88.0  102.0  106.0    NaN   NaN  115.0 ...   \n",
      "22    88.0  102.0  106.0    NaN   NaN  115.0  111.0    NaN  92.0  115.0 ...   \n",
      "23    92.0    NaN  115.0   94.0  92.0  111.0  120.0   91.0  84.0    NaN ...   \n",
      "24     NaN  106.0    NaN   87.0   NaN   98.0  111.0    NaN   NaN   98.0 ...   \n",
      "25    84.0   98.0  106.0   91.0  84.0  102.0  111.0   87.0  84.0  106.0 ...   \n",
      "26    84.0  102.0    NaN   87.0  84.0  106.0  111.0   87.0  88.0  111.0 ...   \n",
      "27    84.0  106.0  111.0   87.0  88.0  111.0  115.0   91.0   NaN  111.0 ...   \n",
      "28     NaN  111.0  115.0   91.0  88.0    NaN  120.0   87.0  88.0    NaN ...   \n",
      "29     NaN  111.0  115.0   87.0   NaN    NaN  106.0    NaN  88.0  106.0 ...   \n",
      "...    ...    ...    ...    ...   ...    ...    ...    ...   ...    ... ...   \n",
      "4405  64.0   91.0  113.0    NaN  64.0    NaN  113.0    NaN  68.0    NaN ...   \n",
      "4406   NaN  103.0  113.0   88.0  68.0    NaN  118.0    NaN  68.0  107.0 ...   \n",
      "4407  68.0  107.0    NaN   92.0  68.0  107.0    NaN    NaN   NaN    NaN ...   \n",
      "4408  68.0  107.0  118.0   92.0  68.0  103.0  118.0   92.0  71.0  103.0 ...   \n",
      "4409   NaN  103.0  118.0    NaN  64.0  103.0  122.0   92.0  71.0  107.0 ...   \n",
      "4410  64.0    NaN    NaN    NaN   NaN  107.0  122.0   96.0  71.0  107.0 ...   \n",
      "4411  71.0    NaN    NaN   96.0  71.0  107.0    NaN   96.0   NaN    NaN ...   \n",
      "4412  71.0    NaN  122.0   96.0   NaN  103.0  113.0    NaN  71.0  103.0 ...   \n",
      "4413   NaN  103.0    NaN   92.0   NaN  103.0  118.0    NaN  71.0  107.0 ...   \n",
      "4414   NaN  103.0  118.0   92.0  71.0    NaN  118.0    NaN  71.0  107.0 ...   \n",
      "4415  71.0  107.0    NaN   96.0   NaN  107.0  118.0   96.0   NaN  107.0 ...   \n",
      "4416   NaN    NaN    NaN   96.0  76.0  107.0  122.0   99.0  71.0  116.0 ...   \n",
      "4417  71.0  116.0  122.0   99.0  76.0  107.0  122.0  103.0  76.0  112.0 ...   \n",
      "4418  76.0  112.0  122.0   96.0  76.0  112.0  122.0   99.0  80.0  107.0 ...   \n",
      "4419  76.0  107.0  118.0   96.0  84.0  116.0  128.0  103.0  92.0  116.0 ...   \n",
      "4420  92.0  116.0  133.0  103.0  84.0  112.0  122.0   96.0  71.0   83.0 ...   \n",
      "4421  84.0  112.0  122.0   96.0  71.0   83.0    NaN   85.0  64.0   79.0 ...   \n",
      "4422  71.0    NaN    NaN   85.0  64.0   79.0    NaN   81.0   NaN   83.0 ...   \n",
      "4423  64.0   79.0   96.0   81.0  60.0   83.0  100.0   81.0  60.0   83.0 ...   \n",
      "4424  60.0   83.0    NaN   81.0  60.0   83.0    NaN   85.0  64.0   87.0 ...   \n",
      "4425  64.0    NaN  104.0    NaN  64.0   79.0  100.0   85.0  56.0   71.0 ...   \n",
      "4426  56.0    NaN   96.0   85.0  56.0   68.0    NaN   81.0  56.0    NaN ...   \n",
      "4427  56.0   64.0   91.0   81.0  53.0   64.0   83.0   78.0  56.0   68.0 ...   \n",
      "4428  53.0   64.0   83.0    NaN   NaN   68.0   87.0    NaN   NaN   71.0 ...   \n",
      "4429  60.0   64.0  104.0   99.0  56.0   64.0  108.0   96.0  64.0   71.0 ...   \n",
      "4430   NaN    NaN    NaN   96.0  64.0   71.0    NaN    NaN  68.0   75.0 ...   \n",
      "4431   NaN    NaN    NaN   96.0  68.0   75.0  108.0    NaN  71.0    NaN ...   \n",
      "4432   NaN   75.0  108.0   96.0  71.0    NaN    NaN   88.0  71.0   91.0 ...   \n",
      "4433  71.0   87.0  108.0   88.0  71.0   91.0  100.0   81.0  76.0   95.0 ...   \n",
      "4434  71.0   91.0    NaN   81.0  76.0   95.0  108.0   88.0   NaN   95.0 ...   \n",
      "\n",
      "         27    28     29     30     31    32     33     34    35  36  \n",
      "0     104.0  88.0  121.0  128.0  100.0  84.0  107.0  113.0  87.0   0  \n",
      "1     100.0  84.0  107.0  113.0   87.0  84.0   99.0  104.0  79.0   0  \n",
      "2      87.0  84.0   99.0  104.0   79.0  84.0    NaN    NaN   NaN   0  \n",
      "3      79.0  84.0   99.0    NaN   79.0   NaN  103.0    NaN   NaN   0  \n",
      "4      79.0  84.0  103.0  104.0   79.0  79.0  107.0  109.0  87.0   0  \n",
      "5      79.0  79.0  107.0  109.0   87.0  79.0  107.0  109.0  87.0   0  \n",
      "6      87.0  79.0  103.0    NaN   83.0   NaN    NaN  104.0  79.0   0  \n",
      "7       NaN   NaN    NaN  104.0    NaN  79.0    NaN  100.0   NaN   0  \n",
      "8      75.0  75.0   91.0    NaN   71.0   NaN   87.0   93.0  71.0   0  \n",
      "9      71.0  79.0   87.0   93.0   71.0  79.0   87.0   93.0   NaN   0  \n",
      "10      NaN  79.0   87.0   93.0    NaN  75.0   87.0   96.0  71.0   0  \n",
      "11     71.0  75.0   87.0   93.0   67.0  71.0   87.0   89.0  67.0   0  \n",
      "12      NaN  71.0    NaN   89.0   67.0  71.0   79.0   81.0  62.0   0  \n",
      "13     62.0  71.0   79.0   85.0   62.0   NaN    NaN   85.0  62.0   0  \n",
      "14     62.0  71.0   75.0   81.0   67.0  71.0   75.0   81.0  62.0   0  \n",
      "15     67.0  71.0    NaN   81.0   62.0  67.0   75.0   85.0   NaN   0  \n",
      "16     62.0  67.0   75.0   85.0   71.0  67.0   75.0   96.0  79.0   0  \n",
      "17      NaN  67.0   75.0    NaN   79.0  75.0    NaN   96.0   NaN   0  \n",
      "18     83.0   NaN    NaN  113.0   87.0   NaN   99.0    NaN   NaN   0  \n",
      "19     87.0  88.0  107.0  104.0   87.0  88.0  107.0  109.0  83.0   0  \n",
      "20      NaN  88.0  103.0  109.0    NaN  88.0    NaN  109.0  87.0   0  \n",
      "21     87.0  88.0  103.0  109.0   87.0   NaN  103.0  113.0  87.0   0  \n",
      "22     87.0  84.0  103.0    NaN    NaN  88.0    NaN  113.0   NaN   0  \n",
      "23      NaN  93.0    NaN    NaN   92.0   NaN    NaN    NaN  92.0   0  \n",
      "24     92.0   NaN    NaN  113.0   87.0  93.0  107.0    NaN  87.0   0  \n",
      "25     87.0  93.0  107.0  109.0   87.0  88.0  107.0  109.0  92.0   0  \n",
      "26     87.0   NaN  107.0  109.0    NaN   NaN    NaN  109.0  87.0   0  \n",
      "27     92.0   NaN  107.0  109.0    NaN  88.0  107.0    NaN   NaN   0  \n",
      "28     87.0  88.0  107.0    NaN   87.0  88.0  107.0  109.0   NaN   0  \n",
      "29     87.0   NaN  103.0  109.0   87.0  93.0    NaN  109.0   NaN   0  \n",
      "...     ...   ...    ...    ...    ...   ...    ...    ...   ...  ..  \n",
      "4405   96.0   NaN    NaN  112.0   96.0  66.0  104.0  112.0  92.0   0  \n",
      "4406    NaN   NaN  104.0  112.0   92.0   NaN  109.0  117.0  96.0   0  \n",
      "4407    NaN  70.0    NaN  117.0   92.0  70.0  104.0  112.0  92.0   0  \n",
      "4408   92.0  70.0  104.0  112.0   92.0  70.0  109.0  112.0  92.0   0  \n",
      "4409   92.0  66.0  104.0  117.0   92.0  63.0    NaN  112.0   NaN   0  \n",
      "4410   92.0  63.0    NaN  112.0   92.0  66.0  100.0  112.0  92.0   0  \n",
      "4411   92.0  66.0    NaN    NaN    NaN  66.0  104.0  117.0  92.0   0  \n",
      "4412    NaN  66.0    NaN  117.0   92.0  70.0    NaN  122.0  96.0   0  \n",
      "4413    NaN  70.0  109.0  122.0    NaN   NaN  109.0  117.0  96.0   0  \n",
      "4414   96.0  74.0  109.0  117.0    NaN   NaN    NaN  112.0   NaN   0  \n",
      "4415   96.0  74.0  109.0    NaN   96.0   NaN    NaN  112.0   NaN   0  \n",
      "4416   96.0  74.0  109.0  112.0   96.0  74.0  104.0  117.0   NaN   0  \n",
      "4417   92.0  74.0  109.0  117.0   96.0  78.0  104.0  112.0  96.0   0  \n",
      "4418   96.0  78.0  104.0  112.0   96.0  78.0  104.0  112.0  96.0   0  \n",
      "4419   89.0  66.0   71.0  100.0   85.0  74.0   83.0  104.0  92.0   0  \n",
      "4420   92.0  78.0   96.0  112.0   96.0  82.0   91.0  100.0  89.0   0  \n",
      "4421   96.0   NaN   91.0  100.0   89.0   NaN   71.0   84.0  78.0   0  \n",
      "4422    NaN  66.0   71.0   84.0   78.0   NaN   79.0   96.0  85.0   0  \n",
      "4423   78.0  63.0   79.0   96.0   85.0  66.0   91.0  104.0  92.0   0  \n",
      "4424   85.0  66.0   91.0  104.0    NaN  66.0   87.0    NaN   NaN   0  \n",
      "4425   85.0  63.0    NaN  100.0    NaN   NaN   83.0  100.0  85.0   0  \n",
      "4426   85.0  63.0   83.0  100.0   81.0  59.0    NaN   96.0  81.0   0  \n",
      "4427   81.0  63.0   83.0   92.0   74.0  59.0   83.0   96.0  74.0   0  \n",
      "4428   74.0  59.0   83.0   96.0   74.0   NaN    NaN    NaN  74.0   0  \n",
      "4429   70.0  63.0   79.0  108.0   92.0  66.0   83.0  108.0  96.0   0  \n",
      "4430    NaN  66.0   83.0  108.0   96.0  66.0   87.0    NaN   NaN   0  \n",
      "4431   96.0   NaN   87.0  104.0   89.0  63.0   87.0    NaN  89.0   0  \n",
      "4432   89.0   NaN    NaN    NaN   89.0  70.0    NaN  104.0  85.0   0  \n",
      "4433   89.0  70.0  100.0  104.0   85.0  70.0   91.0  104.0  85.0   0  \n",
      "4434   85.0  70.0    NaN    NaN   85.0  63.0   91.0    NaN   NaN   0  \n",
      "\n",
      "[4435 rows x 37 columns]\n"
     ]
    }
   ],
   "source": [
    "import  scipy.stats as stats\n",
    "import numpy.ma as ma\n",
    "\n",
    "######replace by zero - black colour in RGB\n",
    "#train_df = np.nan_to_num(train_df)\n",
    "#test_df = np.nan_to_num(test_df)\n",
    "\n",
    "######replace by 255 - white colour in RGB\n",
    "#train_df = train_df.fillna(255)\n",
    "#test_df = train_df.fillna(255)\n",
    "\n",
    "######column minimum\n",
    "#train_df = train_df.fillna(train_df.min())\n",
    "#test_df = test_df.fillna(test_df.min())\n",
    "\n",
    "######column maximum\n",
    "#train_df = train_df.fillna(train_df.max())\n",
    "#test_df = test_df.fillna(test_df.max())\n",
    "\n",
    "\n",
    "#column mean\n",
    "#train_df = train_df.fillna(train_df.mean())\n",
    "#test_df = test_df.fillna(test_df.mean())\n",
    "\n",
    "#column median \n",
    "#train_df = train_df.fillna(train_df.median())\n",
    "#test_df = test_df.fillna(test_df.median())\n",
    "\n",
    "#row spectral mean\n",
    "\n",
    "#row spectral median\n",
    "\n",
    "#row spectral minimum\n",
    "\n",
    "#row spectral maximum\n",
    "\n",
    "# distribution of the spectral values. Get random value from this sample\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 - Choose Model\n",
    "\n",
    "Nota: adicionar neural networks - new in v 0.18\n",
    "\n",
    "First goal: discover which type of analyses works better\n",
    "Second Goal: tune the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'slice'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-659b304bc7fd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[1;31m# prepare data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mY_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0mX_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Paula\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2055\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   2056\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2057\u001b[0;31m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_column\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2058\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   2059\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_getitem_column\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Paula\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_getitem_column\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2062\u001b[0m         \u001b[1;31m# get column\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   2063\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2064\u001b[0;31m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_item_cache\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2065\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   2066\u001b[0m         \u001b[1;31m# duplicate columns & possible reduce dimensionality\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Paula\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_get_item_cache\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m   1382\u001b[0m         \u001b[1;34m\"\"\"Return the cached item, item represents a label indexer.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1383\u001b[0m         \u001b[0mcache\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_item_cache\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1384\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1385\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1386\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: unhashable type: 'slice'"
     ]
    }
   ],
   "source": [
    "#inspired in http://machinelearningmastery.com/compare-machine-learning-algorithms-python-scikit-learn/\n",
    "\n",
    "import pandas\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import cross_validation\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "\n",
    "# prepare data\n",
    "\n",
    "Y_train = train_df[:,-1]\n",
    "X_train = train_df[:,:-1]\n",
    "\n",
    "#Y_train = train_df[len(train_df.columns)-1]\n",
    "#X_train = train_df.drop(len(train_df.columns)-1,axis=1)\n",
    "\n",
    "# prepare configuration for cross validation test harness\n",
    "num_folds = 10\n",
    "num_instances = len(X_train)\n",
    "seed = 7\n",
    "\n",
    "# prepare models\n",
    "models = []\n",
    "models.append(('LR', LogisticRegression()))\n",
    "models.append(('LDA', LinearDiscriminantAnalysis()))\n",
    "models.append(('KNN', KNeighborsClassifier()))\n",
    "models.append(('CART', DecisionTreeClassifier()))\n",
    "models.append(('NB', GaussianNB()))\n",
    "models.append(('SVM', SVC()))\n",
    "models.append(('NN', MLPClassifier(alpha=1))) \n",
    "models.append(('RF', RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1)))\n",
    "models.append(('AB', AdaBoostClassifier()))\n",
    "\n",
    "# evaluate each model in turn\n",
    "results = []\n",
    "names = []\n",
    "scoring = 'accuracy' # try with 'roc_auc', f1'\n",
    "\n",
    "for name, model in models:\n",
    "    kfold = cross_validation.KFold(n=num_instances, n_folds=num_folds, random_state=seed)\n",
    "    cv_results = cross_validation.cross_val_score(model, X_train, Y_train, cv=kfold, scoring=scoring)\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
    "    print(msg)\n",
    "    \n",
    "# boxplot algorithm comparison\n",
    "fig = plt.figure()\n",
    "fig.suptitle('Algorithm Comparison')\n",
    "ax = fig.add_subplot(111)\n",
    "plt.boxplot(results)\n",
    "ax.set_xticklabels(names)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission in Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   0    1    2 ..., 1997 1998 1999]\n",
      "[0 0 0 ..., 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression\n",
    "\n",
    "adaboost = AdaBoostClassifier()\n",
    "\n",
    "adaboost.fit(X_train, Y_train)\n",
    "\n",
    "Y_pred = adaboost.predict(test_df)\n",
    "\n",
    "adaboost.score(X_train, Y_train)\n",
    "\n",
    "print(np.arange(Y_pred.size))\n",
    "\n",
    "Y_pred = Y_pred.astype(int)\n",
    "#np.hstack((Y_pred, np.vstack(np.arange(Y_pred.size))))\n",
    "\n",
    "print(Y_pred)\n",
    "np.savetxt(\"Pauliguel.csv\", Y_pred, delimiter=\",\", fmt='%u')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline\n",
    "\n",
    "- Poderíamos tentar fazer alguma coisa a ver com anomaly, porque até agora é uma análise muito geral:\n",
    "-- Pedir frequências das duas classes.\n",
    "-- Pedir um gráfico com as distribuições dos valores para cada espectro.\n",
    "-- Ver resultado quando se lida com os Missing values pela estratégia da distribuição\n",
    "-- ter o cuidado de ver se os resultados não estão a ser influenciados porque o nosso algoritmo diz sempre a mesma classe: ver precision e recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#ReadData\n",
    "#XTrain, YTrain, rawTestData = importDataFromFiles()\n",
    "\n",
    "#handle missing values\n",
    "\n",
    "#for each different strategy for the missing values check which is the best model in the, get values for accuracy, auc, F1\n",
    "#check both on the K fold, and on the test dataset\n",
    "\n",
    "#pick the best strategy for missing values and  the best model and submit to kaggle \n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
