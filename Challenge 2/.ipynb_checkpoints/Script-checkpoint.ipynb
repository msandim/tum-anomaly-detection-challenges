{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Anomaly Detection Challenge 2\n",
    "## Miguel Sandim and Paula Fortuna"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0 - Library Imports & Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# pandas\n",
    "import pandas as pd\n",
    "from pandas import Series,DataFrame\n",
    "\n",
    "# numpy, matplotlib, seaborn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "# Random libraries and seeds:\n",
    "import random\n",
    "random.seed(2)\n",
    "np.random.seed(2)\n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# From: http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\n",
    "import itertools\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "######################################\n",
    "# Function Save Data To CSV\n",
    "######################################\n",
    "\n",
    "def saveDataToCSV(Y_pred):\n",
    "    id_list = range(0, len(Y_pred))\n",
    "    submission = pd.DataFrame({\n",
    "        \"Id\": id_list,\n",
    "        \"Expected\": Y_pred\n",
    "    })\n",
    "    submission = submission[['Id', 'Expected']]\n",
    "    submission.to_csv('submission.csv', index=False)\n",
    "    return\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 - Data Reading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 - Solve format problems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1.1 -  yelp_data_train.dat and yelp_data_test.dat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a text editor (e. g. sublime) use regex.\n",
    "\n",
    "1) Replace \" by \"\"\n",
    "\n",
    "2) Surround text field with \"\n",
    "To match the first one use this (dont forget to remove the one that appears also in the begining of the sentence, and the one in the header):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "^[^;]*;[^;]*;[^;]*;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use this to find the last:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    ";[^;]*;[^;]*;[^;]*;[^;]*;[^;]*;[^;]*$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) check if all the lines match the refered structure:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "^[^;]*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4) Remove random newlines that appear in the rows and make new instance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1.2 - yelp_data_reviewer.dat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) ; caracter removed from fields"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) smiles removed from fields"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3 hotel file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) removal of ; in the link"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Load data (finally!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# read from csv\n",
    "\n",
    "train_df = pd.read_csv(\"data/yelp_data_train.dat\", sep = ';', encoding = 'utf-8')\n",
    "test_df = pd.read_csv(\"data/yelp_data_test.dat\", sep = ';', encoding = 'utf-8')\n",
    "reviewers_df = pd.read_csv(\"data/yelp_data_reviewer.dat\", sep = ';', encoding = 'utf-8')\n",
    "hotels_df = pd.read_csv(\"data/yelp_data_hotel.dat\", sep = ';', encoding = 'utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "N    2516\n",
       "Y     392\n",
       "Name: fake, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[\"fake\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.13480055020632736"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "392/(392 + 2516)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## About 13% of our dataset are anomalous cases. We also checked that each reviewer only reviewed each hotel once, at maximum."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 - Data Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sklearn.preprocessing as skpre"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 - Solve Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>reviewID</th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>reviewContent</th>\n",
       "      <th>rating</th>\n",
       "      <th>usefulCount</th>\n",
       "      <th>coolCount</th>\n",
       "      <th>funnyCount</th>\n",
       "      <th>fake</th>\n",
       "      <th>hotelID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9/16/2010</td>\n",
       "      <td>Ol</td>\n",
       "      <td>nf3q2h-kSQoZK2jBY92FOg</td>\n",
       "      <td>If you are considering staying here, watch thi...</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>N</td>\n",
       "      <td>tQfLGoolUMu2J0igcWcoZg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2/5/2010</td>\n",
       "      <td>i4HIAcNTjabdpG1K4F5Q2g</td>\n",
       "      <td>Sb3DJGdZ4Rq__CqxPbae-g</td>\n",
       "      <td>This place is disgusting, absolutely horrible,...</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>N</td>\n",
       "      <td>tQfLGoolUMu2J0igcWcoZg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8/9/2010</td>\n",
       "      <td>veKKNAaSKWj8os</td>\n",
       "      <td>nR7zLyFOlzAYqmzgJ3DtXg</td>\n",
       "      <td>Disgusting!!! Â There is literally duct tape ho...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>N</td>\n",
       "      <td>tQfLGoolUMu2J0igcWcoZg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8/11/2012</td>\n",
       "      <td>6c-ZiQkHXtp1n6VfiKDQ3g</td>\n",
       "      <td>747lP4p8dUD6RTkcsIaSGg</td>\n",
       "      <td>This hotel came up on Hotwire for $108 a night...</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>33Xc1Bk_gkSY5xb2doQ7Ng</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7/9/2012</td>\n",
       "      <td>POWQ6FuUf3oe2ZkhmHvciA</td>\n",
       "      <td>Ij5t6VdwtasSkrpp9uAbKg</td>\n",
       "      <td>Good location, really run down. I am surprised...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>33Xc1Bk_gkSY5xb2doQ7Ng</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6/19/2012</td>\n",
       "      <td>QBynYcLgIgtAd-YfnrrAtA</td>\n",
       "      <td>hSERzClUe57bCw3nCp4plA</td>\n",
       "      <td>Beautiful lobby. The rest is a dump. The eleva...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>33Xc1Bk_gkSY5xb2doQ7Ng</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>9/14/2012</td>\n",
       "      <td>ELY3TK</td>\n",
       "      <td>OMm2VcGks3QL0p0n3_kPFw</td>\n",
       "      <td>Stayed here when I went to Chicago for a weddi...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>33Xc1Bk_gkSY5xb2doQ7Ng</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3/20/2012</td>\n",
       "      <td>uWKWYb5vDpeDGEAZUc192g</td>\n",
       "      <td>yevHGEUQQmnVlBXIrJ885A</td>\n",
       "      <td>I bleed SPG loyalty blood to the point where I...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>33Xc1Bk_gkSY5xb2doQ7Ng</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3/3/2012</td>\n",
       "      <td>hkt7Dnr7kRnLLd9pm-fxDw</td>\n",
       "      <td>Lql1_3zeGlny_Tgq4MI6Fg</td>\n",
       "      <td>I stayed here a couple of times in 2011, as th...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>33Xc1Bk_gkSY5xb2doQ7Ng</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>6/18/2012</td>\n",
       "      <td>ZlexD7XvkqH8yve4zCAR7g</td>\n",
       "      <td>RtyDimVdIBwjGdQr0dti1w</td>\n",
       "      <td>This is an older property, so the decor is dat...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>33Xc1Bk_gkSY5xb2doQ7Ng</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>3/13/2012</td>\n",
       "      <td>Rw1JmyRyyjoACCUFvmS9kQ</td>\n",
       "      <td>hCIJT7tIhPX_YZBCPhYhMg</td>\n",
       "      <td>Small Rooms....one elevator that takes forever...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>33Xc1Bk_gkSY5xb2doQ7Ng</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>5/24/2010</td>\n",
       "      <td>O9chyjQi5</td>\n",
       "      <td>nKgjmPhPPiJ8BL97dO76XA</td>\n",
       "      <td>Great location, terribly outdated. Feels like ...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>33Xc1Bk_gkSY5xb2doQ7Ng</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>10/25/2010</td>\n",
       "      <td>x4FHvju16JpVa3ihzIwQvw</td>\n",
       "      <td>IhKctrZ3BtJkfpf0qO-8mQ</td>\n",
       "      <td>My husband and I came to Chicago for a week an...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>33Xc1Bk_gkSY5xb2doQ7Ng</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2/13/2011</td>\n",
       "      <td>NaN</td>\n",
       "      <td>yoB_PYQHjnPjh78ATA0Jgw</td>\n",
       "      <td>Stayed here over the Jan 15th weekend. Â The lo...</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>33Xc1Bk_gkSY5xb2doQ7Ng</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>8/9/2011</td>\n",
       "      <td>9CPWfP7Ibj-2TthBN</td>\n",
       "      <td>b8B2b2q_Lcactxp8xr-jvg</td>\n",
       "      <td>Breakfast no longer free, but the wifi is. The...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>33Xc1Bk_gkSY5xb2doQ7Ng</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>9/21/2010</td>\n",
       "      <td>4sIRV-M-nrhyU5wHJSznrA</td>\n",
       "      <td>y5ptsWmvGEAftOQaiFhBcg</td>\n",
       "      <td>I can't imagine paying full price to stay here...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>33Xc1Bk_gkSY5xb2doQ7Ng</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>6/17/2009</td>\n",
       "      <td>s3V-CRnWtlHc2goC7xIAEA</td>\n",
       "      <td>QTJCwSaCfBz3T944SOiHBQ</td>\n",
       "      <td>For the money.. it was a great hotel. Clean, g...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>33Xc1Bk_gkSY5xb2doQ7Ng</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>4/4/2012</td>\n",
       "      <td>A5WJkZECjZVwSoV8Uxciww</td>\n",
       "      <td>_h5MGqTBM8J0tuAfbEvVDg</td>\n",
       "      <td>Great location for walking to any part of down...</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>33Xc1Bk_gkSY5xb2doQ7Ng</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>7/8/2011</td>\n",
       "      <td>xnZtuSIepywIkSC1uGYzGg</td>\n",
       "      <td>s6tSJ1NQMSU59lsCPYzzwQ</td>\n",
       "      <td>Excellent location right down the street from ...</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>33Xc1Bk_gkSY5xb2doQ7Ng</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>4/4/2011</td>\n",
       "      <td>FRM7-hER5S9wMf0IzciDcg</td>\n",
       "      <td>0oA4l1ob50aIZ9x9Kxobqg</td>\n",
       "      <td>Great location for a good price. Book it direc...</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>33Xc1Bk_gkSY5xb2doQ7Ng</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>8/23/2010</td>\n",
       "      <td>0fLzbPuBnOMKzVnmxqz-1w</td>\n",
       "      <td>3KM5g9hyaR-uE92WfMU6Cw</td>\n",
       "      <td>Another Travelzoo deal at an awesome price of ...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>33Xc1Bk_gkSY5xb2doQ7Ng</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>8/9/2008</td>\n",
       "      <td>MGcMncJSQQ7zzE</td>\n",
       "      <td>Nybw4RhZvdexOR-XgXD4DQ</td>\n",
       "      <td>For the love of God, whatever you do, DO NOT t...</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>33Xc1Bk_gkSY5xb2doQ7Ng</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>4/24/2011</td>\n",
       "      <td>8a8MaeJ99mi3WTUZYDYL2Q</td>\n",
       "      <td>SKgjcQz0TNg8LKqlJwxjfg</td>\n",
       "      <td>Decent price for downtown Chicago over a weeke...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>33Xc1Bk_gkSY5xb2doQ7Ng</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>10/3/2009</td>\n",
       "      <td>K8HSCX-GCOcF8VUsAtMSGQ</td>\n",
       "      <td>tdE3__i2otI_nL3M3sy0MQ</td>\n",
       "      <td>Some rooms may reveal the building's age, but ...</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>33Xc1Bk_gkSY5xb2doQ7Ng</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>4/17/2011</td>\n",
       "      <td>2rAeHez1ZzyHvL1u2DIJsw</td>\n",
       "      <td>fOTzYtBF4lJTwDIMfCAeyQ</td>\n",
       "      <td>If you want a reasonably priced, clean, non-ch...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>33Xc1Bk_gkSY5xb2doQ7Ng</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>7/17/2010</td>\n",
       "      <td>07mEVsw7wUKuUOH</td>\n",
       "      <td>Uu-qEGsSb72ngIQUF85rDQ</td>\n",
       "      <td>I arrived at the Tremont this past weekend for...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>33Xc1Bk_gkSY5xb2doQ7Ng</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>10/26/2009</td>\n",
       "      <td>Og0iVk</td>\n",
       "      <td>ptgFdw9WzPQx16w37XxsPQ</td>\n",
       "      <td>I have a fondness for older hotels that are a ...</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>33Xc1Bk_gkSY5xb2doQ7Ng</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>11/23/2011</td>\n",
       "      <td>JKcDTRG0dYs23kj1NeOB5A</td>\n",
       "      <td>zyk-YPhtFZK6kkbpzEKrWw</td>\n",
       "      <td>Well this was an interesting place. Â I went to...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>2nnXespKBBNtDQTtrumNFg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>4/5/2012</td>\n",
       "      <td>6h8rBu1K3AxUiQE8biaTIg</td>\n",
       "      <td>T4LT4dPTTTVZocPhwrJboQ</td>\n",
       "      <td>The card key never worked. Â I even got an extr...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>2nnXespKBBNtDQTtrumNFg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>3/24/2012</td>\n",
       "      <td>4uniW9GJpi56lRUyJFU-OQ</td>\n",
       "      <td>HfypTYNqexsCBuRBQFhKTA</td>\n",
       "      <td>I won't go into details but basically employee...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>2nnXespKBBNtDQTtrumNFg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2878</th>\n",
       "      <td>5/1/2007</td>\n",
       "      <td>ELidp04R7jwXfXV5mFW1XQ</td>\n",
       "      <td>_f9NyNygDasxm4x_8K0FMg</td>\n",
       "      <td>Boo Marriott. You may have comfy beds but hosp...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>Gh4Tb2qCBUCOd5r7jqKnGA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2879</th>\n",
       "      <td>7/14/2012</td>\n",
       "      <td>nJh1lZINVD5SAW2ecQir7A</td>\n",
       "      <td>aAnY0oKxg4WEcYsC9hw3cQ</td>\n",
       "      <td>I attended a week-long training in their confe...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>BISUDalmPulSzHvsO3PhDA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2880</th>\n",
       "      <td>3/5/2012</td>\n",
       "      <td>QkDj-K2</td>\n",
       "      <td>YfsNifnBJYJ1aq05eC-u3g</td>\n",
       "      <td>I am torn with how I want to rate this hotel. ...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>BISUDalmPulSzHvsO3PhDA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2881</th>\n",
       "      <td>9/14/2010</td>\n",
       "      <td>TFKtb8DG7yTAxkntYCRMTQ</td>\n",
       "      <td>uqC3ll6vCfqFalbWnPi-Qg</td>\n",
       "      <td>Rooms are kinda old. Service is pretty mediocr...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>BISUDalmPulSzHvsO3PhDA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2882</th>\n",
       "      <td>1/26/2010</td>\n",
       "      <td>QYD-28qlQRmlAe7G2FbNUA</td>\n",
       "      <td>mzO44cSLjgjo-TUYUqPyHA</td>\n",
       "      <td>I agree with the first reviewer Celeste. I had...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>BISUDalmPulSzHvsO3PhDA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2883</th>\n",
       "      <td>8/3/2011</td>\n",
       "      <td>ZjhC8PHPq5RGocFrXTYcWw</td>\n",
       "      <td>oa027MtAk0PV7Tom9K8xHQ</td>\n",
       "      <td>For the price I got this room for it was Great...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>BISUDalmPulSzHvsO3PhDA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2884</th>\n",
       "      <td>5/27/2010</td>\n",
       "      <td>u5gKtqSW4os8H1OImGEkEw</td>\n",
       "      <td>b_54V-mRPPHIwj0wFWby-g</td>\n",
       "      <td>I once found a key on the sidewalk near here, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>N</td>\n",
       "      <td>bem-1CTpTNpArpCtThTmFw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2885</th>\n",
       "      <td>2/3/2009</td>\n",
       "      <td>VlJdOpIVNevAbBeESTofeQ</td>\n",
       "      <td>WauJzu-aZSJZuCLkLWFkag</td>\n",
       "      <td>I was once told by the talent buyer at the Log...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>N</td>\n",
       "      <td>bem-1CTpTNpArpCtThTmFw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2886</th>\n",
       "      <td>10/4/2009</td>\n",
       "      <td>1bY3wvqJD3zOUx6b-HOb8g</td>\n",
       "      <td>OBz87AmKkY-RKP7dFQFugQ</td>\n",
       "      <td>Where do I begin?? There are so many horrible ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Y</td>\n",
       "      <td>bem-1CTpTNpArpCtThTmFw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2887</th>\n",
       "      <td>9/4/2009</td>\n",
       "      <td>BMQbKdF_m2gGeY6hr9Fv1Q</td>\n",
       "      <td>Dv3r6dxp6N7B2S4stwS4dg</td>\n",
       "      <td>This is obviously a place for junkies and hook...</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Y</td>\n",
       "      <td>bem-1CTpTNpArpCtThTmFw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2888</th>\n",
       "      <td>12/25/2011</td>\n",
       "      <td>M9jtbdwJYyxwWWufBaw3EA</td>\n",
       "      <td>-2aZoH_YaC-1s1BFzo7GcA</td>\n",
       "      <td>Over priced, Â nickle and dime you for everythi...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Y</td>\n",
       "      <td>g51qDl6fQhgat-kFTrcbug</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2889</th>\n",
       "      <td>6/24/2011</td>\n",
       "      <td>LuMU5Me4cAMaxmoKWUrNZg</td>\n",
       "      <td>N0pY2Nd7xTZupPd3SYUWEA</td>\n",
       "      <td>Housekeeping staff here needs lessons--dusty f...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Y</td>\n",
       "      <td>g51qDl6fQhgat-kFTrcbug</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2890</th>\n",
       "      <td>11/30/2010</td>\n",
       "      <td>vE1oKqdlBCOfRDf7ObE_WQ</td>\n",
       "      <td>HWIJ4kkTMnuCTBkLmaupMA</td>\n",
       "      <td>There are too many old men trying to pick up w...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Y</td>\n",
       "      <td>BISUDalmPulSzHvsO3PhDA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2891</th>\n",
       "      <td>6/28/2011</td>\n",
       "      <td>ux6ZfjP5yWHXU4zQA3P7yA</td>\n",
       "      <td>zJ2Op8FsslxF5TSem1f-zw</td>\n",
       "      <td>I used priceline to get a room at this hotel. ...</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Y</td>\n",
       "      <td>Gh4Tb2qCBUCOd5r7jqKnGA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2892</th>\n",
       "      <td>4/16/2010</td>\n",
       "      <td>HzOVUdfy4vAXsIm_eH-Pww</td>\n",
       "      <td>2ck_k8Swtj6-48kLR6IVWA</td>\n",
       "      <td>When we got to the place where check in was ha...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Y</td>\n",
       "      <td>Gh4Tb2qCBUCOd5r7jqKnGA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2893</th>\n",
       "      <td>6/14/2011</td>\n",
       "      <td>D9urHoAJiktxTfpDy84vUw</td>\n",
       "      <td>MtR3yxthVe-LoHEAXUKSGw</td>\n",
       "      <td>My boss booked two rooms here because the pric...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Y</td>\n",
       "      <td>h-U_YfWBK2u_Vqo8AVA4KQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2894</th>\n",
       "      <td>6/4/2010</td>\n",
       "      <td>TYcOMlIhPaobaHFLywRLvw</td>\n",
       "      <td>2ynZkFzXxSYli0acUGEjxA</td>\n",
       "      <td>We stayed in the motel because of it's conveni...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Y</td>\n",
       "      <td>h-U_YfWBK2u_Vqo8AVA4KQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2895</th>\n",
       "      <td>9/25/2011</td>\n",
       "      <td>ECKiMfnDzi11HdfeK0LIBw</td>\n",
       "      <td>pB_MluKOj16YTAH4ZozyNA</td>\n",
       "      <td>Would recommend this hotel to anyone. Â My wife...</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Y</td>\n",
       "      <td>wLjR0DkA4zxu8iqbUQc0Og</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2896</th>\n",
       "      <td>7/27/2012</td>\n",
       "      <td>W0KFuAk6Y62JTMdJw_7hWw</td>\n",
       "      <td>cHegKQwdtrdd3Hpo1b6NsA</td>\n",
       "      <td>Fantastic location, friendly staff and nice ac...</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Y</td>\n",
       "      <td>t5JK4OZzCuetIrJXdHLntg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2897</th>\n",
       "      <td>5/18/2012</td>\n",
       "      <td>t9G4R6uGohktZeHZmf3kKA</td>\n",
       "      <td>nFSimJkp5uq8FPTyY-4NNQ</td>\n",
       "      <td>This boutique hotel is in an excellent locatio...</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Y</td>\n",
       "      <td>t5JK4OZzCuetIrJXdHLntg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2898</th>\n",
       "      <td>8/1/2011</td>\n",
       "      <td>f_MP8IYIvV_Sp3AgAFG0Iw</td>\n",
       "      <td>YMsf5cb9kbEj7DuPdyQ4eA</td>\n",
       "      <td>My wife and I stayed here July 30th. We arrive...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Y</td>\n",
       "      <td>t5JK4OZzCuetIrJXdHLntg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2899</th>\n",
       "      <td>7/19/2011</td>\n",
       "      <td>6mqU5bF4Iq1ZHBfknBUsYQ</td>\n",
       "      <td>JwKrfYb2BNFRZdHCFlwO1w</td>\n",
       "      <td>Very clean and super helpful staff. Â The rooms...</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Y</td>\n",
       "      <td>t5JK4OZzCuetIrJXdHLntg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2900</th>\n",
       "      <td>6/16/2010</td>\n",
       "      <td>pXxaEx57oNIMqsLBqVczyg</td>\n",
       "      <td>hI8LGBnG-VupdJhsj_U3Og</td>\n",
       "      <td>My company held an event here and the staff ov...</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Y</td>\n",
       "      <td>S_qmb0Uzm_cNoRjSvZ6y1w</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2901</th>\n",
       "      <td>4/6/2010</td>\n",
       "      <td>OTJHRZXJn8UfAJ4ljWN9sw</td>\n",
       "      <td>hU9lnr5ZAwWr0SHzg7RdHg</td>\n",
       "      <td>This boutique hotel has a very personal approa...</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Y</td>\n",
       "      <td>S_qmb0Uzm_cNoRjSvZ6y1w</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2902</th>\n",
       "      <td>10/10/2008</td>\n",
       "      <td>IDSx8yGQKNUImss-4YUlGg</td>\n",
       "      <td>BaRtixU-lZsMr2PF4hrvqg</td>\n",
       "      <td>Wife and I stay here when we visit. Went up on...</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Y</td>\n",
       "      <td>S_qmb0Uzm_cNoRjSvZ6y1w</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2903</th>\n",
       "      <td>8/2/2012</td>\n",
       "      <td>lFkroXzrRhmMTrnn6__tnw</td>\n",
       "      <td>ZpFB_pqaUaDmIuCXbN87Ww</td>\n",
       "      <td>All Westins are definitely nice and so was thi...</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Y</td>\n",
       "      <td>LUmAQaRrAleKdXZd8On16Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2904</th>\n",
       "      <td>12/14/2011</td>\n",
       "      <td>mV2x61nyxzsKRgGbM3yuqg</td>\n",
       "      <td>twaozx1wvDOL0Z_fG9gclA</td>\n",
       "      <td>This place was awesome! Well except for the we...</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Y</td>\n",
       "      <td>PyG0aSX3pBx0hzoSH20FnA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2905</th>\n",
       "      <td>11/21/2009</td>\n",
       "      <td>CNwz6w426kCF5H6j-neQSg</td>\n",
       "      <td>S5L1xguLhXJWadpFXnRKqQ</td>\n",
       "      <td>My friend and I, along with our mothers, staye...</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Y</td>\n",
       "      <td>PyG0aSX3pBx0hzoSH20FnA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2906</th>\n",
       "      <td>11/20/2011</td>\n",
       "      <td>1eJPupHCsl-r3WUuz6QvTA</td>\n",
       "      <td>PJK4GsUItBU8JJuoAujWOA</td>\n",
       "      <td>So Surprising when we arrived, The staff was g...</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Y</td>\n",
       "      <td>gCdjyQeE0uRKCh7mVmnZzQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2907</th>\n",
       "      <td>8/5/2010</td>\n",
       "      <td>xwPMoEzuvpn3J32IvTcsiQ</td>\n",
       "      <td>MdYbNl_9Hm1CybsuC6UnkQ</td>\n",
       "      <td>Noise, noise, noise! Â Unbelievable! Â Between t...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Y</td>\n",
       "      <td>rpP9iZsT3NC-Z4pUtQGoiA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2908 rows Ã 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            date                reviewID              reviewerID  \\\n",
       "0      9/16/2010                      Ol  nf3q2h-kSQoZK2jBY92FOg   \n",
       "1       2/5/2010  i4HIAcNTjabdpG1K4F5Q2g  Sb3DJGdZ4Rq__CqxPbae-g   \n",
       "2       8/9/2010          veKKNAaSKWj8os  nR7zLyFOlzAYqmzgJ3DtXg   \n",
       "3      8/11/2012  6c-ZiQkHXtp1n6VfiKDQ3g  747lP4p8dUD6RTkcsIaSGg   \n",
       "4       7/9/2012  POWQ6FuUf3oe2ZkhmHvciA  Ij5t6VdwtasSkrpp9uAbKg   \n",
       "5      6/19/2012  QBynYcLgIgtAd-YfnrrAtA  hSERzClUe57bCw3nCp4plA   \n",
       "6      9/14/2012                  ELY3TK  OMm2VcGks3QL0p0n3_kPFw   \n",
       "7      3/20/2012  uWKWYb5vDpeDGEAZUc192g  yevHGEUQQmnVlBXIrJ885A   \n",
       "8       3/3/2012  hkt7Dnr7kRnLLd9pm-fxDw  Lql1_3zeGlny_Tgq4MI6Fg   \n",
       "9      6/18/2012  ZlexD7XvkqH8yve4zCAR7g  RtyDimVdIBwjGdQr0dti1w   \n",
       "10     3/13/2012  Rw1JmyRyyjoACCUFvmS9kQ  hCIJT7tIhPX_YZBCPhYhMg   \n",
       "11     5/24/2010               O9chyjQi5  nKgjmPhPPiJ8BL97dO76XA   \n",
       "12    10/25/2010  x4FHvju16JpVa3ihzIwQvw  IhKctrZ3BtJkfpf0qO-8mQ   \n",
       "13     2/13/2011                     NaN  yoB_PYQHjnPjh78ATA0Jgw   \n",
       "14      8/9/2011       9CPWfP7Ibj-2TthBN  b8B2b2q_Lcactxp8xr-jvg   \n",
       "15     9/21/2010  4sIRV-M-nrhyU5wHJSznrA  y5ptsWmvGEAftOQaiFhBcg   \n",
       "16     6/17/2009  s3V-CRnWtlHc2goC7xIAEA  QTJCwSaCfBz3T944SOiHBQ   \n",
       "17      4/4/2012  A5WJkZECjZVwSoV8Uxciww  _h5MGqTBM8J0tuAfbEvVDg   \n",
       "18      7/8/2011  xnZtuSIepywIkSC1uGYzGg  s6tSJ1NQMSU59lsCPYzzwQ   \n",
       "19      4/4/2011  FRM7-hER5S9wMf0IzciDcg  0oA4l1ob50aIZ9x9Kxobqg   \n",
       "20     8/23/2010  0fLzbPuBnOMKzVnmxqz-1w  3KM5g9hyaR-uE92WfMU6Cw   \n",
       "21      8/9/2008          MGcMncJSQQ7zzE  Nybw4RhZvdexOR-XgXD4DQ   \n",
       "22     4/24/2011  8a8MaeJ99mi3WTUZYDYL2Q  SKgjcQz0TNg8LKqlJwxjfg   \n",
       "23     10/3/2009  K8HSCX-GCOcF8VUsAtMSGQ  tdE3__i2otI_nL3M3sy0MQ   \n",
       "24     4/17/2011  2rAeHez1ZzyHvL1u2DIJsw  fOTzYtBF4lJTwDIMfCAeyQ   \n",
       "25     7/17/2010         07mEVsw7wUKuUOH  Uu-qEGsSb72ngIQUF85rDQ   \n",
       "26    10/26/2009                  Og0iVk  ptgFdw9WzPQx16w37XxsPQ   \n",
       "27    11/23/2011  JKcDTRG0dYs23kj1NeOB5A  zyk-YPhtFZK6kkbpzEKrWw   \n",
       "28      4/5/2012  6h8rBu1K3AxUiQE8biaTIg  T4LT4dPTTTVZocPhwrJboQ   \n",
       "29     3/24/2012  4uniW9GJpi56lRUyJFU-OQ  HfypTYNqexsCBuRBQFhKTA   \n",
       "...          ...                     ...                     ...   \n",
       "2878    5/1/2007  ELidp04R7jwXfXV5mFW1XQ  _f9NyNygDasxm4x_8K0FMg   \n",
       "2879   7/14/2012  nJh1lZINVD5SAW2ecQir7A  aAnY0oKxg4WEcYsC9hw3cQ   \n",
       "2880    3/5/2012                 QkDj-K2  YfsNifnBJYJ1aq05eC-u3g   \n",
       "2881   9/14/2010  TFKtb8DG7yTAxkntYCRMTQ  uqC3ll6vCfqFalbWnPi-Qg   \n",
       "2882   1/26/2010  QYD-28qlQRmlAe7G2FbNUA  mzO44cSLjgjo-TUYUqPyHA   \n",
       "2883    8/3/2011  ZjhC8PHPq5RGocFrXTYcWw  oa027MtAk0PV7Tom9K8xHQ   \n",
       "2884   5/27/2010  u5gKtqSW4os8H1OImGEkEw  b_54V-mRPPHIwj0wFWby-g   \n",
       "2885    2/3/2009  VlJdOpIVNevAbBeESTofeQ  WauJzu-aZSJZuCLkLWFkag   \n",
       "2886   10/4/2009  1bY3wvqJD3zOUx6b-HOb8g  OBz87AmKkY-RKP7dFQFugQ   \n",
       "2887    9/4/2009  BMQbKdF_m2gGeY6hr9Fv1Q  Dv3r6dxp6N7B2S4stwS4dg   \n",
       "2888  12/25/2011  M9jtbdwJYyxwWWufBaw3EA  -2aZoH_YaC-1s1BFzo7GcA   \n",
       "2889   6/24/2011  LuMU5Me4cAMaxmoKWUrNZg  N0pY2Nd7xTZupPd3SYUWEA   \n",
       "2890  11/30/2010  vE1oKqdlBCOfRDf7ObE_WQ  HWIJ4kkTMnuCTBkLmaupMA   \n",
       "2891   6/28/2011  ux6ZfjP5yWHXU4zQA3P7yA  zJ2Op8FsslxF5TSem1f-zw   \n",
       "2892   4/16/2010  HzOVUdfy4vAXsIm_eH-Pww  2ck_k8Swtj6-48kLR6IVWA   \n",
       "2893   6/14/2011  D9urHoAJiktxTfpDy84vUw  MtR3yxthVe-LoHEAXUKSGw   \n",
       "2894    6/4/2010  TYcOMlIhPaobaHFLywRLvw  2ynZkFzXxSYli0acUGEjxA   \n",
       "2895   9/25/2011  ECKiMfnDzi11HdfeK0LIBw  pB_MluKOj16YTAH4ZozyNA   \n",
       "2896   7/27/2012  W0KFuAk6Y62JTMdJw_7hWw  cHegKQwdtrdd3Hpo1b6NsA   \n",
       "2897   5/18/2012  t9G4R6uGohktZeHZmf3kKA  nFSimJkp5uq8FPTyY-4NNQ   \n",
       "2898    8/1/2011  f_MP8IYIvV_Sp3AgAFG0Iw  YMsf5cb9kbEj7DuPdyQ4eA   \n",
       "2899   7/19/2011  6mqU5bF4Iq1ZHBfknBUsYQ  JwKrfYb2BNFRZdHCFlwO1w   \n",
       "2900   6/16/2010  pXxaEx57oNIMqsLBqVczyg  hI8LGBnG-VupdJhsj_U3Og   \n",
       "2901    4/6/2010  OTJHRZXJn8UfAJ4ljWN9sw  hU9lnr5ZAwWr0SHzg7RdHg   \n",
       "2902  10/10/2008  IDSx8yGQKNUImss-4YUlGg  BaRtixU-lZsMr2PF4hrvqg   \n",
       "2903    8/2/2012  lFkroXzrRhmMTrnn6__tnw  ZpFB_pqaUaDmIuCXbN87Ww   \n",
       "2904  12/14/2011  mV2x61nyxzsKRgGbM3yuqg  twaozx1wvDOL0Z_fG9gclA   \n",
       "2905  11/21/2009  CNwz6w426kCF5H6j-neQSg  S5L1xguLhXJWadpFXnRKqQ   \n",
       "2906  11/20/2011  1eJPupHCsl-r3WUuz6QvTA  PJK4GsUItBU8JJuoAujWOA   \n",
       "2907    8/5/2010  xwPMoEzuvpn3J32IvTcsiQ  MdYbNl_9Hm1CybsuC6UnkQ   \n",
       "\n",
       "                                          reviewContent  rating  usefulCount  \\\n",
       "0     If you are considering staying here, watch thi...       1            8   \n",
       "1     This place is disgusting, absolutely horrible,...       3           11   \n",
       "2     Disgusting!!! Â There is literally duct tape ho...       1            1   \n",
       "3     This hotel came up on Hotwire for $108 a night...       4            2   \n",
       "4     Good location, really run down. I am surprised...       2            0   \n",
       "5     Beautiful lobby. The rest is a dump. The eleva...       1            0   \n",
       "6     Stayed here when I went to Chicago for a weddi...       3            2   \n",
       "7     I bleed SPG loyalty blood to the point where I...       1            1   \n",
       "8     I stayed here a couple of times in 2011, as th...       3            0   \n",
       "9     This is an older property, so the decor is dat...       1            0   \n",
       "10    Small Rooms....one elevator that takes forever...       2            0   \n",
       "11    Great location, terribly outdated. Feels like ...       2            2   \n",
       "12    My husband and I came to Chicago for a week an...       4            1   \n",
       "13    Stayed here over the Jan 15th weekend. Â The lo...       4            0   \n",
       "14    Breakfast no longer free, but the wifi is. The...       4            1   \n",
       "15    I can't imagine paying full price to stay here...       2            0   \n",
       "16    For the money.. it was a great hotel. Clean, g...       3            0   \n",
       "17    Great location for walking to any part of down...       4            0   \n",
       "18    Excellent location right down the street from ...       4            0   \n",
       "19    Great location for a good price. Book it direc...       4            0   \n",
       "20    Another Travelzoo deal at an awesome price of ...       2            0   \n",
       "21    For the love of God, whatever you do, DO NOT t...       4            0   \n",
       "22    Decent price for downtown Chicago over a weeke...       2            0   \n",
       "23    Some rooms may reveal the building's age, but ...       4            0   \n",
       "24    If you want a reasonably priced, clean, non-ch...       3            0   \n",
       "25    I arrived at the Tremont this past weekend for...       2            2   \n",
       "26    I have a fondness for older hotels that are a ...       4            0   \n",
       "27    Well this was an interesting place. Â I went to...       3            1   \n",
       "28    The card key never worked. Â I even got an extr...       1            1   \n",
       "29    I won't go into details but basically employee...       1            1   \n",
       "...                                                 ...     ...          ...   \n",
       "2878  Boo Marriott. You may have comfy beds but hosp...       1            2   \n",
       "2879  I attended a week-long training in their confe...       4            1   \n",
       "2880  I am torn with how I want to rate this hotel. ...       4            3   \n",
       "2881  Rooms are kinda old. Service is pretty mediocr...       3            0   \n",
       "2882  I agree with the first reviewer Celeste. I had...       2            2   \n",
       "2883  For the price I got this room for it was Great...       3            1   \n",
       "2884  I once found a key on the sidewalk near here, ...       1            4   \n",
       "2885  I was once told by the talent buyer at the Log...       1            3   \n",
       "2886  Where do I begin?? There are so many horrible ...       1            0   \n",
       "2887  This is obviously a place for junkies and hook...       5            0   \n",
       "2888  Over priced, Â nickle and dime you for everythi...       1            0   \n",
       "2889  Housekeeping staff here needs lessons--dusty f...       2            0   \n",
       "2890  There are too many old men trying to pick up w...       2            0   \n",
       "2891  I used priceline to get a room at this hotel. ...       4            0   \n",
       "2892  When we got to the place where check in was ha...       1            0   \n",
       "2893  My boss booked two rooms here because the pric...       1            0   \n",
       "2894  We stayed in the motel because of it's conveni...       1            0   \n",
       "2895  Would recommend this hotel to anyone. Â My wife...       5            0   \n",
       "2896  Fantastic location, friendly staff and nice ac...       4            0   \n",
       "2897  This boutique hotel is in an excellent locatio...       4            0   \n",
       "2898  My wife and I stayed here July 30th. We arrive...       2            0   \n",
       "2899  Very clean and super helpful staff. Â The rooms...       4            0   \n",
       "2900  My company held an event here and the staff ov...       4            0   \n",
       "2901  This boutique hotel has a very personal approa...       5            0   \n",
       "2902  Wife and I stay here when we visit. Went up on...       5            0   \n",
       "2903  All Westins are definitely nice and so was thi...       4            0   \n",
       "2904  This place was awesome! Well except for the we...       4            0   \n",
       "2905  My friend and I, along with our mothers, staye...       5            0   \n",
       "2906  So Surprising when we arrived, The staff was g...       5            0   \n",
       "2907  Noise, noise, noise! Â Unbelievable! Â Between t...       1            0   \n",
       "\n",
       "      coolCount  funnyCount fake                 hotelID  \n",
       "0             2           6    N  tQfLGoolUMu2J0igcWcoZg  \n",
       "1             4           9    N  tQfLGoolUMu2J0igcWcoZg  \n",
       "2             0           3    N  tQfLGoolUMu2J0igcWcoZg  \n",
       "3             0           1    N  33Xc1Bk_gkSY5xb2doQ7Ng  \n",
       "4             0           0    N  33Xc1Bk_gkSY5xb2doQ7Ng  \n",
       "5             1           1    N  33Xc1Bk_gkSY5xb2doQ7Ng  \n",
       "6             0           0    N  33Xc1Bk_gkSY5xb2doQ7Ng  \n",
       "7             1           0    N  33Xc1Bk_gkSY5xb2doQ7Ng  \n",
       "8             0           0    N  33Xc1Bk_gkSY5xb2doQ7Ng  \n",
       "9             0           0    N  33Xc1Bk_gkSY5xb2doQ7Ng  \n",
       "10            0           0    N  33Xc1Bk_gkSY5xb2doQ7Ng  \n",
       "11            1           1    N  33Xc1Bk_gkSY5xb2doQ7Ng  \n",
       "12            0           0    N  33Xc1Bk_gkSY5xb2doQ7Ng  \n",
       "13            0           0    N  33Xc1Bk_gkSY5xb2doQ7Ng  \n",
       "14            0           0    N  33Xc1Bk_gkSY5xb2doQ7Ng  \n",
       "15            0           1    N  33Xc1Bk_gkSY5xb2doQ7Ng  \n",
       "16            0           0    N  33Xc1Bk_gkSY5xb2doQ7Ng  \n",
       "17            0           0    N  33Xc1Bk_gkSY5xb2doQ7Ng  \n",
       "18            0           0    N  33Xc1Bk_gkSY5xb2doQ7Ng  \n",
       "19            0           0    N  33Xc1Bk_gkSY5xb2doQ7Ng  \n",
       "20            1           1    N  33Xc1Bk_gkSY5xb2doQ7Ng  \n",
       "21            0           1    N  33Xc1Bk_gkSY5xb2doQ7Ng  \n",
       "22            0           0    N  33Xc1Bk_gkSY5xb2doQ7Ng  \n",
       "23            0           0    N  33Xc1Bk_gkSY5xb2doQ7Ng  \n",
       "24            0           1    N  33Xc1Bk_gkSY5xb2doQ7Ng  \n",
       "25            0           0    N  33Xc1Bk_gkSY5xb2doQ7Ng  \n",
       "26            0           0    N  33Xc1Bk_gkSY5xb2doQ7Ng  \n",
       "27            0           0    N  2nnXespKBBNtDQTtrumNFg  \n",
       "28            0           0    N  2nnXespKBBNtDQTtrumNFg  \n",
       "29            0           0    N  2nnXespKBBNtDQTtrumNFg  \n",
       "...         ...         ...  ...                     ...  \n",
       "2878          0           0    N  Gh4Tb2qCBUCOd5r7jqKnGA  \n",
       "2879          0           0    N  BISUDalmPulSzHvsO3PhDA  \n",
       "2880          1           1    N  BISUDalmPulSzHvsO3PhDA  \n",
       "2881          0           0    N  BISUDalmPulSzHvsO3PhDA  \n",
       "2882          0           0    N  BISUDalmPulSzHvsO3PhDA  \n",
       "2883          0           0    N  BISUDalmPulSzHvsO3PhDA  \n",
       "2884          2          11    N  bem-1CTpTNpArpCtThTmFw  \n",
       "2885          2           3    N  bem-1CTpTNpArpCtThTmFw  \n",
       "2886          0           0    Y  bem-1CTpTNpArpCtThTmFw  \n",
       "2887          0           0    Y  bem-1CTpTNpArpCtThTmFw  \n",
       "2888          0           0    Y  g51qDl6fQhgat-kFTrcbug  \n",
       "2889          0           0    Y  g51qDl6fQhgat-kFTrcbug  \n",
       "2890          0           0    Y  BISUDalmPulSzHvsO3PhDA  \n",
       "2891          0           0    Y  Gh4Tb2qCBUCOd5r7jqKnGA  \n",
       "2892          0           0    Y  Gh4Tb2qCBUCOd5r7jqKnGA  \n",
       "2893          0           0    Y  h-U_YfWBK2u_Vqo8AVA4KQ  \n",
       "2894          0           0    Y  h-U_YfWBK2u_Vqo8AVA4KQ  \n",
       "2895          0           0    Y  wLjR0DkA4zxu8iqbUQc0Og  \n",
       "2896          0           0    Y  t5JK4OZzCuetIrJXdHLntg  \n",
       "2897          0           0    Y  t5JK4OZzCuetIrJXdHLntg  \n",
       "2898          0           0    Y  t5JK4OZzCuetIrJXdHLntg  \n",
       "2899          0           0    Y  t5JK4OZzCuetIrJXdHLntg  \n",
       "2900          0           0    Y  S_qmb0Uzm_cNoRjSvZ6y1w  \n",
       "2901          0           0    Y  S_qmb0Uzm_cNoRjSvZ6y1w  \n",
       "2902          0           0    Y  S_qmb0Uzm_cNoRjSvZ6y1w  \n",
       "2903          0           0    Y  LUmAQaRrAleKdXZd8On16Q  \n",
       "2904          0           0    Y  PyG0aSX3pBx0hzoSH20FnA  \n",
       "2905          0           0    Y  PyG0aSX3pBx0hzoSH20FnA  \n",
       "2906          0           0    Y  gCdjyQeE0uRKCh7mVmnZzQ  \n",
       "2907          0           0    Y  rpP9iZsT3NC-Z4pUtQGoiA  \n",
       "\n",
       "[2908 rows x 10 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.set_value(2550, 'reviewContent', ' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 - Feature Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.1 - Features from paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2908, 10)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def maxNumberOfReviews(data):\n",
    "    import datetime\n",
    "    date_old = [datetime.datetime.strptime(x, \"%B %Y\") for x in data[\"yelpJoinDate\"]]\n",
    "    date_new = datetime.datetime.strptime(\"October 2012\", \"%B %Y\") # Data da review mais antiga\n",
    "    data[\"reviewsPerDay\"] = data[\"reviewCount\"] / [(date_new - x).days for x in date_old]\n",
    "    \n",
    "maxNumberOfReviews(reviewers_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def PPR():\n",
    "    \n",
    "    percentageReviews = []\n",
    "    \n",
    "    for r_id in reviewers_df[\"reviewerID\"]:\n",
    "        train_count = (train_df[\"reviewerID\"] == r_id).sum()\n",
    "        test_count = (test_df[\"reviewerID\"] == r_id).sum()\n",
    "        \n",
    "        \n",
    "        train_count_4 = train_df.loc[(train_df[\"reviewerID\"] == r_id) & (train_df[\"rating\"] > 4)].shape[0]\n",
    "        test_count_4 = test_df.loc[(test_df[\"reviewerID\"] == r_id) & (test_df[\"rating\"] > 4)].shape[0]\n",
    "        \n",
    "        if ((train_count + test_count) == 0):\n",
    "            percentageReviews.append(0.0)\n",
    "        else:\n",
    "            percentageReviews.append((train_count_4 + test_count_4) / (train_count + test_count))\n",
    "\n",
    "    reviewers_df[\"percentageReviews\"] = percentageReviews\n",
    "\n",
    "        \n",
    "    # para cada reviewer fazer get do ID,\n",
    "        # Contar o nÂº de vezes que o ID aparece no train + test com >= 4\n",
    "        # meter no revewer\n",
    "        \n",
    "PPR()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Adapted from http://stackoverflow.com/questions/15173225/how-to-calculate-cosine-similarity-given-2-sentence-strings-python\n",
    "def cosSim(text1, text2):\n",
    "    import re, math\n",
    "    from collections import Counter\n",
    "\n",
    "    WORD = re.compile(r'\\w+')\n",
    "\n",
    "    def get_cosine(vec1, vec2):\n",
    "        intersection = set(vec1.keys()) & set(vec2.keys())\n",
    "        numerator = sum([vec1[x] * vec2[x] for x in intersection])\n",
    "\n",
    "        sum1 = sum([vec1[x]**2 for x in vec1.keys()])\n",
    "        sum2 = sum([vec2[x]**2 for x in vec2.keys()])\n",
    "        denominator = math.sqrt(sum1) * math.sqrt(sum2)\n",
    "\n",
    "        if not denominator:\n",
    "            return(0.0)\n",
    "        else:\n",
    "            return(numerator / denominator)\n",
    "\n",
    "    def text_to_vector(text):\n",
    "        words = WORD.findall(text)\n",
    "        return Counter(words)\n",
    "\n",
    "    vector1 = text_to_vector(text1)\n",
    "    vector2 = text_to_vector(text2)\n",
    "\n",
    "    cosine = get_cosine(vector1, vector2)\n",
    "    return(cosine)\n",
    "    \n",
    "def similarityUsers():\n",
    "    import itertools as it\n",
    "    \n",
    "    mean_distance = []\n",
    "    \n",
    "    for r_id in reviewers_df[\"reviewerID\"]:\n",
    "        texts_train = train_df[train_df[\"reviewerID\"] == r_id][\"reviewContent\"]\n",
    "        texts_test = test_df[test_df[\"reviewerID\"] == r_id][\"reviewContent\"]\n",
    "        texts = np.append(texts_train, texts_test)\n",
    "        \n",
    "        #print(\"tamanho do texto %d\" % len(texts))\n",
    "        if (len(texts) == 0 or len(texts) == 1):\n",
    "            mean_distance.append(0.0)\n",
    "        else:\n",
    "            # Get all combinations of reviews from an user:\n",
    "            combs = list(it.combinations(texts,2))\n",
    "            #print(len(texts))\n",
    "            #print(len(combs))\n",
    "            dist_list = [cosSim(comb[0], comb[1]) for comb in list(it.combinations(texts,2))]\n",
    "            #print(dist_list)\n",
    "\n",
    "            # Calculate the mean distance for the user's reviews\n",
    "            mean_distance.append(np.mean(np.array(dist_list)))\n",
    "        \n",
    "    reviewers_df[\"reviewSimilarity\"] = mean_distance \n",
    "    # percorrer os users\n",
    "        # buscar todos os textos do user (indices)\n",
    "            # ver a funÃ§Ã£o das combinaÃ§Ãµes e pedir a cosSim para todos, no fim fazer a media\n",
    "similarityUsers()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def markFakeUsers():\n",
    "    import itertools as it\n",
    "    \n",
    "    fakeUser = []\n",
    "    \n",
    "    for r_id in reviewers_df[\"reviewerID\"]:\n",
    "        fake_train = train_df[train_df[\"reviewerID\"] == r_id][\"fake\"]\n",
    "        \n",
    "        if (len(fake_train) == 0):\n",
    "            fakeUser.append(0)\n",
    "        else:\n",
    "            # check if any of the fake is 'Y'\n",
    "            if ('Y' in fake_train.values):\n",
    "                fakeUser.append(1)\n",
    "            else:\n",
    "                fakeUser.append(0)\n",
    "        \n",
    "    reviewers_df[\"fakeUser\"] = fakeUser \n",
    "    # percorrer os users\n",
    "        # buscar todos os textos do user (indices)\n",
    "            # ver a funÃ§Ã£o das combinaÃ§Ãµes e pedir a cosSim para todos, no fim fazer a media\n",
    "markFakeUsers()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Joining tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_df_joined = train_df.add_suffix(\"_review\").join(reviewers_df.add_suffix(\"_user\")).join(hotels_df.add_suffix(\"_hotel\")).drop([\n",
    "        \"reviewerID_review\",\n",
    "        \"hotelID_review\"\n",
    "    ], axis=1)\n",
    "\n",
    "test_df_joined = test_df.add_suffix(\"_review\").join(reviewers_df.add_suffix(\"_user\")).join(hotels_df.add_suffix(\"_hotel\")).drop([\n",
    "        \"reviewerID_review\",\n",
    "        \"hotelID_review\"\n",
    "    ], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['date_review', 'reviewID_review', 'reviewContent_review',\n",
       "       'rating_review', 'usefulCount_review', 'coolCount_review',\n",
       "       'funnyCount_review', 'fake_review', 'reviewerID_user', 'name_user',\n",
       "       'location_user', 'yelpJoinDate_user', 'friendCount_user',\n",
       "       'reviewCount_user', 'firstCount_user', 'usefulCount_user',\n",
       "       'coolCount_user', 'funnyCount_user', 'complimentCount_user',\n",
       "       'tipCount_user', 'fanCount_user', 'reviewsPerDay_user',\n",
       "       'percentageReviews_user', 'reviewSimilarity_user', 'fakeUser_user',\n",
       "       'hotelID_hotel', 'name_hotel', 'location_hotel', 'reviewCount_hotel',\n",
       "       'rating_hotel', 'categories_hotel', 'address_hotel',\n",
       "       'AcceptsCreditCards_hotel', 'PriceRange_hotel', 'WiFi_hotel',\n",
       "       'webSite_hotel', 'phoneNumber_hotel', 'filReviewCount_hotel'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_joined.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#train_df_joined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#test_df_joined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df_joined.to_csv(\"train_joined.csv\", encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.2 - Text Mining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lengthReview(data):\n",
    "    data['text_length'] = data['reviewContent_review'].str.len() \n",
    "    data['word_count'] = data['reviewContent_review'].str.count(' ')\n",
    "    \n",
    "lengthReview(train_df_joined)\n",
    "lengthReview(test_df_joined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# bag of words based in the words referenced in the paper\n",
    "def bagOfWords(data): \n",
    "    personal_pronouns = ['i', 'we', 'me', 'us', 'my', 'mine', 'our', 'ours']\n",
    "    associated_actions = ['went', 'feel']\n",
    "    targets = ['area', 'options', 'price', 'stay']\n",
    "    emotion_words = ['nice', 'deal', 'comfort', 'helpful']\n",
    "\n",
    "    import collections, re\n",
    "\n",
    "    # put in lower case\n",
    "    data['reviewContent_review'] = data['reviewContent_review'].str.lower()\n",
    "    \n",
    "    # Replace characters\n",
    "    data['reviewContent_review'] = data['reviewContent_review'].str.replace('\\xa0',' ')\n",
    "    \n",
    "    texts = list(data['reviewContent_review'])\n",
    "    bagsofwords = [collections.Counter(re.findall(r'\\w+', txt)) \n",
    "                   for txt in texts]\n",
    "\n",
    "    def count_words(data, word_list, attribute_name):\n",
    "        data[attribute_name] = np.nan\n",
    "        for i in range(0, data.shape[0]):\n",
    "            num = 0\n",
    "            for word in word_list:\n",
    "                num += bagsofwords[i][word]\n",
    "                \n",
    "            if (data[\"word_count\"][i] == 0):\n",
    "                data.set_value(i, attribute_name, 0.0)\n",
    "            else:\n",
    "                data.set_value(i, attribute_name, num/data[\"word_count\"][i])\n",
    "\n",
    "    count_words(data, personal_pronouns, 'count_pronouns')\n",
    "    count_words(data, associated_actions, 'count_associated_actions')\n",
    "    count_words(data, targets, 'count_targets')\n",
    "    count_words(data, emotion_words, 'count_emotion_words')\n",
    "    \n",
    "bagOfWords(train_df_joined)\n",
    "bagOfWords(test_df_joined)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.2. - Other features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def deviationFromHotelRating(data):\n",
    "    data[\"deviatonReviewHotel\"] = data[\"rating_review\"] - data[\"rating_hotel\"]\n",
    "\n",
    "deviationFromHotelRating(train_df_joined)\n",
    "deviationFromHotelRating(test_df_joined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def countsUserReview(data):\n",
    "    data[\"popularity_review\"] = data[\"usefulCount_review\"] + data[\"coolCount_review\"] + data[\"funnyCount_review\"]\n",
    "        \n",
    "    data[\"popularity_user\"] = data[\"usefulCount_user\"] + data[\"coolCount_user\"] + data[\"funnyCount_user\"] + data[\"complimentCount_user\"] + data[\"fanCount_user\"]\n",
    "\n",
    "countsUserReview(train_df_joined)\n",
    "countsUserReview(test_df_joined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#train_df_joined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#test_df_joined"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 Sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4.1 Undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def undersampling(data):\n",
    "    ids_to_sample = data[data[\"fake_review\"] == \"N\"].index.values\n",
    "    sample_size = data[data[\"fake_review\"] == \"Y\"].shape[0]\n",
    "    anomalies = data[data[\"fake_review\"] == \"Y\"].index.values\n",
    "    \n",
    "    final_ids = np.append(np.random.choice(ids_to_sample, size = sample_size), anomalies)\n",
    "    #print(ids_to_sample)\n",
    "    #data[fake_review]\n",
    "    return data.iloc[final_ids]\n",
    "    \n",
    "train_df_joined = undersampling(train_df_joined)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4.2 Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def oversampling(data):\n",
    "    anomalies = data[data[\"fake_review\"] == \"Y\"]\n",
    "    data = data.append(anomalies)\n",
    "    data = data.append(anomalies)\n",
    "    data = data.append(anomalies)\n",
    "    data = data.append(anomalies)\n",
    "    data = data.append(anomalies)\n",
    "    data = data.append(anomalies)\n",
    "    return data\n",
    "\n",
    "#train_df_joined = oversampling(train_df_joined)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5 Define global variables for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      usefulCount_review  coolCount_review  funnyCount_review  \\\n",
      "1608                   0                 0                  0   \n",
      "2717                   2                 0                  3   \n",
      "2884                   4                 2                 11   \n",
      "1099                   1                 1                  0   \n",
      "2778                   4                 0                  0   \n",
      "674                    0                 0                  0   \n",
      "433                    0                 0                  0   \n",
      "1071                   0                 0                  0   \n",
      "2822                   3                 3                  1   \n",
      "124                    1                 1                  0   \n",
      "1219                   0                 0                  0   \n",
      "1126                   0                 0                  0   \n",
      "938                    0                 0                  0   \n",
      "875                    3                 1                  3   \n",
      "51                    20                17                  0   \n",
      "2777                   0                 0                  0   \n",
      "892                    0                 0                  0   \n",
      "255                    0                 0                  0   \n",
      "1349                   1                 1                  0   \n",
      "1112                   0                 0                  0   \n",
      "1326                   1                 1                  1   \n",
      "1375                   1                 1                  0   \n",
      "2169                   0                 0                  0   \n",
      "31                     0                 0                  0   \n",
      "2868                   1                 0                  1   \n",
      "1588                   7                 5                  4   \n",
      "132                    1                 0                  0   \n",
      "1585                   1                 1                  1   \n",
      "1831                   0                 0                  0   \n",
      "2047                   2                 0                  1   \n",
      "...                  ...               ...                ...   \n",
      "2703                   0                 0                  0   \n",
      "2704                   0                 0                  0   \n",
      "2705                   0                 0                  0   \n",
      "2706                   0                 0                  0   \n",
      "2707                   0                 0                  0   \n",
      "2708                   0                 0                  0   \n",
      "2709                   0                 0                  0   \n",
      "2710                   0                 0                  0   \n",
      "2886                   0                 0                  0   \n",
      "2887                   0                 0                  0   \n",
      "2888                   0                 0                  0   \n",
      "2889                   0                 0                  0   \n",
      "2890                   0                 0                  0   \n",
      "2891                   0                 0                  0   \n",
      "2892                   0                 0                  0   \n",
      "2893                   0                 0                  0   \n",
      "2894                   0                 0                  0   \n",
      "2895                   0                 0                  0   \n",
      "2896                   0                 0                  0   \n",
      "2897                   0                 0                  0   \n",
      "2898                   0                 0                  0   \n",
      "2899                   0                 0                  0   \n",
      "2900                   0                 0                  0   \n",
      "2901                   0                 0                  0   \n",
      "2902                   0                 0                  0   \n",
      "2903                   0                 0                  0   \n",
      "2904                   0                 0                  0   \n",
      "2905                   0                 0                  0   \n",
      "2906                   0                 0                  0   \n",
      "2907                   0                 0                  0   \n",
      "\n",
      "      usefulCount_user  coolCount_user  funnyCount_user  complimentCount_user  \\\n",
      "1608                 8               1                1                     7   \n",
      "2717                 0               2                0                     0   \n",
      "2884                 9               3                4                     2   \n",
      "1099               409              99               80                    75   \n",
      "2778              9203            7853             8626                  7764   \n",
      "674                 36              12                3                     5   \n",
      "433                 97              31               32                    12   \n",
      "1071               260              72               91                    18   \n",
      "2822               234             151              109                    28   \n",
      "124                 25               9               18                     1   \n",
      "1219                 7               1                2                     0   \n",
      "1126                 1               1                1                     0   \n",
      "938                  2               0                1                     0   \n",
      "875              19514           17253            14329                 31185   \n",
      "51                3279            2331             1523                  1976   \n",
      "2777                35               6                1                     0   \n",
      "892                 52              23               10                    13   \n",
      "255                 44               9                9                     3   \n",
      "1349               944             654              836                   271   \n",
      "1112               118              73               47                    21   \n",
      "1326                 0               0                0                     0   \n",
      "1375                11               9                7                     4   \n",
      "2169              5290            4184             3285                  2813   \n",
      "31                  19              10                7                     2   \n",
      "2868                82              40               28                    25   \n",
      "1588                 1               0                0                     0   \n",
      "132                 31               6               17                     2   \n",
      "1585                37               8               21                     6   \n",
      "1831                 7               2                0                     1   \n",
      "2047                 0               0                2                     0   \n",
      "...                ...             ...              ...                   ...   \n",
      "2703               701             383              910                    81   \n",
      "2704              1825            1466             1238                  1588   \n",
      "2705                74              50               68                     6   \n",
      "2706                14               6                7                     1   \n",
      "2707                 9               2                0                     1   \n",
      "2708               174              77               65                    55   \n",
      "2709                 0               0                0                     0   \n",
      "2710               109              49               63                    22   \n",
      "2886               971             718             1024                   264   \n",
      "2887                57              35               23                    12   \n",
      "2888                13               9               11                     6   \n",
      "2889                48              15               12                     6   \n",
      "2890                12               3                0                     0   \n",
      "2891               200              70               12                    44   \n",
      "2892                 4               1                0                     9   \n",
      "2893               429             243              178                    54   \n",
      "2894               391             234              139                    83   \n",
      "2895                35              10               11                     7   \n",
      "2896                 1               1                1                     0   \n",
      "2897                 0               0                0                     1   \n",
      "2898              7575            7216             6603                 17700   \n",
      "2899                98              42               50                    16   \n",
      "2900                66              21               39                     7   \n",
      "2901               134             103               90                    46   \n",
      "2902                 4               0                4                     2   \n",
      "2903                24               9                9                     2   \n",
      "2904                 0               0                2                     0   \n",
      "2905                27              14                9                     2   \n",
      "2906               110              77               43                   114   \n",
      "2907                74              47               77                    11   \n",
      "\n",
      "      tipCount_user  fanCount_user  fakeUser_user  \n",
      "1608             24              0              0  \n",
      "2717              0              0              0  \n",
      "2884              0              0              0  \n",
      "1099             34              8              0  \n",
      "2778            322            327              0  \n",
      "674               0              0              0  \n",
      "433               0              3              0  \n",
      "1071              7              4              0  \n",
      "2822              2              3              0  \n",
      "124               0              0              0  \n",
      "1219              0              0              0  \n",
      "1126              0              0              0  \n",
      "938               0              1              0  \n",
      "875            1619            353              0  \n",
      "51                0             63              0  \n",
      "2777              0              0              0  \n",
      "892               0              2              0  \n",
      "255               0              0              0  \n",
      "1349              0             16              0  \n",
      "1112             19              0              0  \n",
      "1326              0              0              0  \n",
      "1375              6              0              0  \n",
      "2169              0             47              0  \n",
      "31                0              0              0  \n",
      "2868              0              0              0  \n",
      "1588              0              0              0  \n",
      "132               0              2              0  \n",
      "1585              0              1              0  \n",
      "1831              0              0              0  \n",
      "2047              0              0              1  \n",
      "...             ...            ...            ...  \n",
      "2703              0             16              0  \n",
      "2704            312             45              0  \n",
      "2705              2              2              0  \n",
      "2706              0              0              0  \n",
      "2707              0              0              0  \n",
      "2708             10              5              0  \n",
      "2709              0              0              0  \n",
      "2710            483              1              0  \n",
      "2886             11             24              0  \n",
      "2887              0              4              0  \n",
      "2888              0              0              0  \n",
      "2889             65              0              0  \n",
      "2890              6              0              0  \n",
      "2891              0              1              0  \n",
      "2892             14              0              0  \n",
      "2893              0             14              0  \n",
      "2894              0              3              0  \n",
      "2895              0              0              0  \n",
      "2896              0              0              0  \n",
      "2897              1              0              0  \n",
      "2898            115            205              0  \n",
      "2899              0              0              0  \n",
      "2900             43              2              0  \n",
      "2901              0              6              0  \n",
      "2902              0              0              0  \n",
      "2903              0              0              0  \n",
      "2904              0              0              0  \n",
      "2905              0              1              0  \n",
      "2906              0              3              0  \n",
      "2907              8              1              0  \n",
      "\n",
      "[784 rows x 10 columns]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1]\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "775",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32mC:\\Users\\Paula\\Anaconda3\\lib\\site-packages\\pandas\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2103\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2104\u001b[0;31m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2105\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas\\index.pyx\u001b[0m in \u001b[0;36mpandas.index.IndexEngine.get_loc (pandas\\index.c:4160)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas\\index.pyx\u001b[0m in \u001b[0;36mpandas.index.IndexEngine.get_loc (pandas\\index.c:4024)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas\\src\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas.hashtable.PyObjectHashTable.get_item (pandas\\hashtable.c:13161)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas\\src\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas.hashtable.PyObjectHashTable.get_item (pandas\\hashtable.c:13115)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 775",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-61b458d2c0a8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mencodeVariables\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32mmtrand.pyx\u001b[0m in \u001b[0;36mmtrand.RandomState.shuffle (numpy\\random\\mtrand\\mtrand.c:34696)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mmtrand.pyx\u001b[0m in \u001b[0;36mmtrand.RandomState.shuffle (numpy\\random\\mtrand\\mtrand.c:34645)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Paula\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2055\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   2056\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2057\u001b[0;31m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_column\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2058\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   2059\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_getitem_column\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Paula\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_getitem_column\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2062\u001b[0m         \u001b[1;31m# get column\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   2063\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2064\u001b[0;31m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_item_cache\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2065\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   2066\u001b[0m         \u001b[1;31m# duplicate columns & possible reduce dimensionality\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Paula\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_get_item_cache\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m   1384\u001b[0m         \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1385\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1386\u001b[0;31m             \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1387\u001b[0m             \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_box_item_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1388\u001b[0m             \u001b[0mcache\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Paula\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, item, fastpath)\u001b[0m\n\u001b[1;32m   3518\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   3519\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misnull\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3520\u001b[0;31m                 \u001b[0mloc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3521\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   3522\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0misnull\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Paula\\Anaconda3\\lib\\site-packages\\pandas\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2104\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   2105\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2106\u001b[0;31m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2107\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   2108\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas\\index.pyx\u001b[0m in \u001b[0;36mpandas.index.IndexEngine.get_loc (pandas\\index.c:4160)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas\\index.pyx\u001b[0m in \u001b[0;36mpandas.index.IndexEngine.get_loc (pandas\\index.c:4024)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas\\src\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas.hashtable.PyObjectHashTable.get_item (pandas\\hashtable.c:13161)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas\\src\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas.hashtable.PyObjectHashTable.get_item (pandas\\hashtable.c:13115)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 775"
     ]
    }
   ],
   "source": [
    "def encodeVariables():\n",
    "    \n",
    "    target_variable = \"fake_review\" # target variable\n",
    "    \n",
    "    dropVariableList = [\n",
    "        \n",
    "        ###all list of variables, then choose the ones to keep\n",
    "        \n",
    "        #REVIEW FEATURES\n",
    "        \n",
    "        \n",
    "        \n",
    "        'date_review', #not useful\n",
    "        'reviewID_review', #not useful\n",
    "        'reviewContent_review', #not useful after having the features\n",
    "        'rating_review', \n",
    "        #'usefulCount_review', #correlated 1\n",
    "        #'coolCount_review',  #correlated 1\n",
    "        #'funnyCount_review', #correlated 1\n",
    "        'popularity_review', \n",
    "        \n",
    "        #USER FEATURES\n",
    "        \n",
    "        'reviewerID_user', #not useful\n",
    "        'name_user', #not useful\n",
    "        'location_user', #not useful\n",
    "        'yelpJoinDate_user', #not useful\n",
    "        'friendCount_user', #mean proves it distinguish among the groups, #based on feature selection\n",
    "        'reviewCount_user', #mean proves it distinguish among the groups\n",
    "        'firstCount_user', # very strange patern in the mean values\n",
    "        #'usefulCount_user', # correlated 2\n",
    "        #'coolCount_user', # correlated 2\n",
    "        #'funnyCount_user', # correlated 2\n",
    "        #'complimentCount_user', # correlated 2\n",
    "        #'tipCount_user', # very strange patern in the mean values\n",
    "        #'fanCount_user', # correlated 2\n",
    "        'reviewsPerDay_user', \n",
    "        'percentageReviews_user', #based on feature selection\n",
    "        'reviewSimilarity_user', #based on feature selection\n",
    "        'popularity_user', #based on feature selection\n",
    "        \n",
    "        #HOTEL FEATURES\n",
    "        \n",
    "        'hotelID_hotel', #not useful\n",
    "        'name_hotel',  #not useful\n",
    "        'location_hotel', #not useful\n",
    "        'reviewCount_hotel',# correlated 3\n",
    "        'rating_hotel', # correlated 4\n",
    "        'categories_hotel', #not useful\n",
    "        'address_hotel', #not useful\n",
    "        'AcceptsCreditCards_hotel', #not useful\n",
    "        'PriceRange_hotel', #not useful \n",
    "        'WiFi_hotel', #not useful\n",
    "        'webSite_hotel', #not useful\n",
    "        'phoneNumber_hotel',#not useful\n",
    "        'filReviewCount_hotel', #based on feature selection\n",
    "        'deviatonReviewHotel',\n",
    "        \n",
    "        #TEXT MINING FEATURES\n",
    "        'text_length',\n",
    "        'word_count', #based on feature selection\n",
    "        'count_pronouns', #based on feature selection\n",
    "        'count_associated_actions',#based on feature selection\n",
    "        'count_targets', #based on feature selection\n",
    "        'count_emotion_words' #based on feature selection\n",
    "        \n",
    "        #EXTRA FEATURES\n",
    "        #'fakeUser'\n",
    "        \n",
    "        ]\n",
    " \n",
    "    # Drop variables in the X\n",
    "    X_train = train_df_joined.drop(dropVariableList, axis=1)\n",
    "    X_train = X_train.drop(target_variable, axis=1)\n",
    "    X_test = test_df_joined.drop(dropVariableList, axis=1)\n",
    "    X_test = X_test.drop(\"id_review\", axis=1)\n",
    "    \n",
    "    # Drop variables in the Y\n",
    "    Y_train = train_df_joined[\"fake_review\"]\n",
    "\n",
    "    # Transform categorical variables for X_train:\n",
    "    categoricalVariableList = [\n",
    "        #\"AcceptsCreditCards_hotel\",\n",
    "        #\"PriceRange_hotel\",\n",
    "        #\"WiFi_hotel\"\n",
    "    ]\n",
    "    \n",
    "    for var_name in categoricalVariableList:\n",
    "        encoder = skpre.LabelEncoder().fit(X_train[var_name])\n",
    "        X_train[var_name] = encoder.transform(X_train[var_name])\n",
    "        X_test[var_name] = encoder.transform(X_test[var_name])\n",
    "\n",
    "    # Transform categorical variables for Y_train\n",
    "    Y_train = skpre.LabelEncoder().fit_transform(Y_train)\n",
    "\n",
    "    print(X_train)\n",
    "    #print(X_test)\n",
    "    print(Y_train)\n",
    "    \n",
    "    return X_train, Y_train, X_test\n",
    "    \n",
    "X_train, Y_train, X_test = encodeVariables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sum(Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def featureNormalization():\n",
    "    global X_train\n",
    "    global X_test\n",
    "    \n",
    "    scaler = skpre.StandardScaler().fit(X_train)\n",
    "    X_train = scaler.transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "    \n",
    "#featureNormalization()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save for CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train.to_csv(\"X_train.csv\", index = False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 - Model selection based on which models do best in CV using default settings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier().fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rf.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fe_v = [ 0.06769878,  0.08105388,  0.08188304,  0.01007828,  0.01464884,\n",
    "        0.01141371,  0.08350329,  0.06392067,  0.07042613,  0.01676487,\n",
    "        0.051405  ,  0.03442772,  0.0786505 ,  0.2648185 ,  0.0693068 ]\n",
    "\n",
    "fe_n = ['friendCount_user', 'reviewCount_user', 'reviewsPerDay_user',\n",
    "       'percentageReviews_user', 'reviewSimilarity_user',\n",
    "       'filReviewCount_hotel', 'text_length', 'word_count', 'count_pronouns',\n",
    "       'count_associated_actions', 'count_targets', 'count_emotion_words',\n",
    "       'deviatonReviewHotel', 'popularity_review', 'popularity_user']\n",
    "\n",
    "features = []\n",
    "for i in range(0, len(fe_v)):\n",
    "    features.append((fe_v[i], fe_n[i]))\n",
    "    \n",
    "features.sort(key = lambda x: x[0], reverse = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#inspired in http://machinelearningmastery.com/compare-machine-learning-algorithms-python-scikit-learn/\n",
    "\n",
    "import sklearn.model_selection as mds\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "#import xgboost as xgb\n",
    "\n",
    "def modelSelection():\n",
    "\n",
    "    # prepare data\n",
    "\n",
    "    #Y_train = train_df[:,-1]\n",
    "    #X_train = train_df[:,:-1]\n",
    "\n",
    "    #Y_train = train_df[len(train_df.columns)-1]\n",
    "    #X_train = train_df.drop(len(train_df.columns)-1,axis=1)\n",
    "\n",
    "    # prepare configuration for cross validation test harness\n",
    "    num_folds = 10\n",
    "    num_instances = len(X_train)\n",
    "\n",
    "    # prepare models\n",
    "    models = []\n",
    "    models.append(('LR', LogisticRegression()))\n",
    "    models.append(('LDA', LinearDiscriminantAnalysis()))\n",
    "    models.append(('KNN', KNeighborsClassifier()))\n",
    "    models.append(('CART', DecisionTreeClassifier()))\n",
    "    models.append(('NB', GaussianNB()))\n",
    "    #models.append(('SVM-Linear', SVC(kernel=\"linear\")))\n",
    "    #models.append(('SVM-Poly', SVC(kernel=\"poly\")))\n",
    "    models.append(('SVM-RBF', SVC(kernel=\"rbf\")))\n",
    "    models.append(('NN', MLPClassifier())) \n",
    "    models.append(('RF', RandomForestClassifier(criterion=\"entropy\", n_estimators=40)))\n",
    "    models.append(('AB', AdaBoostClassifier()))\n",
    "    #models.append(('XGB', xgb.XGBClassifier()))\n",
    "\n",
    "    # evaluate each model in turn\n",
    "    results = []\n",
    "    scoring = 'roc_auc' # try with 'roc_auc', f1'\n",
    "\n",
    "    kfold = mds.StratifiedKFold(n_splits=num_folds, shuffle=True, random_state=2)\n",
    "\n",
    "    for model_name, model in models:\n",
    "        cv_results = mds.cross_val_score(model, X_train, Y_train, cv=kfold, scoring=scoring)\n",
    "        results.append({\"name\": model_name, \"cv_results\": cv_results, \"mean\": cv_results.mean(), \"std\": cv_results.std()})\n",
    "        print(\"%s: %f (%f)\" % (model_name, cv_results.mean(), cv_results.std()))\n",
    "\n",
    "    # boxplot algorithm comparison\n",
    "    fig = plt.figure(figsize=(13, 5), dpi=500)\n",
    "    fig.suptitle('Algorithm Comparison')\n",
    "    ax = fig.add_subplot(111)\n",
    "    plt.boxplot([x[\"cv_results\"] for x in results])\n",
    "    ax.set_xticklabels([x[\"name\"] for x in results])\n",
    "    plt.show()\n",
    "\n",
    "    # order the models by the mean auc\n",
    "    #results_by_strategy.sort(key=lambda x: x[\"mean\"], reverse=True)\n",
    "    #print([(x[\"name\"], x[\"mean\"]) for x in results])\n",
    "\n",
    "modelSelection()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results sorted by AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "results_sorted = [(na_method, algorithm[\"name\"], algorithm[\"mean\"]) for na_method in results for algorithm in results[na_method]]\n",
    "results_sorted.sort(key=lambda x: x[2], reverse=True)\n",
    "results_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plotSupervisedAlgorithmsDefault(inf, sup):\n",
    "    plt.figure(figsize=(13, 7), dpi=500)\n",
    "    \n",
    "    # x axis\n",
    "    labels = [na_method for na_method in results]\n",
    "    labels.sort()\n",
    "    plt.xticks(np.arange(len(labels)), labels, rotation='vertical')\n",
    "    plt.ylim(inf, sup)\n",
    "    \n",
    "    # legend:\n",
    "    algorithm_names = [x[\"name\"] for x in results[\"01-zero\"]] \n",
    "    \n",
    "    [plt.plot([[x[\"mean\"] for x in results[na_method] if x[\"name\"] == alg_name] for na_method in sorted(results)],\n",
    "              label = alg_name) for alg_name in algorithm_names]\n",
    "    \n",
    "    plt.ylabel('AUC')\n",
    "    plt.xlabel('NA-filling method')\n",
    "    \n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "    plt.show()\n",
    "    \n",
    "plotSupervisedAlgorithmsDefault(0.69, 1)\n",
    "plotSupervisedAlgorithmsDefault(0.9, 1)\n",
    "plotSupervisedAlgorithmsDefault(0.99, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Based on this plot, we decided to tune XGB and LDA and use 07-spec-mean and 09-spec-min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plotConfusionMatrixBestXGB():\n",
    "    kfold = mds.StratifiedKFold(n_splits=2, shuffle=True, random_state=2)\n",
    "    train, test = kfold.split(datasets[\"07-spec-mean\"][\"train\"], Y_train)\n",
    "\n",
    "    lol = xgb.XGBClassifier().fit(datasets[\"07-spec-mean\"][\"train\"].iloc[train[0]], Y_train[train[0]])\n",
    "\n",
    "    train1_pred = lol.predict(datasets[\"07-spec-mean\"][\"train\"].iloc[train[1]])\n",
    "\n",
    "    plot_confusion_matrix(confusion_matrix(Y_train[train[1]], train1_pred, labels = [0, 1]), classes = [0, 1])\n",
    "    \n",
    "plotConfusionMatrixBestXGB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plotConfusionMatrixBestLDA():\n",
    "    kfold = mds.StratifiedKFold(n_splits=2, shuffle=True, random_state=2)\n",
    "    train, test = kfold.split(datasets[\"09-spec-min\"][\"train\"], Y_train)\n",
    "\n",
    "    lol = xgb.XGBClassifier().fit(datasets[\"09-spec-min\"][\"train\"].iloc[train[0]], Y_train[train[0]])\n",
    "\n",
    "    train1_pred = lol.predict(datasets[\"09-spec-min\"][\"train\"].iloc[train[1]])\n",
    "\n",
    "    plot_confusion_matrix(confusion_matrix(Y_train[train[1]], train1_pred, labels = [0, 1]), classes = [0, 1])\n",
    "    \n",
    "plotConfusionMatrixBestLDA()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.1 - Tuning of the best models\n",
    "#### Based on this plot, we decided to tune LDA and XGB\n",
    "### Tuning XGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Adapted from https://www.analyticsvidhya.com/blog/2016/03/complete-guide-parameter-tuning-xgboost-with-codes-python/\n",
    "def modelfit(alg, train_predictors, train_target, useTrainCV=True, cv_folds=10, early_stopping_rounds=50):\n",
    "    \n",
    "    if useTrainCV:\n",
    "        xgb_param = alg.get_xgb_params()\n",
    "        xgtrain = xgb.DMatrix(train_predictors.values, label=train_target.values)\n",
    "        cvresult = xgb.cv(xgb_param, xgtrain, num_boost_round=alg.get_params()['n_estimators'], nfold=cv_folds,\n",
    "            metrics='auc', early_stopping_rounds=early_stopping_rounds, verbose_eval=True)\n",
    "        alg.set_params(n_estimators=cvresult.shape[0])\n",
    "    \n",
    "    #Fit the algorithm on the data\n",
    "    alg.fit(train_predictors, train_target, eval_metric='auc')\n",
    "        \n",
    "    #Predict training set:\n",
    "    dtrain_predictions = alg.predict(train_predictors)\n",
    "    dtrain_predprob = alg.predict_proba(train_predictors)[:,1]\n",
    "        \n",
    "    #Print model report:\n",
    "    print(\"\\nModel Report\")\n",
    "    print(\"Accuracy : %.4g\" % metrics.accuracy_score(train_target.values, dtrain_predictions))\n",
    "    print(\"AUC Score (Train): %f\" % metrics.roc_auc_score(train_target, dtrain_predprob))\n",
    "                    \n",
    "    #feat_imp = pd.Series(alg.booster().get_fscore()).sort_values(ascending=False)\n",
    "    #feat_imp.plot(kind='bar', title='Feature Importances')\n",
    "    #plt.ylabel('Feature Importance Score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics   #Additional scklearn functions\n",
    "from sklearn.model_selection import GridSearchCV   #Perforing grid search\n",
    "\n",
    "def tuneXGB1():\n",
    "    xgb1 = xgb.XGBClassifier(\n",
    "        learning_rate=0.1,\n",
    "        n_estimators=1000,\n",
    "        max_depth=5, # This should be between 3-10\n",
    "        min_child_weight=1, # A smaller value is chosen because it is a highly imbalanced class problem\n",
    "        gamma=0,\n",
    "        subsample=0.8, # Typical values range between 0.5-0.9.\n",
    "        colsample_bytree=0.8, # Typical values range between 0.5-0.9.\n",
    "        objective= 'binary:logistic',\n",
    "        #nthread=4,\n",
    "        scale_pos_weight=1, # Because of high class imbalance\n",
    "        seed=2)\n",
    "    \n",
    "    modelfit(xgb1, datasets[\"07-spec-mean\"][\"train\"], Y_train)\n",
    "    \n",
    "tuneXGB1()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This last result seems too good to be truth?!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def tuneXGB2():\n",
    "    param_test1 = {\n",
    "        'max_depth': np.arange(3,10,2),\n",
    "        'min_child_weight': np.arange(1,6,2)\n",
    "    }\n",
    "    \n",
    "    gsearch1 = GridSearchCV(estimator = xgb.XGBClassifier( learning_rate=0.1, n_estimators=156, max_depth=5,\n",
    "                                                      min_child_weight=1, gamma=0, subsample=0.8, colsample_bytree=0.8,\n",
    "                                                      objective= 'binary:logistic', scale_pos_weight=1, seed=2), \n",
    "                            param_grid = param_test1, scoring='roc_auc',iid=False, cv=10)\n",
    "    \n",
    "    gsearch1.fit(datasets[\"07-spec-mean\"][\"train\"], Y_train)\n",
    "    print(gsearch1.grid_scores_, gsearch1.best_params_, gsearch1.best_score_)\n",
    "    \n",
    "tuneXGB2()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### {'max_depth': 7, 'min_child_weight': 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def tuneXGB3():\n",
    "    param_test1 = {\n",
    "        'max_depth': [6,7,8],\n",
    "        'min_child_weight': [1,2,3]\n",
    "    }\n",
    "    \n",
    "    gsearch1 = GridSearchCV(estimator = xgb.XGBClassifier( learning_rate=0.1, n_estimators=156, max_depth=5,\n",
    "                                                      min_child_weight=1, gamma=0, subsample=0.8, colsample_bytree=0.8,\n",
    "                                                      objective= 'binary:logistic', scale_pos_weight=1, seed=2), \n",
    "                            param_grid = param_test1, scoring='roc_auc',iid=False, cv=10)\n",
    "    \n",
    "    gsearch1.fit(datasets[\"07-spec-mean\"][\"train\"], Y_train)\n",
    "    print(gsearch1.grid_scores_, gsearch1.best_params_, gsearch1.best_score_)\n",
    "    \n",
    "tuneXGB3()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def tuneXGB4():\n",
    "    param_test1 = {\n",
    "        'gamma':[i/10.0 for i in np.arange(0,5)]\n",
    "    }\n",
    "    \n",
    "    gsearch1 = GridSearchCV(estimator = xgb.XGBClassifier( learning_rate=0.1, n_estimators=156, max_depth=7,\n",
    "                                                      min_child_weight=1, gamma=0, subsample=0.8, colsample_bytree=0.8,\n",
    "                                                      objective= 'binary:logistic', scale_pos_weight=1, seed=2), \n",
    "                            param_grid = param_test1, scoring='roc_auc',iid=False, cv=10)\n",
    "    \n",
    "    gsearch1.fit(datasets[\"07-spec-mean\"][\"train\"], Y_train)\n",
    "    print(gsearch1.grid_scores_, gsearch1.best_params_, gsearch1.best_score_)\n",
    "    \n",
    "tuneXGB4()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### gamma = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def tuneXGB5():\n",
    "    xgb1 = xgb.XGBClassifier(\n",
    "        learning_rate=0.1,\n",
    "        n_estimators=1000,\n",
    "        max_depth=7, # This should be between 3-10\n",
    "        min_child_weight=1, # A smaller value is chosen because it is a highly imbalanced class problem\n",
    "        gamma=0,\n",
    "        subsample=0.8, # Typical values range between 0.5-0.9.\n",
    "        colsample_bytree=0.8, # Typical values range between 0.5-0.9.\n",
    "        objective= 'binary:logistic',\n",
    "        #nthread=4,\n",
    "        scale_pos_weight=1, # Because of high class imbalance\n",
    "        seed=2)\n",
    "    \n",
    "    modelfit(xgb1, datasets[\"07-spec-mean\"][\"train\"], Y_train)\n",
    "    \n",
    "tuneXGB5()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def tuneXGB6():\n",
    "    param_test1 = {\n",
    "     'subsample': np.arange(0.6, 1.0, 0.1),\n",
    "     'colsample_bytree': np.arange(0.6, 1.0, 0.1)\n",
    "    }\n",
    "    \n",
    "    gsearch1 = GridSearchCV(estimator = xgb.XGBClassifier( learning_rate=0.1, n_estimators=156, max_depth=7,\n",
    "                                                      min_child_weight=1, gamma=0, subsample=0.8, colsample_bytree=0.8,\n",
    "                                                      objective= 'binary:logistic', scale_pos_weight=1, seed=2), \n",
    "                            param_grid = param_test1, scoring='roc_auc',iid=False, cv=10)\n",
    "    \n",
    "    gsearch1.fit(datasets[\"07-spec-mean\"][\"train\"], Y_train)\n",
    "    print(gsearch1.grid_scores_, gsearch1.best_params_, gsearch1.best_score_)\n",
    "    \n",
    "tuneXGB6()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### subsample = 0.6 and colsample_bytree = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def tuneXGB7():\n",
    "    param_test1 = {\n",
    "     'subsample': np.arange(0.55, 0.7, 0.05),\n",
    "     'colsample_bytree': np.arange(0.85, 1.0, 0.05)\n",
    "    }\n",
    "    \n",
    "    gsearch1 = GridSearchCV(estimator = xgb.XGBClassifier( learning_rate=0.1, n_estimators=156, max_depth=7,\n",
    "                                                      min_child_weight=1, gamma=0, subsample=0.8, colsample_bytree=0.8,\n",
    "                                                      objective= 'binary:logistic', scale_pos_weight=1, seed=2), \n",
    "                            param_grid = param_test1, scoring='roc_auc',iid=False, cv=10)\n",
    "    \n",
    "    gsearch1.fit(datasets[\"07-spec-mean\"][\"train\"], Y_train)\n",
    "    print(gsearch1.grid_scores_, gsearch1.best_params_, gsearch1.best_score_)\n",
    "    \n",
    "tuneXGB7()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### better tuned: subsample=0.55 and colsample_bytree=0.85"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def tuneXGB8():\n",
    "    param_test1 = {\n",
    "     'reg_alpha':[1e-5, 1e-2, 0.1, 1, 100]\n",
    "    }\n",
    "    \n",
    "    gsearch1 = GridSearchCV(estimator = xgb.XGBClassifier( learning_rate=0.1, n_estimators=156, max_depth=7,\n",
    "                                                      min_child_weight=1, gamma=0, subsample=0.55, colsample_bytree=0.85,\n",
    "                                                      objective= 'binary:logistic', scale_pos_weight=1, seed=2), \n",
    "                            param_grid = param_test1, scoring='roc_auc',iid=False, cv=10)\n",
    "    \n",
    "    gsearch1.fit(datasets[\"07-spec-mean\"][\"train\"], Y_train)\n",
    "    print(gsearch1.grid_scores_, gsearch1.best_params_, gsearch1.best_score_)\n",
    "    \n",
    "tuneXGB8()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reg alpha = 1e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def tuneXGB9():    \n",
    "    xgb1 = xgb.XGBClassifier( learning_rate=0.01, n_estimators=5000, max_depth=7,\n",
    "                      min_child_weight=1, gamma=0, subsample=0.55, colsample_bytree=0.85,\n",
    "                      reg_alpha=1e-5, objective= 'binary:logistic', scale_pos_weight=1, seed=2)\n",
    "    \n",
    "    modelfit(xgb1, datasets[\"07-spec-mean\"][\"train\"], Y_train)\n",
    "    \n",
    "tuneXGB9()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def tuneLDA():\n",
    "    param_test1 = [{\"solver\": [\"svd\"], \"n_components\": np.arange(1,len(X_train.columns) - 1)},\n",
    "                   {\"solver\": [\"lsqr\", \"eigen\"], \"n_components\": np.arange(1,len(X_train.columns) - 1), \"shrinkage\": [\"auto\"]}]\n",
    "        \n",
    "    gsearch1 = GridSearchCV(estimator=LinearDiscriminantAnalysis(), \n",
    "                            param_grid = param_test1, scoring='roc_auc', cv=10)\n",
    "    \n",
    "    fit = gsearch1.fit(datasets[\"09-spec-min\"][\"train\"], Y_train)\n",
    "    return(fit)\n",
    "    \n",
    "bestLDAfit = tuneLDA()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bestLDAfit.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bestLDAfit.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def evaluatingBestLDA():\n",
    "    kfold = mds.StratifiedKFold(n_splits=num_folds, shuffle=True, random_state=2)\n",
    "    model = LinearDiscriminantAnalysis(n_components = 1, shrinkage = \"auto\", solver=\"lsqr\")\n",
    "    \n",
    "    cv_results = mds.cross_val_score(model, datasets[\"09-spec-min\"][\"train\"], Y_train, cv=kfold, scoring=\"roc_auc\")\n",
    "    print(cv_results.mean())\n",
    "    \n",
    "evaluatingBestLDA()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 - Unsupervised Anomaly Detection Methods\n",
    "We decided to try LOF and see how it goes. We used our implementation from HW1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import lof_pal as lof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def makePredictonsLOF():\n",
    "    outliers = []\n",
    "    \n",
    "    kfold = mds.StratifiedKFold(n_splits=2, shuffle=True, random_state=2)\n",
    "    sets,_ = kfold.split(datasets[\"07-spec-mean\"][\"train\"], Y_train)                                      \n",
    "    \n",
    "    # Train with only positive examples:\n",
    "    l = lof.LOF(datasets[\"07-spec-mean\"][\"train\"].iloc[sets[0]][Y_train[sets[0]] != 1], 3)\n",
    "    \n",
    "    Y_pred = [1 if x > 1.2 else 0 for x in l.predict(datasets[\"07-spec-mean\"][\"train\"].iloc[sets[1]])]\n",
    "        \n",
    "    plot_confusion_matrix(confusion_matrix(Y_train[sets[1]], Y_pred, labels = [0, 1]), classes = [0, 1])\n",
    "    #return Y_pred\n",
    "        \n",
    "    \n",
    "makePredictonsLOF()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 - Submission to Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# choose algorithm\n",
    "def makeSubmissionKaggle(algorithm):\n",
    "    algorithm.fit(X_train, Y_train)\n",
    "    Y_pred = algorithm.predict(X_test)\n",
    "    Y_pred = Y_pred.astype(int)\n",
    "\n",
    "    # save data to CSV\n",
    "    saveDataToCSV(Y_pred)\n",
    "    \n",
    "#makeSubmissionKaggle(\"07-spec-mean\", xgb.XGBClassifier( learning_rate=0.01, n_estimators=5000, max_depth=7,\n",
    "#                      min_child_weight=1, gamma=0, subsample=0.55, colsample_bytree=0.85,\n",
    "#                      reg_alpha=1e-5, objective= 'binary:logistic', scale_pos_weight=1, seed=2))\n",
    "\n",
    "#makeSubmissionKaggle(\"09-spec-min\", LinearDiscriminantAnalysis(n_components = 1, shrinkage = \"auto\", solver=\"lsqr\"))\n",
    "makeSubmissionKaggle(RandomForestClassifier(criterion=\"entropy\", n_estimators=40))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
