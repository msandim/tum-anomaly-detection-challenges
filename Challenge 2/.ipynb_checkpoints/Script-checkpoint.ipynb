{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Anomaly Detection Challenge 1\n",
    "## Miguel Sandim and Paula Fortuna"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 - Data Reading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 - Solve format problems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1.1 -  yelp_data_train.dat and yelp_data_test.dat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a text editor (e. g. sublime) use regex.\n",
    "\n",
    "1) Replace \" by \"\"\n",
    "\n",
    "2) Surround text field with \"\n",
    "To match the first one use this (dont forget to remove the one that appears also in the begining of the sentence, and the one in the header):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "^[^;]*;[^;]*;[^;]*;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use this to find the last:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ";[^;]*;[^;]*;[^;]*;[^;]*;[^;]*;[^;]*$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) check if all the lines match the refered structure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "^[^;]*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4) Remove random newlines that appear in the rows and make new instance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1.2 - yelp_data_reviewer.dat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) ; caracter removed from fields"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) smiles removed from fields"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Load data (finally!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# pandas\n",
    "import pandas as pd\n",
    "from pandas import Series,DataFrame\n",
    "\n",
    "# numpy, matplotlib, seaborn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "# Random libraries and seeds:\n",
    "import random\n",
    "random.seed(2)\n",
    "np.random.seed(2)\n",
    "\n",
    "# read from csv\n",
    "\n",
    "\n",
    "#train_df = pd.read_csv(\"data/yelp_data_train.dat\", sep = ';', encoding = 'utf-8')\n",
    "#test_df = pd.read_csv(\"data/yelp_data_test.dat\", sep = ';', encoding = 'utf-8')\n",
    "#reviewers_df = pd.read_csv(\"data/yelp_data_reviewer.dat\", sep = ';', encoding = 'utf-8')\n",
    "#hotels_df = pd.read_csv(\"data/yelp_data_hotel.dat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>name</th>\n",
       "      <th>location</th>\n",
       "      <th>yelpJoinDate</th>\n",
       "      <th>friendCount</th>\n",
       "      <th>reviewCount</th>\n",
       "      <th>firstCount</th>\n",
       "      <th>usefulCount</th>\n",
       "      <th>coolCount</th>\n",
       "      <th>funnyCount</th>\n",
       "      <th>complimentCount</th>\n",
       "      <th>tipCount</th>\n",
       "      <th>fanCount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>yevHGEUQQmnVlBXIrJ885A</td>\n",
       "      <td>Kevin T.</td>\n",
       "      <td>Oconomowoc, WI</td>\n",
       "      <td>May 2011</td>\n",
       "      <td>4</td>\n",
       "      <td>86</td>\n",
       "      <td>3</td>\n",
       "      <td>129</td>\n",
       "      <td>47</td>\n",
       "      <td>31</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>yoB_PYQHjnPjh78ATA0Jgw</td>\n",
       "      <td>Veronica B.</td>\n",
       "      <td>Saint Paul, MN</td>\n",
       "      <td>January 2010</td>\n",
       "      <td>5</td>\n",
       "      <td>49</td>\n",
       "      <td>5</td>\n",
       "      <td>63</td>\n",
       "      <td>34</td>\n",
       "      <td>21</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XrFCag4AMW5qta9QXokWPA</td>\n",
       "      <td>Paul The Commander M.</td>\n",
       "      <td>Saint Louis, MO</td>\n",
       "      <td>August 2008</td>\n",
       "      <td>15</td>\n",
       "      <td>135</td>\n",
       "      <td>29</td>\n",
       "      <td>235</td>\n",
       "      <td>85</td>\n",
       "      <td>102</td>\n",
       "      <td>72</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>y5ptsWmvGEAftOQaiFhBcg</td>\n",
       "      <td>Stella BraveTart J.</td>\n",
       "      <td>Lexington-Fayette, KY</td>\n",
       "      <td>September 2009</td>\n",
       "      <td>49</td>\n",
       "      <td>104</td>\n",
       "      <td>36</td>\n",
       "      <td>282</td>\n",
       "      <td>83</td>\n",
       "      <td>92</td>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>uUVZJm9yxNl5FBsXbt4WBg</td>\n",
       "      <td>Ginger 'where's my meds' v.</td>\n",
       "      <td>San Francisco, CA</td>\n",
       "      <td>August 2008</td>\n",
       "      <td>22</td>\n",
       "      <td>34</td>\n",
       "      <td>2</td>\n",
       "      <td>81</td>\n",
       "      <td>32</td>\n",
       "      <td>52</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ZCRY4GLLTli8tZRPi1P7Cw</td>\n",
       "      <td>Johan Johanna S.</td>\n",
       "      <td>San Leandro, CA</td>\n",
       "      <td>August 2010</td>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>uOFIY6vBBp7O6un8CLggTw</td>\n",
       "      <td>Daniel Don Quijote K.</td>\n",
       "      <td>Honolulu, HI</td>\n",
       "      <td>June 2011</td>\n",
       "      <td>72</td>\n",
       "      <td>51</td>\n",
       "      <td>0</td>\n",
       "      <td>57</td>\n",
       "      <td>19</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>tdE3__i2otI_nL3M3sy0MQ</td>\n",
       "      <td>Jen Mme Federer C.</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>December 2008</td>\n",
       "      <td>136</td>\n",
       "      <td>238</td>\n",
       "      <td>37</td>\n",
       "      <td>200</td>\n",
       "      <td>103</td>\n",
       "      <td>40</td>\n",
       "      <td>55</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Uu-qEGsSb72ngIQUF85rDQ</td>\n",
       "      <td>Anna P.</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>March 2010</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>zyk-YPhtFZK6kkbpzEKrWw</td>\n",
       "      <td>Kara P.</td>\n",
       "      <td>Covington, KY</td>\n",
       "      <td>December 2009</td>\n",
       "      <td>66</td>\n",
       "      <td>49</td>\n",
       "      <td>2</td>\n",
       "      <td>51</td>\n",
       "      <td>19</td>\n",
       "      <td>14</td>\n",
       "      <td>27</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>V2OQaeZvePoGkbZ-Uye6KA</td>\n",
       "      <td>Rachel here's lookin at U.</td>\n",
       "      <td>Philadelphia, PA</td>\n",
       "      <td>October 2007</td>\n",
       "      <td>52</td>\n",
       "      <td>234</td>\n",
       "      <td>21</td>\n",
       "      <td>554</td>\n",
       "      <td>402</td>\n",
       "      <td>192</td>\n",
       "      <td>163</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>TYSR6svM9HQoqgBUpQH7GQ</td>\n",
       "      <td>Jeffrey A.</td>\n",
       "      <td>Los Angeles, CA</td>\n",
       "      <td>June 2011</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>vvB_c7yYIA1bnjgb3aPckg</td>\n",
       "      <td>Craig H.</td>\n",
       "      <td>Gridley, IL</td>\n",
       "      <td>February 2006</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>wiD0JGjaifHO5rTF49dJlg</td>\n",
       "      <td>penny h.</td>\n",
       "      <td>Chicago, IL</td>\n",
       "      <td>February 2007</td>\n",
       "      <td>0</td>\n",
       "      <td>52</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>WFfMbs9iXsYZT9GHfVCLTA</td>\n",
       "      <td>Esther P.</td>\n",
       "      <td>Chicago, IL</td>\n",
       "      <td>December 2011</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>UqYndXp9pbFpapebnIleTw</td>\n",
       "      <td>Amy w.</td>\n",
       "      <td>Richardson, TX</td>\n",
       "      <td>February 2009</td>\n",
       "      <td>8</td>\n",
       "      <td>43</td>\n",
       "      <td>1</td>\n",
       "      <td>42</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>TIlh76nA82VBpXK_XuoOBg</td>\n",
       "      <td>c m.</td>\n",
       "      <td>Chicago, IL</td>\n",
       "      <td>May 2010</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>x1uo32SAD_XMq0ulqC8_OQ</td>\n",
       "      <td>Shadow shadow K.</td>\n",
       "      <td>San Diego, CA</td>\n",
       "      <td>April 2011</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Ztd3ZxcPSCXv01MZTBXVZQ</td>\n",
       "      <td>Emily W.</td>\n",
       "      <td>Berkeley, CA</td>\n",
       "      <td>December 2006</td>\n",
       "      <td>13</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>TtwhWwNSqDv64M2EnYZE8g</td>\n",
       "      <td>Michael The best is good enough for me S.</td>\n",
       "      <td>Denver, CO</td>\n",
       "      <td>January 2007</td>\n",
       "      <td>511</td>\n",
       "      <td>838</td>\n",
       "      <td>175</td>\n",
       "      <td>4146</td>\n",
       "      <td>3448</td>\n",
       "      <td>3411</td>\n",
       "      <td>2458</td>\n",
       "      <td>3</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>wiFeLz74XNt7Z8NnfxDzWQ</td>\n",
       "      <td>Tanya thrifty splurger S.</td>\n",
       "      <td>River Forest, IL</td>\n",
       "      <td>August 2007</td>\n",
       "      <td>7</td>\n",
       "      <td>129</td>\n",
       "      <td>16</td>\n",
       "      <td>126</td>\n",
       "      <td>34</td>\n",
       "      <td>29</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>UWT8_eEQVLsFaQfqUmX-Mw</td>\n",
       "      <td>Tina M.</td>\n",
       "      <td>Chicago, IL</td>\n",
       "      <td>October 2010</td>\n",
       "      <td>31</td>\n",
       "      <td>85</td>\n",
       "      <td>10</td>\n",
       "      <td>64</td>\n",
       "      <td>15</td>\n",
       "      <td>10</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>yfhTcICkoPGD_BRE5fDmXQ</td>\n",
       "      <td>Kate S.</td>\n",
       "      <td>Chicago, IL</td>\n",
       "      <td>April 2008</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>yCykhVHx9FITYE9CpZ3oug</td>\n",
       "      <td>K. N.</td>\n",
       "      <td>Boston, MA</td>\n",
       "      <td>September 2009</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>tpV0gtalY54P4y2bv-gQow</td>\n",
       "      <td>Garrett deadbody L.</td>\n",
       "      <td>Minneapolis, MN</td>\n",
       "      <td>November 2010</td>\n",
       "      <td>3</td>\n",
       "      <td>32</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>xq8MehjzMhUEl33Eun4OCw</td>\n",
       "      <td>Pete B.</td>\n",
       "      <td>Chicago, IL</td>\n",
       "      <td>October 2009</td>\n",
       "      <td>19</td>\n",
       "      <td>88</td>\n",
       "      <td>2</td>\n",
       "      <td>77</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>-Zj7AybUs0qnG5qDZ4E9Hw</td>\n",
       "      <td>Maybelyn L.</td>\n",
       "      <td>Madison, WI</td>\n",
       "      <td>June 2010</td>\n",
       "      <td>1</td>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>UvN5nsb99EG-0rhNkY0gpw</td>\n",
       "      <td>John M.</td>\n",
       "      <td>Hawthorne, CA</td>\n",
       "      <td>December 2011</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>UM0hJuVRR27cTRLrQfJ9EA</td>\n",
       "      <td>Dee M.</td>\n",
       "      <td>Gurnee, IL</td>\n",
       "      <td>April 2012</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>We19fTNDqsoKmbdIlo165A</td>\n",
       "      <td>Karim Friendbear V.</td>\n",
       "      <td>Seattle, WA</td>\n",
       "      <td>July 2011</td>\n",
       "      <td>22</td>\n",
       "      <td>84</td>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "      <td>21</td>\n",
       "      <td>18</td>\n",
       "      <td>16</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5093</th>\n",
       "      <td>_dC3wEoq02Op4lCyzYXSZg</td>\n",
       "      <td>Arturo V.</td>\n",
       "      <td>Los Angeles, CA</td>\n",
       "      <td>May 2009</td>\n",
       "      <td>7</td>\n",
       "      <td>286</td>\n",
       "      <td>2</td>\n",
       "      <td>115</td>\n",
       "      <td>51</td>\n",
       "      <td>25</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5094</th>\n",
       "      <td>66aze3LTNApho1WNisj0xg</td>\n",
       "      <td>Amy S.</td>\n",
       "      <td>Grand Haven, MI</td>\n",
       "      <td>July 2011</td>\n",
       "      <td>7</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5095</th>\n",
       "      <td>3cGJkCJ_YhaXoZa23uRnbw</td>\n",
       "      <td>Steve StevePDX S.</td>\n",
       "      <td>Portland, OR</td>\n",
       "      <td>September 2010</td>\n",
       "      <td>12</td>\n",
       "      <td>57</td>\n",
       "      <td>10</td>\n",
       "      <td>34</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>6</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5096</th>\n",
       "      <td>7JLSvyBwLIRLS-P-pxzOdg</td>\n",
       "      <td>Ryan C.</td>\n",
       "      <td>Lynnwood, WA</td>\n",
       "      <td>June 2009</td>\n",
       "      <td>17</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5097</th>\n",
       "      <td>ASVlcKZj5upEpHpS8yfzYA</td>\n",
       "      <td>Karen T.</td>\n",
       "      <td>Palo Alto, CA</td>\n",
       "      <td>December 2009</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>62</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5098</th>\n",
       "      <td>6euawCABdGNPwNIgCk4VAw</td>\n",
       "      <td>Gus Gus Where's Jaq? L.</td>\n",
       "      <td>Brooklyn, NY</td>\n",
       "      <td>May 2009</td>\n",
       "      <td>3</td>\n",
       "      <td>30</td>\n",
       "      <td>3</td>\n",
       "      <td>48</td>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5099</th>\n",
       "      <td>aNE6au8Ly2yDHPpqDgnPqQ</td>\n",
       "      <td>Mort B.</td>\n",
       "      <td>San Francisco, CA</td>\n",
       "      <td>December 2006</td>\n",
       "      <td>57</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5100</th>\n",
       "      <td>AIvveD8AcYnPqYE_VEn8Bw</td>\n",
       "      <td>Ayanna Speak On It B.</td>\n",
       "      <td>Saint Augustine, FL</td>\n",
       "      <td>February 2006</td>\n",
       "      <td>88</td>\n",
       "      <td>192</td>\n",
       "      <td>55</td>\n",
       "      <td>350</td>\n",
       "      <td>207</td>\n",
       "      <td>187</td>\n",
       "      <td>65</td>\n",
       "      <td>108</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5101</th>\n",
       "      <td>57H49pZo-1-kDQ6XmuYmyA</td>\n",
       "      <td>Al W.</td>\n",
       "      <td>Oakland, CA</td>\n",
       "      <td>September 2009</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5102</th>\n",
       "      <td>6yI7fmSF1vmmqv-rtan3LA</td>\n",
       "      <td>Holly M.</td>\n",
       "      <td>Chicago, IL</td>\n",
       "      <td>April 2009</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5103</th>\n",
       "      <td>6D6ssMZ6EEa5MqLlP-rbMg</td>\n",
       "      <td>Courtney M.</td>\n",
       "      <td>Chicago, IL</td>\n",
       "      <td>August 2010</td>\n",
       "      <td>7</td>\n",
       "      <td>28</td>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5104</th>\n",
       "      <td>8YQu--DAepnVQuYvGD0PWg</td>\n",
       "      <td>Stephen S.</td>\n",
       "      <td>Los Angeles, CA</td>\n",
       "      <td>November 2008</td>\n",
       "      <td>62</td>\n",
       "      <td>80</td>\n",
       "      <td>3</td>\n",
       "      <td>59</td>\n",
       "      <td>24</td>\n",
       "      <td>25</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5105</th>\n",
       "      <td>3S_R2NhzPfvcjc7oIdIyQA</td>\n",
       "      <td>Doug Doogie Fresh S.</td>\n",
       "      <td>Seattle, WA</td>\n",
       "      <td>August 2010</td>\n",
       "      <td>33</td>\n",
       "      <td>173</td>\n",
       "      <td>10</td>\n",
       "      <td>200</td>\n",
       "      <td>99</td>\n",
       "      <td>126</td>\n",
       "      <td>12</td>\n",
       "      <td>18</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5106</th>\n",
       "      <td>2xp2PStd-7u53jh30DkC3A</td>\n",
       "      <td>Mark Marcos P.</td>\n",
       "      <td>Madison, WI</td>\n",
       "      <td>January 2006</td>\n",
       "      <td>12</td>\n",
       "      <td>46</td>\n",
       "      <td>21</td>\n",
       "      <td>23</td>\n",
       "      <td>11</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5107</th>\n",
       "      <td>7BiWqhSJ-h0drMp7xCZC8w</td>\n",
       "      <td>Lily Z.</td>\n",
       "      <td>Chicago, IL</td>\n",
       "      <td>February 2012</td>\n",
       "      <td>39</td>\n",
       "      <td>66</td>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>68</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5108</th>\n",
       "      <td>Amc7J0F3KeAKzOOQrlpqog</td>\n",
       "      <td>Lesley Last name: Ever, First name: Greatest S.</td>\n",
       "      <td>O'Fallon, IL</td>\n",
       "      <td>September 2009</td>\n",
       "      <td>259</td>\n",
       "      <td>365</td>\n",
       "      <td>84</td>\n",
       "      <td>596</td>\n",
       "      <td>274</td>\n",
       "      <td>350</td>\n",
       "      <td>347</td>\n",
       "      <td>86</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5109</th>\n",
       "      <td>_aVCYt2Bxn5vmkN-d1Mq7g</td>\n",
       "      <td>Audra K.</td>\n",
       "      <td>Washington, DC</td>\n",
       "      <td>January 2007</td>\n",
       "      <td>82</td>\n",
       "      <td>119</td>\n",
       "      <td>13</td>\n",
       "      <td>430</td>\n",
       "      <td>306</td>\n",
       "      <td>100</td>\n",
       "      <td>81</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5110</th>\n",
       "      <td>_f9NyNygDasxm4x_8K0FMg</td>\n",
       "      <td>Jen K.</td>\n",
       "      <td>Costa Mesa, CA</td>\n",
       "      <td>February 2007</td>\n",
       "      <td>94</td>\n",
       "      <td>523</td>\n",
       "      <td>48</td>\n",
       "      <td>352</td>\n",
       "      <td>268</td>\n",
       "      <td>176</td>\n",
       "      <td>160</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5111</th>\n",
       "      <td>4qCxGO9JEzpaKXUgttzQGg</td>\n",
       "      <td>Jesse D.</td>\n",
       "      <td>Hopkins, MN</td>\n",
       "      <td>March 2011</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5112</th>\n",
       "      <td>aAnY0oKxg4WEcYsC9hw3cQ</td>\n",
       "      <td>Leticia Girl in Heels R.</td>\n",
       "      <td>Chicago, IL</td>\n",
       "      <td>April 2012</td>\n",
       "      <td>12</td>\n",
       "      <td>66</td>\n",
       "      <td>5</td>\n",
       "      <td>24</td>\n",
       "      <td>17</td>\n",
       "      <td>15</td>\n",
       "      <td>19</td>\n",
       "      <td>75</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5113</th>\n",
       "      <td>AezWAIKb1X-Gw9vbPtdxlQ</td>\n",
       "      <td>Paul M.</td>\n",
       "      <td>Fulton, MD</td>\n",
       "      <td>December 2011</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5114</th>\n",
       "      <td>3dI4ySxLTmt4M9h6L5WlYQ</td>\n",
       "      <td>Ted texty malfoy M.</td>\n",
       "      <td>Manhattan, NY</td>\n",
       "      <td>August 2007</td>\n",
       "      <td>48</td>\n",
       "      <td>146</td>\n",
       "      <td>6</td>\n",
       "      <td>197</td>\n",
       "      <td>149</td>\n",
       "      <td>83</td>\n",
       "      <td>71</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5115</th>\n",
       "      <td>47B009pYUaWfMfHDG-rEKg</td>\n",
       "      <td>Meredith M.</td>\n",
       "      <td>Chicago, IL</td>\n",
       "      <td>September 2007</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5116</th>\n",
       "      <td>4GzOqUnnI192soVYvlh2tQ</td>\n",
       "      <td>Charles C.</td>\n",
       "      <td>Chicago, IL</td>\n",
       "      <td>February 2012</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5117</th>\n",
       "      <td>-2aZoH_YaC-1s1BFzo7GcA</td>\n",
       "      <td>Todd B.</td>\n",
       "      <td>Greenville, SC</td>\n",
       "      <td>December 2011</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5118</th>\n",
       "      <td>6keZ8N8uCgxsT4lDwkn-kQ</td>\n",
       "      <td>A N.</td>\n",
       "      <td>Chicago, IL</td>\n",
       "      <td>April 2011</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5119</th>\n",
       "      <td>ArrrUihsfS8lQVeJRPEwqQ</td>\n",
       "      <td>Joanna N.</td>\n",
       "      <td>Rockwood, MI</td>\n",
       "      <td>April 2009</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5120</th>\n",
       "      <td>2ck_k8Swtj6-48kLR6IVWA</td>\n",
       "      <td>m s.</td>\n",
       "      <td>Chicago, IL</td>\n",
       "      <td>February 2010</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5121</th>\n",
       "      <td>2ynZkFzXxSYli0acUGEjxA</td>\n",
       "      <td>Ralph traveler M.</td>\n",
       "      <td>Medford, MA</td>\n",
       "      <td>June 2010</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5122</th>\n",
       "      <td>AERZ6T8Qj0NgFABdIZGbGA</td>\n",
       "      <td>Isela C.</td>\n",
       "      <td>Chicago, IL</td>\n",
       "      <td>March 2012</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5123 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  reviewerID                                             name  \\\n",
       "0     yevHGEUQQmnVlBXIrJ885A                                         Kevin T.   \n",
       "1     yoB_PYQHjnPjh78ATA0Jgw                                      Veronica B.   \n",
       "2     XrFCag4AMW5qta9QXokWPA                            Paul The Commander M.   \n",
       "3     y5ptsWmvGEAftOQaiFhBcg                              Stella BraveTart J.   \n",
       "4     uUVZJm9yxNl5FBsXbt4WBg                      Ginger 'where's my meds' v.   \n",
       "5     ZCRY4GLLTli8tZRPi1P7Cw                                 Johan Johanna S.   \n",
       "6     uOFIY6vBBp7O6un8CLggTw                            Daniel Don Quijote K.   \n",
       "7     tdE3__i2otI_nL3M3sy0MQ                               Jen Mme Federer C.   \n",
       "8     Uu-qEGsSb72ngIQUF85rDQ                                          Anna P.   \n",
       "9     zyk-YPhtFZK6kkbpzEKrWw                                          Kara P.   \n",
       "10    V2OQaeZvePoGkbZ-Uye6KA                       Rachel here's lookin at U.   \n",
       "11    TYSR6svM9HQoqgBUpQH7GQ                                       Jeffrey A.   \n",
       "12    vvB_c7yYIA1bnjgb3aPckg                                         Craig H.   \n",
       "13    wiD0JGjaifHO5rTF49dJlg                                         penny h.   \n",
       "14    WFfMbs9iXsYZT9GHfVCLTA                                        Esther P.   \n",
       "15    UqYndXp9pbFpapebnIleTw                                           Amy w.   \n",
       "16    TIlh76nA82VBpXK_XuoOBg                                             c m.   \n",
       "17    x1uo32SAD_XMq0ulqC8_OQ                                 Shadow shadow K.   \n",
       "18    Ztd3ZxcPSCXv01MZTBXVZQ                                         Emily W.   \n",
       "19    TtwhWwNSqDv64M2EnYZE8g        Michael The best is good enough for me S.   \n",
       "20    wiFeLz74XNt7Z8NnfxDzWQ                        Tanya thrifty splurger S.   \n",
       "21    UWT8_eEQVLsFaQfqUmX-Mw                                          Tina M.   \n",
       "22    yfhTcICkoPGD_BRE5fDmXQ                                          Kate S.   \n",
       "23    yCykhVHx9FITYE9CpZ3oug                                            K. N.   \n",
       "24    tpV0gtalY54P4y2bv-gQow                              Garrett deadbody L.   \n",
       "25    xq8MehjzMhUEl33Eun4OCw                                          Pete B.   \n",
       "26    -Zj7AybUs0qnG5qDZ4E9Hw                                      Maybelyn L.   \n",
       "27    UvN5nsb99EG-0rhNkY0gpw                                          John M.   \n",
       "28    UM0hJuVRR27cTRLrQfJ9EA                                           Dee M.   \n",
       "29    We19fTNDqsoKmbdIlo165A                              Karim Friendbear V.   \n",
       "...                      ...                                              ...   \n",
       "5093  _dC3wEoq02Op4lCyzYXSZg                                        Arturo V.   \n",
       "5094  66aze3LTNApho1WNisj0xg                                           Amy S.   \n",
       "5095  3cGJkCJ_YhaXoZa23uRnbw                                Steve StevePDX S.   \n",
       "5096  7JLSvyBwLIRLS-P-pxzOdg                                          Ryan C.   \n",
       "5097  ASVlcKZj5upEpHpS8yfzYA                                         Karen T.   \n",
       "5098  6euawCABdGNPwNIgCk4VAw                          Gus Gus Where's Jaq? L.   \n",
       "5099  aNE6au8Ly2yDHPpqDgnPqQ                                          Mort B.   \n",
       "5100  AIvveD8AcYnPqYE_VEn8Bw                            Ayanna Speak On It B.   \n",
       "5101  57H49pZo-1-kDQ6XmuYmyA                                            Al W.   \n",
       "5102  6yI7fmSF1vmmqv-rtan3LA                                         Holly M.   \n",
       "5103  6D6ssMZ6EEa5MqLlP-rbMg                                      Courtney M.   \n",
       "5104  8YQu--DAepnVQuYvGD0PWg                                       Stephen S.   \n",
       "5105  3S_R2NhzPfvcjc7oIdIyQA                             Doug Doogie Fresh S.   \n",
       "5106  2xp2PStd-7u53jh30DkC3A                                   Mark Marcos P.   \n",
       "5107  7BiWqhSJ-h0drMp7xCZC8w                                          Lily Z.   \n",
       "5108  Amc7J0F3KeAKzOOQrlpqog  Lesley Last name: Ever, First name: Greatest S.   \n",
       "5109  _aVCYt2Bxn5vmkN-d1Mq7g                                         Audra K.   \n",
       "5110  _f9NyNygDasxm4x_8K0FMg                                           Jen K.   \n",
       "5111  4qCxGO9JEzpaKXUgttzQGg                                         Jesse D.   \n",
       "5112  aAnY0oKxg4WEcYsC9hw3cQ                         Leticia Girl in Heels R.   \n",
       "5113  AezWAIKb1X-Gw9vbPtdxlQ                                          Paul M.   \n",
       "5114  3dI4ySxLTmt4M9h6L5WlYQ                              Ted texty malfoy M.   \n",
       "5115  47B009pYUaWfMfHDG-rEKg                                      Meredith M.   \n",
       "5116  4GzOqUnnI192soVYvlh2tQ                                       Charles C.   \n",
       "5117  -2aZoH_YaC-1s1BFzo7GcA                                          Todd B.   \n",
       "5118  6keZ8N8uCgxsT4lDwkn-kQ                                             A N.   \n",
       "5119  ArrrUihsfS8lQVeJRPEwqQ                                        Joanna N.   \n",
       "5120  2ck_k8Swtj6-48kLR6IVWA                                             m s.   \n",
       "5121  2ynZkFzXxSYli0acUGEjxA                                Ralph traveler M.   \n",
       "5122  AERZ6T8Qj0NgFABdIZGbGA                                         Isela C.   \n",
       "\n",
       "                   location    yelpJoinDate  friendCount  reviewCount  \\\n",
       "0            Oconomowoc, WI        May 2011            4           86   \n",
       "1            Saint Paul, MN    January 2010            5           49   \n",
       "2           Saint Louis, MO     August 2008           15          135   \n",
       "3     Lexington-Fayette, KY  September 2009           49          104   \n",
       "4         San Francisco, CA     August 2008           22           34   \n",
       "5           San Leandro, CA     August 2010            0           34   \n",
       "6              Honolulu, HI       June 2011           72           51   \n",
       "7              New York, NY   December 2008          136          238   \n",
       "8              New York, NY      March 2010            1           11   \n",
       "9             Covington, KY   December 2009           66           49   \n",
       "10         Philadelphia, PA    October 2007           52          234   \n",
       "11          Los Angeles, CA       June 2011            2            8   \n",
       "12              Gridley, IL   February 2006            0           20   \n",
       "13              Chicago, IL   February 2007            0           52   \n",
       "14              Chicago, IL   December 2011            2           10   \n",
       "15           Richardson, TX   February 2009            8           43   \n",
       "16              Chicago, IL        May 2010            0           22   \n",
       "17            San Diego, CA      April 2011            0            2   \n",
       "18             Berkeley, CA   December 2006           13            7   \n",
       "19               Denver, CO    January 2007          511          838   \n",
       "20         River Forest, IL     August 2007            7          129   \n",
       "21              Chicago, IL    October 2010           31           85   \n",
       "22              Chicago, IL      April 2008            0           11   \n",
       "23               Boston, MA  September 2009            0           12   \n",
       "24          Minneapolis, MN   November 2010            3           32   \n",
       "25              Chicago, IL    October 2009           19           88   \n",
       "26              Madison, WI       June 2010            1           46   \n",
       "27            Hawthorne, CA   December 2011            1           18   \n",
       "28               Gurnee, IL      April 2012            0            3   \n",
       "29              Seattle, WA       July 2011           22           84   \n",
       "...                     ...             ...          ...          ...   \n",
       "5093        Los Angeles, CA        May 2009            7          286   \n",
       "5094        Grand Haven, MI       July 2011            7           15   \n",
       "5095           Portland, OR  September 2010           12           57   \n",
       "5096           Lynnwood, WA       June 2009           17           18   \n",
       "5097          Palo Alto, CA   December 2009            7            6   \n",
       "5098           Brooklyn, NY        May 2009            3           30   \n",
       "5099      San Francisco, CA   December 2006           57           27   \n",
       "5100    Saint Augustine, FL   February 2006           88          192   \n",
       "5101            Oakland, CA  September 2009            0            8   \n",
       "5102            Chicago, IL      April 2009            0            3   \n",
       "5103            Chicago, IL     August 2010            7           28   \n",
       "5104        Los Angeles, CA   November 2008           62           80   \n",
       "5105            Seattle, WA     August 2010           33          173   \n",
       "5106            Madison, WI    January 2006           12           46   \n",
       "5107            Chicago, IL   February 2012           39           66   \n",
       "5108           O'Fallon, IL  September 2009          259          365   \n",
       "5109         Washington, DC    January 2007           82          119   \n",
       "5110         Costa Mesa, CA   February 2007           94          523   \n",
       "5111            Hopkins, MN      March 2011            5            1   \n",
       "5112            Chicago, IL      April 2012           12           66   \n",
       "5113             Fulton, MD   December 2011            0            4   \n",
       "5114          Manhattan, NY     August 2007           48          146   \n",
       "5115            Chicago, IL  September 2007            3            8   \n",
       "5116            Chicago, IL   February 2012            0            1   \n",
       "5117         Greenville, SC   December 2011            0            6   \n",
       "5118            Chicago, IL      April 2011            0            1   \n",
       "5119           Rockwood, MI      April 2009            0            1   \n",
       "5120            Chicago, IL   February 2010            0            3   \n",
       "5121            Medford, MA       June 2010            0            1   \n",
       "5122            Chicago, IL      March 2012            3           13   \n",
       "\n",
       "      firstCount  usefulCount  coolCount  funnyCount  complimentCount  \\\n",
       "0              3          129         47          31               12   \n",
       "1              5           63         34          21               10   \n",
       "2             29          235         85         102               72   \n",
       "3             36          282         83          92               43   \n",
       "4              2           81         32          52                5   \n",
       "5              0           20          3           3                0   \n",
       "6              0           57         19          16                8   \n",
       "7             37          200        103          40               55   \n",
       "8              0            9          4           3                1   \n",
       "9              2           51         19          14               27   \n",
       "10            21          554        402         192              163   \n",
       "11             0            3          1           1                0   \n",
       "12             6           11          6           1                2   \n",
       "13             1           22          7           4                3   \n",
       "14             0            4          3           2                0   \n",
       "15             1           42         10          10                0   \n",
       "16             0           14          2           4                0   \n",
       "17             0            0          0           0                0   \n",
       "18             0            7          3           0                0   \n",
       "19           175         4146       3448        3411             2458   \n",
       "20            16          126         34          29                9   \n",
       "21            10           64         15          10               19   \n",
       "22             0            5          1           0                0   \n",
       "23             1            3          0           0                0   \n",
       "24             6            4          4           5                2   \n",
       "25             2           77          6          12                2   \n",
       "26             0            8          5           5                1   \n",
       "27             1            7          2           3                0   \n",
       "28             1            3          1           0                0   \n",
       "29             0           61         21          18               16   \n",
       "...          ...          ...        ...         ...              ...   \n",
       "5093           2          115         51          25                4   \n",
       "5094           2            9          4           2                1   \n",
       "5095          10           34         11          12                6   \n",
       "5096           2           17          8           7                1   \n",
       "5097           0            3          0           3                0   \n",
       "5098           3           48         12          11                4   \n",
       "5099           0           18         12          12                3   \n",
       "5100          55          350        207         187               65   \n",
       "5101           0            1          0           0                0   \n",
       "5102           0            8          0           2                0   \n",
       "5103           2           17          8           8                6   \n",
       "5104           3           59         24          25                9   \n",
       "5105          10          200         99         126               12   \n",
       "5106          21           23         11          21                0   \n",
       "5107           4           14          3           3                0   \n",
       "5108          84          596        274         350              347   \n",
       "5109          13          430        306         100               81   \n",
       "5110          48          352        268         176              160   \n",
       "5111           0            0          0           0                0   \n",
       "5112           5           24         17          15               19   \n",
       "5113           0            0          0           0                0   \n",
       "5114           6          197        149          83               71   \n",
       "5115           0           12          8           6                3   \n",
       "5116           0            1          0           0                0   \n",
       "5117           0            0          0           0                0   \n",
       "5118           0            0          0           0                0   \n",
       "5119           0            0          0           0                1   \n",
       "5120           0            1          0           0                0   \n",
       "5121           0            0          0           0                0   \n",
       "5122           0            2          0           3                0   \n",
       "\n",
       "      tipCount  fanCount  \n",
       "0            0         1  \n",
       "1            2         0  \n",
       "2            0         3  \n",
       "3            0        21  \n",
       "4            0         1  \n",
       "5            0         0  \n",
       "6            0         1  \n",
       "7           10         2  \n",
       "8            1         0  \n",
       "9           13         1  \n",
       "10           0        11  \n",
       "11           1         0  \n",
       "12           3         0  \n",
       "13           0         0  \n",
       "14           0         0  \n",
       "15           0         0  \n",
       "16           0         1  \n",
       "17           0         0  \n",
       "18           0         2  \n",
       "19           3        66  \n",
       "20           0         1  \n",
       "21          19         1  \n",
       "22           0         0  \n",
       "23           0         0  \n",
       "24           0         0  \n",
       "25           0         0  \n",
       "26           0         1  \n",
       "27           0         0  \n",
       "28           1         0  \n",
       "29          27         1  \n",
       "...        ...       ...  \n",
       "5093         0         6  \n",
       "5094        28         0  \n",
       "5095        39         0  \n",
       "5096         0         1  \n",
       "5097        62         1  \n",
       "5098         0         0  \n",
       "5099         0         1  \n",
       "5100       108         9  \n",
       "5101         1         0  \n",
       "5102         0         0  \n",
       "5103         0         1  \n",
       "5104         0         1  \n",
       "5105        18        10  \n",
       "5106         0         0  \n",
       "5107        68         1  \n",
       "5108        86        16  \n",
       "5109         7         8  \n",
       "5110         4        10  \n",
       "5111         0         0  \n",
       "5112        75         1  \n",
       "5113         0         0  \n",
       "5114         2         1  \n",
       "5115         0         0  \n",
       "5116         0         0  \n",
       "5117         1         0  \n",
       "5118         0         0  \n",
       "5119         0         0  \n",
       "5120         0         0  \n",
       "5121         0         0  \n",
       "5122         0         0  \n",
       "\n",
       "[5123 rows x 13 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviewers_df"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_df.iloc[:,36].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "479/(3956 + 479)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## About 10% of our dataset are anomalous cases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Global Variables "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Y_train = train_df[len(train_df.columns)-1]\n",
    "X_train = train_df.drop(len(train_df.columns)-1,axis=1)\n",
    "num_rows_X_train = X_train[0].count()\n",
    "num_columns_X_train = len(X_train.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utils Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# From: http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\n",
    "import itertools\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "######################################\n",
    "# Function Save Data To CSV\n",
    "######################################\n",
    "\n",
    "def saveDataToCSV(Y_pred):\n",
    "    id_list = range(1, len(Y_pred)+1)\n",
    "    submission = pd.DataFrame({\n",
    "        \"Id\": id_list,\n",
    "        \"Expected\": Y_pred\n",
    "    })\n",
    "    submission = submission[['Id', 'Expected']]\n",
    "    submission.to_csv('submission.csv', index=False)\n",
    "    return\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 - Data Pre-Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 - Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n",
    "import numpy.ma as ma\n",
    "import math\n",
    "\n",
    "######################################\n",
    "# Strategies based on constants\n",
    "######################################\n",
    "\n",
    "#replace by zero - black colour in RGB\n",
    "def replaceByZero(df):\n",
    "    return np.nan_to_num(df)\n",
    "\n",
    "#replace by 255 - white colour in RGB\n",
    "def replaceBy255(df):\n",
    "    return df.fillna(255)\n",
    "\n",
    "#####################################\n",
    "# Strategies based on columns values\n",
    "#####################################\n",
    "\n",
    "#column minimum\n",
    "def replaceByColumnMinimum(df):\n",
    "    return df.fillna(df.min())\n",
    "\n",
    "#column maximum\n",
    "def replaceByColumnMaximum(df):\n",
    "    return df.fillna(df.max())\n",
    "\n",
    "#column mean\n",
    "def replaceByColumnMean(df):\n",
    "    return df.fillna(df.mean())\n",
    "\n",
    "#column median\n",
    "def replaceByColumnMedian(df):\n",
    "    return df.fillna(df.median())\n",
    "\n",
    "#####################################\n",
    "# Strategies based on rows values\n",
    "#####################################\n",
    "\n",
    "# in the analysis of the rows we have to take into account that each four consecutive rows describe a pixel.\n",
    "# Each of these four rows stands for: Red, Green, IR, IR. |R|G|IR1|IR2|\n",
    "# These values refer to different things, and therefore are analysed independently.\n",
    "# this will allow to consider more the specificities of the problem\n",
    "\n",
    "# divide the data into four datasets, corresponding to each type of values \n",
    "\n",
    "#general function to gather columns for each type |R|G|IR1|IR2| using the mod operator\n",
    "def separatePixelColumns(position, df):\n",
    "    indexes = range(0, num_columns_X_train-1)\n",
    "    indexes = [x for x in indexes if x % 4 == position]\n",
    "    df_p_attribute = df.iloc[:,indexes]\n",
    "    return df_p_attribute\n",
    "\n",
    "#general function to fill missing values based on the rows\n",
    "#Note that does not make sense to consider the four values |R|G|IR1|IR2|, because they refer to different properties\n",
    "def fillMissingValuesByRow(df, function):\n",
    "    for index, row in df.iterrows():\n",
    "        value_without_nan = function(row)\n",
    "        nan_positions = row.isnull()\n",
    "        row[nan_positions] = value_without_nan\n",
    "    return df\n",
    "\n",
    "#row spectral mean\n",
    "def replaceByRowMean(df):\n",
    "    return fillMissingValuesByRow(df, np.nanmean)\n",
    "\n",
    "#row spectral median\n",
    "def replaceByRowMedian(df):\n",
    "    return fillMissingValuesByRow(df, np.nanmedian)\n",
    "\n",
    "#row spectral minimum\n",
    "def replaceByRowMinimum(df):\n",
    "    return fillMissingValuesByRow(df, np.nanmin)\n",
    "\n",
    "#row spectral maximum\n",
    "def replaceByRowMaximum(df):\n",
    "    return fillMissingValuesByRow(df, np.nanmax)\n",
    "\n",
    "########################################\n",
    "# Strategies based on data distribution\n",
    "########################################\n",
    "\n",
    "#consider the distribution of the spectral values of each type. \n",
    "#Get random value from the spectral values of same type\n",
    "\n",
    "    \n",
    "def getRandomNumberFromDataframe(df):\n",
    "    while True:\n",
    "        row = df.sample(1, random_state = 2)\n",
    "        values = row.values[0]\n",
    "        value = random.choice(values)\n",
    "        if not math.isnan(value):\n",
    "            break\n",
    "    return value\n",
    "        \n",
    "def fillMissingValuesWithDistribution(df):\n",
    "    for index, row in df.iterrows():\n",
    "        nan_positions = row.isnull()\n",
    "        for i in range(len(nan_positions)): \n",
    "            if nan_positions.iloc[i] == True:\n",
    "                value = getRandomNumberFromDataframe(df)\n",
    "                row.iloc[i] = value\n",
    "    return df\n",
    "\n",
    "#########################################%%%\n",
    "# fill Missing Values Considering Spectral\n",
    "#########################################%%%\n",
    "\n",
    "def fillMissingValuesBySpectral(df, function):\n",
    "\n",
    "    #generate four new datasets with the columns of each type\n",
    "    df_p_attribute_R = separatePixelColumns(0, df)\n",
    "    df_p_attribute_G = separatePixelColumns(1, df)\n",
    "    df_p_attribute_IR1 = separatePixelColumns(2, df)\n",
    "    df_p_attribute_IR2 = separatePixelColumns(3, df)\n",
    "\n",
    "    #apply function to each of the 4 datasets\n",
    "    df_p_attribute_R = function(df_p_attribute_R)\n",
    "    df_p_attribute_G = function(df_p_attribute_G)\n",
    "    df_p_attribute_IR1 = function(df_p_attribute_IR1)\n",
    "    df_p_attribute_IR2 = function(df_p_attribute_IR2)\n",
    "\n",
    "    df = pd.concat(\n",
    "                        [df_p_attribute_R, \n",
    "                         df_p_attribute_G,\n",
    "                         df_p_attribute_IR1,\n",
    "                         df_p_attribute_IR2], \n",
    "                        axis=1\n",
    "                        )\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#######################\n",
    "#   CHAMADAS\n",
    "#######################\n",
    "\n",
    "#X_train = replaceByZero(X_train)\n",
    "#test_df = replaceByZero(test_df)\n",
    "\n",
    "#X_train = replaceBy255(X_train)\n",
    "#test_df = replaceBy255(test_df)\n",
    "\n",
    "#X_train = replaceByColumnMinimum(X_train)\n",
    "#test_df = replaceByColumnMinimum(test_df)\n",
    "\n",
    "#X_train = replaceByColumnMaximum(X_train)\n",
    "#test_df = replaceByColumnMaximum(test_df)\n",
    "\n",
    "#X_train = replaceByColumnMean(X_train)\n",
    "#test_df = replaceByColumnMean(test_df)\n",
    "\n",
    "#X_train = replaceByColumnMedian(X_train)\n",
    "#test_df = replaceByColumnMedian(test_df)\n",
    "\n",
    "#X_train = fillMissingValuesBySpectral(X_train, replaceByRowMean)\n",
    "#test_df = fillMissingValuesBySpectral(test_df, replaceByRowMean)\n",
    "\n",
    "#X_train = fillMissingValuesBySpectral(X_train, replaceByRowMedian)\n",
    "#test_df = fillMissingValuesBySpectral(test_df, replaceByRowMedian)\n",
    "\n",
    "#X_train = fillMissingValuesBySpectral(X_train, replaceByRowMinimum)\n",
    "#test_df = fillMissingValuesBySpectral(test_df, replaceByRowMinimum)\n",
    "\n",
    "#X_train = fillMissingValuesBySpectral(X_train, replaceByRowMaximum)\n",
    "#test_df = fillMissingValuesBySpectral(test_df, replaceByRowMaximum)\n",
    "\n",
    "#X_train = fillMissingValuesBySpectral(X_train, fillMissingValuesWithDistribution)\n",
    "#test_df = fillMissingValuesBySpectral(test_df, fillMissingValuesWithDistribution)\n",
    "\n",
    "datasets = {f_name: {\"train\": f(X_train.copy()), \"test\": f(test_df.copy())} for f_name, f in [\n",
    "        (\"01-zero\", replaceByZero),\n",
    "        (\"02-255\", replaceBy255),\n",
    "        (\"03-col-min\", replaceByColumnMinimum),\n",
    "        (\"04-col-max\", replaceByColumnMaximum),\n",
    "        (\"05-col-mean\", replaceByColumnMean),\n",
    "        (\"06-col-median\", replaceByColumnMedian),\n",
    "        (\"07-spec-mean\", lambda data: fillMissingValuesBySpectral(data, replaceByRowMean)),\n",
    "        (\"08-spec-median\", lambda data: fillMissingValuesBySpectral(data, replaceByRowMedian)),\n",
    "        (\"09-spec-min\", lambda data: fillMissingValuesBySpectral(data, replaceByRowMinimum)),\n",
    "        (\"10-spec-max\", lambda data: fillMissingValuesBySpectral(data, replaceByRowMaximum)),\n",
    "        (\"11-spec-dis\", lambda data: fillMissingValuesBySpectral(data, fillMissingValuesWithDistribution))\n",
    "    ]}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Normalization\n",
    "\n",
    "There is no need for normalization in this dataset, since all features are between 0 and 255."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 - Model Selection\n",
    "\n",
    "- First goal: discover which type of analyses works better\n",
    "- Second Goal: tune the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 - Model selection based on which models do best in CV using default settings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#inspired in http://machinelearningmastery.com/compare-machine-learning-algorithms-python-scikit-learn/\n",
    "\n",
    "import sklearn.model_selection as mds\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "import xgboost as xgb\n",
    "\n",
    "# prepare data\n",
    "\n",
    "#Y_train = train_df[:,-1]\n",
    "#X_train = train_df[:,:-1]\n",
    "\n",
    "#Y_train = train_df[len(train_df.columns)-1]\n",
    "#X_train = train_df.drop(len(train_df.columns)-1,axis=1)\n",
    "\n",
    "# prepare configuration for cross validation test harness\n",
    "num_folds = 10\n",
    "num_instances = len(X_train)\n",
    "\n",
    "# prepare models\n",
    "models = []\n",
    "models.append(('LR', LogisticRegression()))\n",
    "models.append(('LDA', LinearDiscriminantAnalysis()))\n",
    "models.append(('KNN', KNeighborsClassifier()))\n",
    "models.append(('CART', DecisionTreeClassifier()))\n",
    "models.append(('NB', GaussianNB()))\n",
    "#models.append(('SVM-Linear', SVC(kernel=\"linear\")))\n",
    "models.append(('SVM-Poly', SVC(kernel=\"poly\")))\n",
    "models.append(('SVM-RBF', SVC(kernel=\"rbf\")))\n",
    "models.append(('NN', MLPClassifier(alpha=1))) \n",
    "models.append(('RF', RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1)))\n",
    "models.append(('AB', AdaBoostClassifier()))\n",
    "models.append(('XGB', xgb.XGBClassifier()))\n",
    "\n",
    "# evaluate each model in turn\n",
    "results = {}\n",
    "scoring = 'roc_auc' # try with 'roc_auc', f1'\n",
    "\n",
    "kfold = mds.StratifiedKFold(n_splits=num_folds, shuffle=True, random_state=2)\n",
    "\n",
    "for NA_strategy in sorted(datasets.keys()):\n",
    "    \n",
    "    results_by_strategy = []\n",
    "    \n",
    "    for model_name, model in models:\n",
    "        cv_results = mds.cross_val_score(model, datasets[NA_strategy][\"train\"], Y_train, cv=kfold, scoring=scoring)\n",
    "        results_by_strategy.append({\"name\": model_name, \"cv_results\": cv_results, \"mean\": cv_results.mean(), \"std\": cv_results.std()})\n",
    "        #print(\"%s: %f (%f)\" % (model_name, cv_results.mean(), cv_results.std()))\n",
    "        \n",
    "    # boxplot algorithm comparison\n",
    "    fig = plt.figure(figsize=(13, 5), dpi=500)\n",
    "    fig.suptitle('Algorithm Comparison using \\\"%s\\\"' % NA_strategy)\n",
    "    ax = fig.add_subplot(111)\n",
    "    plt.boxplot([x[\"cv_results\"] for x in results_by_strategy])\n",
    "    ax.set_xticklabels([x[\"name\"] for x in results_by_strategy])\n",
    "    plt.show()\n",
    "    \n",
    "    # order the models by the mean auc\n",
    "    results_by_strategy.sort(key=lambda x: x[\"mean\"], reverse=True)\n",
    "    print([(x[\"name\"], x[\"mean\"]) for x in results_by_strategy])\n",
    "    \n",
    "    results[NA_strategy] = results_by_strategy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results sorted by AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "results_sorted = [(na_method, algorithm[\"name\"], algorithm[\"mean\"]) for na_method in results for algorithm in results[na_method]]\n",
    "results_sorted.sort(key=lambda x: x[2], reverse=True)\n",
    "results_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plotSupervisedAlgorithmsDefault(inf, sup):\n",
    "    plt.figure(figsize=(13, 7), dpi=500)\n",
    "    \n",
    "    # x axis\n",
    "    labels = [na_method for na_method in results]\n",
    "    labels.sort()\n",
    "    plt.xticks(np.arange(len(labels)), labels, rotation='vertical')\n",
    "    plt.ylim(inf, sup)\n",
    "    \n",
    "    # legend:\n",
    "    algorithm_names = [x[\"name\"] for x in results[\"01-zero\"]] \n",
    "    \n",
    "    [plt.plot([[x[\"mean\"] for x in results[na_method] if x[\"name\"] == alg_name] for na_method in sorted(results)],\n",
    "              label = alg_name) for alg_name in algorithm_names]\n",
    "    \n",
    "    plt.ylabel('AUC')\n",
    "    plt.xlabel('NA-filling method')\n",
    "    \n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "    plt.show()\n",
    "    \n",
    "plotSupervisedAlgorithmsDefault(0.69, 1)\n",
    "plotSupervisedAlgorithmsDefault(0.9, 1)\n",
    "plotSupervisedAlgorithmsDefault(0.99, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Based on this plot, we decided to tune XGB and LDA and use 07-spec-mean and 09-spec-min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plotConfusionMatrixBestXGB():\n",
    "    kfold = mds.StratifiedKFold(n_splits=2, shuffle=True, random_state=2)\n",
    "    train, test = kfold.split(datasets[\"07-spec-mean\"][\"train\"], Y_train)\n",
    "\n",
    "    lol = xgb.XGBClassifier().fit(datasets[\"07-spec-mean\"][\"train\"].iloc[train[0]], Y_train[train[0]])\n",
    "\n",
    "    train1_pred = lol.predict(datasets[\"07-spec-mean\"][\"train\"].iloc[train[1]])\n",
    "\n",
    "    plot_confusion_matrix(confusion_matrix(Y_train[train[1]], train1_pred, labels = [0, 1]), classes = [0, 1])\n",
    "    \n",
    "plotConfusionMatrixBestXGB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plotConfusionMatrixBestLDA():\n",
    "    kfold = mds.StratifiedKFold(n_splits=2, shuffle=True, random_state=2)\n",
    "    train, test = kfold.split(datasets[\"09-spec-min\"][\"train\"], Y_train)\n",
    "\n",
    "    lol = xgb.XGBClassifier().fit(datasets[\"09-spec-min\"][\"train\"].iloc[train[0]], Y_train[train[0]])\n",
    "\n",
    "    train1_pred = lol.predict(datasets[\"09-spec-min\"][\"train\"].iloc[train[1]])\n",
    "\n",
    "    plot_confusion_matrix(confusion_matrix(Y_train[train[1]], train1_pred, labels = [0, 1]), classes = [0, 1])\n",
    "    \n",
    "plotConfusionMatrixBestLDA()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.1 - Tuning of the best models\n",
    "#### Based on this plot, we decided to tune LDA and XGB\n",
    "### Tuning XGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Adapted from https://www.analyticsvidhya.com/blog/2016/03/complete-guide-parameter-tuning-xgboost-with-codes-python/\n",
    "def modelfit(alg, train_predictors, train_target, useTrainCV=True, cv_folds=10, early_stopping_rounds=50):\n",
    "    \n",
    "    if useTrainCV:\n",
    "        xgb_param = alg.get_xgb_params()\n",
    "        xgtrain = xgb.DMatrix(train_predictors.values, label=train_target.values)\n",
    "        cvresult = xgb.cv(xgb_param, xgtrain, num_boost_round=alg.get_params()['n_estimators'], nfold=cv_folds,\n",
    "            metrics='auc', early_stopping_rounds=early_stopping_rounds, verbose_eval=True)\n",
    "        alg.set_params(n_estimators=cvresult.shape[0])\n",
    "    \n",
    "    #Fit the algorithm on the data\n",
    "    alg.fit(train_predictors, train_target, eval_metric='auc')\n",
    "        \n",
    "    #Predict training set:\n",
    "    dtrain_predictions = alg.predict(train_predictors)\n",
    "    dtrain_predprob = alg.predict_proba(train_predictors)[:,1]\n",
    "        \n",
    "    #Print model report:\n",
    "    print(\"\\nModel Report\")\n",
    "    print(\"Accuracy : %.4g\" % metrics.accuracy_score(train_target.values, dtrain_predictions))\n",
    "    print(\"AUC Score (Train): %f\" % metrics.roc_auc_score(train_target, dtrain_predprob))\n",
    "                    \n",
    "    #feat_imp = pd.Series(alg.booster().get_fscore()).sort_values(ascending=False)\n",
    "    #feat_imp.plot(kind='bar', title='Feature Importances')\n",
    "    #plt.ylabel('Feature Importance Score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics   #Additional scklearn functions\n",
    "from sklearn.model_selection import GridSearchCV   #Perforing grid search\n",
    "\n",
    "def tuneXGB1():\n",
    "    xgb1 = xgb.XGBClassifier(\n",
    "        learning_rate=0.1,\n",
    "        n_estimators=1000,\n",
    "        max_depth=5, # This should be between 3-10\n",
    "        min_child_weight=1, # A smaller value is chosen because it is a highly imbalanced class problem\n",
    "        gamma=0,\n",
    "        subsample=0.8, # Typical values range between 0.5-0.9.\n",
    "        colsample_bytree=0.8, # Typical values range between 0.5-0.9.\n",
    "        objective= 'binary:logistic',\n",
    "        #nthread=4,\n",
    "        scale_pos_weight=1, # Because of high class imbalance\n",
    "        seed=2)\n",
    "    \n",
    "    modelfit(xgb1, datasets[\"07-spec-mean\"][\"train\"], Y_train)\n",
    "    \n",
    "tuneXGB1()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This last result seems too good to be truth?!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def tuneXGB2():\n",
    "    param_test1 = {\n",
    "        'max_depth': np.arange(3,10,2),\n",
    "        'min_child_weight': np.arange(1,6,2)\n",
    "    }\n",
    "    \n",
    "    gsearch1 = GridSearchCV(estimator = xgb.XGBClassifier( learning_rate=0.1, n_estimators=156, max_depth=5,\n",
    "                                                      min_child_weight=1, gamma=0, subsample=0.8, colsample_bytree=0.8,\n",
    "                                                      objective= 'binary:logistic', scale_pos_weight=1, seed=2), \n",
    "                            param_grid = param_test1, scoring='roc_auc',iid=False, cv=10)\n",
    "    \n",
    "    gsearch1.fit(datasets[\"07-spec-mean\"][\"train\"], Y_train)\n",
    "    print(gsearch1.grid_scores_, gsearch1.best_params_, gsearch1.best_score_)\n",
    "    \n",
    "tuneXGB2()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### {'max_depth': 7, 'min_child_weight': 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def tuneXGB3():\n",
    "    param_test1 = {\n",
    "        'max_depth': [6,7,8],\n",
    "        'min_child_weight': [1,2,3]\n",
    "    }\n",
    "    \n",
    "    gsearch1 = GridSearchCV(estimator = xgb.XGBClassifier( learning_rate=0.1, n_estimators=156, max_depth=5,\n",
    "                                                      min_child_weight=1, gamma=0, subsample=0.8, colsample_bytree=0.8,\n",
    "                                                      objective= 'binary:logistic', scale_pos_weight=1, seed=2), \n",
    "                            param_grid = param_test1, scoring='roc_auc',iid=False, cv=10)\n",
    "    \n",
    "    gsearch1.fit(datasets[\"07-spec-mean\"][\"train\"], Y_train)\n",
    "    print(gsearch1.grid_scores_, gsearch1.best_params_, gsearch1.best_score_)\n",
    "    \n",
    "tuneXGB3()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def tuneXGB4():\n",
    "    param_test1 = {\n",
    "        'gamma':[i/10.0 for i in np.arange(0,5)]\n",
    "    }\n",
    "    \n",
    "    gsearch1 = GridSearchCV(estimator = xgb.XGBClassifier( learning_rate=0.1, n_estimators=156, max_depth=7,\n",
    "                                                      min_child_weight=1, gamma=0, subsample=0.8, colsample_bytree=0.8,\n",
    "                                                      objective= 'binary:logistic', scale_pos_weight=1, seed=2), \n",
    "                            param_grid = param_test1, scoring='roc_auc',iid=False, cv=10)\n",
    "    \n",
    "    gsearch1.fit(datasets[\"07-spec-mean\"][\"train\"], Y_train)\n",
    "    print(gsearch1.grid_scores_, gsearch1.best_params_, gsearch1.best_score_)\n",
    "    \n",
    "tuneXGB4()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### gamma = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def tuneXGB5():\n",
    "    xgb1 = xgb.XGBClassifier(\n",
    "        learning_rate=0.1,\n",
    "        n_estimators=1000,\n",
    "        max_depth=7, # This should be between 3-10\n",
    "        min_child_weight=1, # A smaller value is chosen because it is a highly imbalanced class problem\n",
    "        gamma=0,\n",
    "        subsample=0.8, # Typical values range between 0.5-0.9.\n",
    "        colsample_bytree=0.8, # Typical values range between 0.5-0.9.\n",
    "        objective= 'binary:logistic',\n",
    "        #nthread=4,\n",
    "        scale_pos_weight=1, # Because of high class imbalance\n",
    "        seed=2)\n",
    "    \n",
    "    modelfit(xgb1, datasets[\"07-spec-mean\"][\"train\"], Y_train)\n",
    "    \n",
    "tuneXGB5()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def tuneXGB6():\n",
    "    param_test1 = {\n",
    "     'subsample': np.arange(0.6, 1.0, 0.1),\n",
    "     'colsample_bytree': np.arange(0.6, 1.0, 0.1)\n",
    "    }\n",
    "    \n",
    "    gsearch1 = GridSearchCV(estimator = xgb.XGBClassifier( learning_rate=0.1, n_estimators=156, max_depth=7,\n",
    "                                                      min_child_weight=1, gamma=0, subsample=0.8, colsample_bytree=0.8,\n",
    "                                                      objective= 'binary:logistic', scale_pos_weight=1, seed=2), \n",
    "                            param_grid = param_test1, scoring='roc_auc',iid=False, cv=10)\n",
    "    \n",
    "    gsearch1.fit(datasets[\"07-spec-mean\"][\"train\"], Y_train)\n",
    "    print(gsearch1.grid_scores_, gsearch1.best_params_, gsearch1.best_score_)\n",
    "    \n",
    "tuneXGB6()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### subsample = 0.6 and colsample_bytree = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def tuneXGB7():\n",
    "    param_test1 = {\n",
    "     'subsample': np.arange(0.55, 0.7, 0.05),\n",
    "     'colsample_bytree': np.arange(0.85, 1.0, 0.05)\n",
    "    }\n",
    "    \n",
    "    gsearch1 = GridSearchCV(estimator = xgb.XGBClassifier( learning_rate=0.1, n_estimators=156, max_depth=7,\n",
    "                                                      min_child_weight=1, gamma=0, subsample=0.8, colsample_bytree=0.8,\n",
    "                                                      objective= 'binary:logistic', scale_pos_weight=1, seed=2), \n",
    "                            param_grid = param_test1, scoring='roc_auc',iid=False, cv=10)\n",
    "    \n",
    "    gsearch1.fit(datasets[\"07-spec-mean\"][\"train\"], Y_train)\n",
    "    print(gsearch1.grid_scores_, gsearch1.best_params_, gsearch1.best_score_)\n",
    "    \n",
    "tuneXGB7()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### better tuned: subsample=0.55 and colsample_bytree=0.85"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def tuneXGB8():\n",
    "    param_test1 = {\n",
    "     'reg_alpha':[1e-5, 1e-2, 0.1, 1, 100]\n",
    "    }\n",
    "    \n",
    "    gsearch1 = GridSearchCV(estimator = xgb.XGBClassifier( learning_rate=0.1, n_estimators=156, max_depth=7,\n",
    "                                                      min_child_weight=1, gamma=0, subsample=0.55, colsample_bytree=0.85,\n",
    "                                                      objective= 'binary:logistic', scale_pos_weight=1, seed=2), \n",
    "                            param_grid = param_test1, scoring='roc_auc',iid=False, cv=10)\n",
    "    \n",
    "    gsearch1.fit(datasets[\"07-spec-mean\"][\"train\"], Y_train)\n",
    "    print(gsearch1.grid_scores_, gsearch1.best_params_, gsearch1.best_score_)\n",
    "    \n",
    "tuneXGB8()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reg alpha = 1e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def tuneXGB9():    \n",
    "    xgb1 = xgb.XGBClassifier( learning_rate=0.01, n_estimators=5000, max_depth=7,\n",
    "                      min_child_weight=1, gamma=0, subsample=0.55, colsample_bytree=0.85,\n",
    "                      reg_alpha=1e-5, objective= 'binary:logistic', scale_pos_weight=1, seed=2)\n",
    "    \n",
    "    modelfit(xgb1, datasets[\"07-spec-mean\"][\"train\"], Y_train)\n",
    "    \n",
    "tuneXGB9()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def tuneLDA():\n",
    "    param_test1 = [{\"solver\": [\"svd\"], \"n_components\": np.arange(1,len(X_train.columns) - 1)},\n",
    "                   {\"solver\": [\"lsqr\", \"eigen\"], \"n_components\": np.arange(1,len(X_train.columns) - 1), \"shrinkage\": [\"auto\"]}]\n",
    "        \n",
    "    gsearch1 = GridSearchCV(estimator=LinearDiscriminantAnalysis(), \n",
    "                            param_grid = param_test1, scoring='roc_auc', cv=10)\n",
    "    \n",
    "    fit = gsearch1.fit(datasets[\"09-spec-min\"][\"train\"], Y_train)\n",
    "    return(fit)\n",
    "    \n",
    "bestLDAfit = tuneLDA()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bestLDAfit.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bestLDAfit.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def evaluatingBestLDA():\n",
    "    kfold = mds.StratifiedKFold(n_splits=num_folds, shuffle=True, random_state=2)\n",
    "    model = LinearDiscriminantAnalysis(n_components = 1, shrinkage = \"auto\", solver=\"lsqr\")\n",
    "    \n",
    "    cv_results = mds.cross_val_score(model, datasets[\"09-spec-min\"][\"train\"], Y_train, cv=kfold, scoring=\"roc_auc\")\n",
    "    print(cv_results.mean())\n",
    "    \n",
    "evaluatingBestLDA()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 - Unsupervised Anomaly Detection Methods\n",
    "We decided to try LOF and see how it goes. We used our implementation from HW1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import lof_pal as lof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def makePredictonsLOF():\n",
    "    outliers = []\n",
    "    \n",
    "    kfold = mds.StratifiedKFold(n_splits=2, shuffle=True, random_state=2)\n",
    "    sets,_ = kfold.split(datasets[\"07-spec-mean\"][\"train\"], Y_train)                                      \n",
    "    \n",
    "    # Train with only positive examples:\n",
    "    l = lof.LOF(datasets[\"07-spec-mean\"][\"train\"].iloc[sets[0]][Y_train[sets[0]] != 1], 3)\n",
    "    \n",
    "    Y_pred = [1 if x > 1.2 else 0 for x in l.predict(datasets[\"07-spec-mean\"][\"train\"].iloc[sets[1]])]\n",
    "        \n",
    "    plot_confusion_matrix(confusion_matrix(Y_train[sets[1]], Y_pred, labels = [0, 1]), classes = [0, 1])\n",
    "    #return Y_pred\n",
    "        \n",
    "    \n",
    "makePredictonsLOF()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 - Submission to Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# choose algorithm\n",
    "def makeSubmissionKaggle(NA_strategy, algorithm):\n",
    "    print(\"Submiting using \\\"%s\\\"\" % (NA_strategy))\n",
    "\n",
    "    algorithm.fit(datasets[NA_strategy][\"train\"], Y_train)\n",
    "    Y_pred = algorithm.predict(datasets[NA_strategy][\"test\"])\n",
    "    Y_pred = Y_pred.astype(int)\n",
    "\n",
    "    # save data to CSV\n",
    "    saveDataToCSV(Y_pred)\n",
    "    \n",
    "#makeSubmissionKaggle(\"07-spec-mean\", xgb.XGBClassifier( learning_rate=0.01, n_estimators=5000, max_depth=7,\n",
    "#                      min_child_weight=1, gamma=0, subsample=0.55, colsample_bytree=0.85,\n",
    "#                      reg_alpha=1e-5, objective= 'binary:logistic', scale_pos_weight=1, seed=2))\n",
    "\n",
    "#makeSubmissionKaggle(\"09-spec-min\", LinearDiscriminantAnalysis(n_components = 1, shrinkage = \"auto\", solver=\"lsqr\"))\n",
    "makeSubmissionKaggle(\"10-spec-max\", AdaBoostClassifier())"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
